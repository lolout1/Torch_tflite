{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03567cc6-903f-469f-9960-c43b5943a843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 16:50:45,316 - INFO - TFLite model loaded successfully.\n",
      "2025-04-30 16:50:45,318 - INFO - Model File Size: 0.09 MB\n",
      "2025-04-30 16:50:45,319 - INFO - \n",
      "Input Tensors:\n",
      "2025-04-30 16:50:45,320 - INFO - Name: inputs, Index: 0, Shape: [ 1 64  3], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,320 - INFO - \n",
      "Output Tensors:\n",
      "2025-04-30 16:50:45,322 - INFO - Name: Identity, Index: 171, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,323 - INFO - \n",
      "All Tensors:\n",
      "2025-04-30 16:50:45,326 - INFO - Name: inputs, Index: 0, Shape: [ 1 64  3], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,327 - INFO - Name: arith.constant, Index: 1, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,328 - INFO - Name: arith.constant1, Index: 2, Shape: [32 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,329 - INFO - Name: arith.constant2, Index: 3, Shape: [64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,330 - INFO - Name: arith.constant3, Index: 4, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,331 - INFO - Name: arith.constant4, Index: 5, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,332 - INFO - Name: arith.constant5, Index: 6, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,333 - INFO - Name: arith.constant6, Index: 7, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,333 - INFO - Name: arith.constant7, Index: 8, Shape: [32 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,334 - INFO - Name: arith.constant8, Index: 9, Shape: [64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,339 - INFO - Name: arith.constant9, Index: 10, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,341 - INFO - Name: arith.constant10, Index: 11, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,341 - INFO - Name: arith.constant11, Index: 12, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,342 - INFO - Name: arith.constant12, Index: 13, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,343 - INFO - Name: arith.constant13, Index: 14, Shape: [32  8  1  3], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,344 - INFO - Name: arith.constant14, Index: 15, Shape: [ 1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,344 - INFO - Name: arith.constant15, Index: 16, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,345 - INFO - Name: arith.constant16, Index: 17, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,346 - INFO - Name: arith.constant17, Index: 18, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,347 - INFO - Name: arith.constant18, Index: 19, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,347 - INFO - Name: arith.constant19, Index: 20, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,348 - INFO - Name: arith.constant20, Index: 21, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,349 - INFO - Name: arith.constant21, Index: 22, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,350 - INFO - Name: arith.constant22, Index: 23, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,352 - INFO - Name: arith.constant23, Index: 24, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,353 - INFO - Name: arith.constant24, Index: 25, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,354 - INFO - Name: arith.constant25, Index: 26, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,355 - INFO - Name: arith.constant26, Index: 27, Shape: [ 1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,357 - INFO - Name: arith.constant27, Index: 28, Shape: [1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,357 - INFO - Name: arith.constant28, Index: 29, Shape: [4 8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,358 - INFO - Name: arith.constant29, Index: 30, Shape: [4 8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,359 - INFO - Name: arith.constant30, Index: 31, Shape: [4 8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,360 - INFO - Name: arith.constant31, Index: 32, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,360 - INFO - Name: arith.constant32, Index: 33, Shape: [4 8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,361 - INFO - Name: arith.constant33, Index: 34, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,362 - INFO - Name: arith.constant34, Index: 35, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,362 - INFO - Name: arith.constant35, Index: 36, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,363 - INFO - Name: arith.constant36, Index: 37, Shape: [4 8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,364 - INFO - Name: arith.constant37, Index: 38, Shape: [4 8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,365 - INFO - Name: arith.constant38, Index: 39, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,366 - INFO - Name: arith.constant39, Index: 40, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,367 - INFO - Name: arith.constant40, Index: 41, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,368 - INFO - Name: arith.constant41, Index: 42, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,369 - INFO - Name: arith.constant42, Index: 43, Shape: [], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,370 - INFO - Name: arith.constant43, Index: 44, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,371 - INFO - Name: arith.constant44, Index: 45, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,372 - INFO - Name: arith.constant45, Index: 46, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,374 - INFO - Name: arith.constant46, Index: 47, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,375 - INFO - Name: arith.constant47, Index: 48, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,376 - INFO - Name: arith.constant48, Index: 49, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,377 - INFO - Name: arith.constant49, Index: 50, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,377 - INFO - Name: trans_model_14_1/ExpandDims/dim, Index: 51, Shape: [], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,378 - INFO - Name: trans_model_14_1/ExpandDims, Index: 52, Shape: [ 1 64  1  3], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,379 - INFO - Name: trans_model_14_1/conv_projection_1/BiasAdd;trans_model_14_1/conv_projection_1/convolution, Index: 53, Shape: [ 1 64  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,380 - INFO - Name: trans_model_14_1/Squeeze, Index: 54, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,381 - INFO - Name: trans_model_14_1/layer_norm_1/moments/mean, Index: 55, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,382 - INFO - Name: trans_model_14_1/layer_norm_1/Neg, Index: 56, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,383 - INFO - Name: trans_model_14_1/layer_norm_1/moments/SquaredDifference, Index: 57, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,384 - INFO - Name: trans_model_14_1/layer_norm_1/moments/variance, Index: 58, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,385 - INFO - Name: trans_model_14_1/layer_norm_1/add, Index: 59, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,387 - INFO - Name: trans_model_14_1/layer_norm_1/Rsqrt, Index: 60, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,388 - INFO - Name: trans_model_14_1/layer_norm_1/mul, Index: 61, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,389 - INFO - Name: trans_model_14_1/layer_norm_1/mul_1, Index: 62, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,390 - INFO - Name: trans_model_14_1/layer_norm_1/add_1, Index: 63, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,391 - INFO - Name: trans_model_14_1/layer_norm_1/mul_2, Index: 64, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,392 - INFO - Name: trans_model_14_1/layer_norm_1/add_2, Index: 65, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,393 - INFO - Name: trans_model_14_1/mha_0_1/key_1/MatMul, Index: 66, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,394 - INFO - Name: trans_model_14_1/mha_0_1/key_1/Reshape_1, Index: 67, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,395 - INFO - Name: trans_model_14_1/mha_0_1/key_1/add, Index: 68, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,395 - INFO - Name: trans_model_14_1/mha_0_1/query_1/MatMul, Index: 69, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,396 - INFO - Name: trans_model_14_1/mha_0_1/query_1/Reshape_1, Index: 70, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,397 - INFO - Name: trans_model_14_1/mha_0_1/query_1/add, Index: 71, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,399 - INFO - Name: trans_model_14_1/mha_0_1/Mul, Index: 72, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,400 - INFO - Name: trans_model_14_1/mha_0_1/transpose, Index: 73, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,401 - INFO - Name: trans_model_14_1/mha_0_1/transpose_1, Index: 74, Shape: [ 1  4  8 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,402 - INFO - Name: trans_model_14_1/mha_0_1/MatMul, Index: 75, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,403 - INFO - Name: trans_model_14_1/mha_0_1/transpose_2, Index: 76, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,404 - INFO - Name: trans_model_14_1/mha_0_1/softmax_44_1/Softmax, Index: 77, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,405 - INFO - Name: trans_model_14_1/mha_0_1/value_1/MatMul, Index: 78, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,406 - INFO - Name: trans_model_14_1/mha_0_1/value_1/Reshape_1, Index: 79, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,407 - INFO - Name: trans_model_14_1/mha_0_1/value_1/add, Index: 80, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,409 - INFO - Name: trans_model_14_1/mha_0_1/transpose_3, Index: 81, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,410 - INFO - Name: trans_model_14_1/mha_0_1/MatMul_1, Index: 82, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,411 - INFO - Name: trans_model_14_1/mha_0_1/transpose_4, Index: 83, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,413 - INFO - Name: trans_model_14_1/mha_0_1/attention_output_1/Reshape, Index: 84, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,414 - INFO - Name: trans_model_14_1/mha_0_1/attention_output_1/MatMul;trans_model_14_1/mha_0_1/attention_output_1/add, Index: 85, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,415 - INFO - Name: trans_model_14_1/add, Index: 86, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,416 - INFO - Name: trans_model_14_1/ln0_0_1/moments/mean, Index: 87, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,418 - INFO - Name: trans_model_14_1/ln0_0_1/Neg, Index: 88, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,419 - INFO - Name: trans_model_14_1/ln0_0_1/moments/SquaredDifference, Index: 89, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,421 - INFO - Name: trans_model_14_1/ln0_0_1/moments/variance, Index: 90, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,423 - INFO - Name: trans_model_14_1/ln0_0_1/add, Index: 91, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,424 - INFO - Name: trans_model_14_1/ln0_0_1/Rsqrt, Index: 92, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,427 - INFO - Name: trans_model_14_1/ln0_0_1/mul, Index: 93, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,429 - INFO - Name: trans_model_14_1/ln0_0_1/mul_1, Index: 94, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,435 - INFO - Name: trans_model_14_1/ln0_0_1/add_1, Index: 95, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,437 - INFO - Name: trans_model_14_1/ln0_0_1/mul_2, Index: 96, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,443 - INFO - Name: trans_model_14_1/ln0_0_1/add_2, Index: 97, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,455 - INFO - Name: trans_model_14_1/ffn_0_1/ffn_dense1_0_1/MatMul;trans_model_14_1/ffn_0_1/ffn_dense1_0_1/Relu;trans_model_14_1/ffn_0_1/ffn_dense1_0_1/BiasAdd, Index: 98, Shape: [ 1 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,456 - INFO - Name: trans_model_14_1/ffn_0_1/ffn_dense2_0_1/MatMul;trans_model_14_1/ffn_0_1/ffn_dense2_0_1/BiasAdd, Index: 99, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,458 - INFO - Name: trans_model_14_1/add_1, Index: 100, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,461 - INFO - Name: trans_model_14_1/ln0_1_1/moments/mean, Index: 101, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,463 - INFO - Name: trans_model_14_1/ln0_1_1/Neg, Index: 102, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,466 - INFO - Name: trans_model_14_1/ln0_1_1/moments/SquaredDifference, Index: 103, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,469 - INFO - Name: trans_model_14_1/ln0_1_1/moments/variance, Index: 104, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,471 - INFO - Name: trans_model_14_1/ln0_1_1/add, Index: 105, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,473 - INFO - Name: trans_model_14_1/ln0_1_1/Rsqrt, Index: 106, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,474 - INFO - Name: trans_model_14_1/ln0_1_1/mul, Index: 107, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,476 - INFO - Name: trans_model_14_1/ln0_1_1/mul_1, Index: 108, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,480 - INFO - Name: trans_model_14_1/ln0_1_1/add_1, Index: 109, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,482 - INFO - Name: trans_model_14_1/ln0_1_1/mul_2, Index: 110, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,486 - INFO - Name: trans_model_14_1/ln0_1_1/add_2, Index: 111, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,488 - INFO - Name: trans_model_14_1/mha_1_1/key_1/MatMul, Index: 112, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,492 - INFO - Name: trans_model_14_1/mha_1_1/key_1/Reshape_1, Index: 113, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,494 - INFO - Name: trans_model_14_1/mha_1_1/key_1/add, Index: 114, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,495 - INFO - Name: trans_model_14_1/mha_1_1/query_1/MatMul, Index: 115, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,497 - INFO - Name: trans_model_14_1/mha_1_1/query_1/Reshape_1, Index: 116, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,499 - INFO - Name: trans_model_14_1/mha_1_1/query_1/add, Index: 117, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,500 - INFO - Name: trans_model_14_1/mha_1_1/Mul, Index: 118, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,502 - INFO - Name: trans_model_14_1/mha_1_1/transpose, Index: 119, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,503 - INFO - Name: trans_model_14_1/mha_1_1/transpose_1, Index: 120, Shape: [ 1  4  8 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,504 - INFO - Name: trans_model_14_1/mha_1_1/MatMul, Index: 121, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,506 - INFO - Name: trans_model_14_1/mha_1_1/transpose_2, Index: 122, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,508 - INFO - Name: trans_model_14_1/mha_1_1/softmax_45_1/Softmax, Index: 123, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,510 - INFO - Name: trans_model_14_1/mha_1_1/value_1/MatMul, Index: 124, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,512 - INFO - Name: trans_model_14_1/mha_1_1/value_1/Reshape_1, Index: 125, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,513 - INFO - Name: trans_model_14_1/mha_1_1/value_1/add, Index: 126, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,515 - INFO - Name: trans_model_14_1/mha_1_1/transpose_3, Index: 127, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,516 - INFO - Name: trans_model_14_1/mha_1_1/MatMul_1, Index: 128, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,517 - INFO - Name: trans_model_14_1/mha_1_1/transpose_4, Index: 129, Shape: [ 1 64  4  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,518 - INFO - Name: trans_model_14_1/mha_1_1/attention_output_1/Reshape, Index: 130, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,519 - INFO - Name: trans_model_14_1/mha_1_1/attention_output_1/MatMul;trans_model_14_1/mha_1_1/attention_output_1/add, Index: 131, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,521 - INFO - Name: trans_model_14_1/add_2, Index: 132, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,523 - INFO - Name: trans_model_14_1/ln1_0_1/moments/mean, Index: 133, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,524 - INFO - Name: trans_model_14_1/ln1_0_1/Neg, Index: 134, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,525 - INFO - Name: trans_model_14_1/ln1_0_1/moments/SquaredDifference, Index: 135, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,526 - INFO - Name: trans_model_14_1/ln1_0_1/moments/variance, Index: 136, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,528 - INFO - Name: trans_model_14_1/ln1_0_1/add, Index: 137, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,529 - INFO - Name: trans_model_14_1/ln1_0_1/Rsqrt, Index: 138, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,530 - INFO - Name: trans_model_14_1/ln1_0_1/mul, Index: 139, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,532 - INFO - Name: trans_model_14_1/ln1_0_1/mul_1, Index: 140, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,533 - INFO - Name: trans_model_14_1/ln1_0_1/add_1, Index: 141, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,535 - INFO - Name: trans_model_14_1/ln1_0_1/mul_2, Index: 142, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,536 - INFO - Name: trans_model_14_1/ln1_0_1/add_2, Index: 143, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,537 - INFO - Name: trans_model_14_1/ffn_1_1/ffn_dense1_1_1/MatMul;trans_model_14_1/ffn_1_1/ffn_dense1_1_1/Relu;trans_model_14_1/ffn_1_1/ffn_dense1_1_1/BiasAdd, Index: 144, Shape: [ 1 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,538 - INFO - Name: trans_model_14_1/ffn_1_1/ffn_dense2_1_1/MatMul;trans_model_14_1/ffn_1_1/ffn_dense2_1_1/BiasAdd, Index: 145, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,540 - INFO - Name: trans_model_14_1/add_3, Index: 146, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,541 - INFO - Name: trans_model_14_1/ln1_1_1/moments/mean, Index: 147, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,543 - INFO - Name: trans_model_14_1/ln1_1_1/Neg, Index: 148, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,544 - INFO - Name: trans_model_14_1/ln1_1_1/moments/SquaredDifference, Index: 149, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,545 - INFO - Name: trans_model_14_1/ln1_1_1/moments/variance, Index: 150, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,546 - INFO - Name: trans_model_14_1/ln1_1_1/add, Index: 151, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,547 - INFO - Name: trans_model_14_1/ln1_1_1/Rsqrt, Index: 152, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,548 - INFO - Name: trans_model_14_1/ln1_1_1/mul, Index: 153, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,549 - INFO - Name: trans_model_14_1/ln1_1_1/mul_1, Index: 154, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,550 - INFO - Name: trans_model_14_1/ln1_1_1/add_1, Index: 155, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,551 - INFO - Name: trans_model_14_1/ln1_1_1/mul_2, Index: 156, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,553 - INFO - Name: trans_model_14_1/ln1_1_1/add_2, Index: 157, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,554 - INFO - Name: trans_model_14_1/final_norm_1/moments/mean, Index: 158, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,555 - INFO - Name: trans_model_14_1/final_norm_1/Neg, Index: 159, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,556 - INFO - Name: trans_model_14_1/final_norm_1/moments/SquaredDifference, Index: 160, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,557 - INFO - Name: trans_model_14_1/final_norm_1/moments/variance, Index: 161, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,558 - INFO - Name: trans_model_14_1/final_norm_1/add, Index: 162, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,559 - INFO - Name: trans_model_14_1/final_norm_1/Rsqrt, Index: 163, Shape: [ 1 64  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,560 - INFO - Name: trans_model_14_1/final_norm_1/mul, Index: 164, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,562 - INFO - Name: trans_model_14_1/final_norm_1/mul_1, Index: 165, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,563 - INFO - Name: trans_model_14_1/final_norm_1/add_1, Index: 166, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,564 - INFO - Name: trans_model_14_1/final_norm_1/mul_2, Index: 167, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,566 - INFO - Name: trans_model_14_1/final_norm_1/add_2, Index: 168, Shape: [ 1 64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,567 - INFO - Name: trans_model_14_1/global_pool_1/Mean, Index: 169, Shape: [ 1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,569 - INFO - Name: trans_model_14_1/output_dense_1/MatMul;trans_model_14_1/output_dense_1/Add, Index: 170, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,570 - INFO - Name: Identity, Index: 171, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,572 - INFO - Name: , Index: 172, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,573 - INFO - Name: , Index: 173, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,574 - INFO - Name: , Index: 174, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,575 - INFO - Name: , Index: 176, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,576 - INFO - Name: , Index: 177, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,578 - INFO - Name: , Index: 178, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,579 - INFO - Name: , Index: 192, Shape: [ 1  4  8 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,580 - INFO - Name: BatchMatMul_scratch_buffer, Index: 193, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,581 - INFO - Name: , Index: 205, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,583 - INFO - Name: BatchMatMul_scratch_buffer, Index: 206, Shape: [ 1  4  8 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,584 - INFO - Name: , Index: 218, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,585 - INFO - Name: , Index: 219, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,587 - INFO - Name: , Index: 220, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,589 - INFO - Name: , Index: 222, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,591 - INFO - Name: , Index: 223, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,593 - INFO - Name: , Index: 224, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,594 - INFO - Name: , Index: 238, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,595 - INFO - Name: , Index: 239, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,596 - INFO - Name: , Index: 240, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,597 - INFO - Name: , Index: 242, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,598 - INFO - Name: , Index: 243, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,600 - INFO - Name: , Index: 244, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,603 - INFO - Name: , Index: 258, Shape: [ 1  4  8 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,606 - INFO - Name: BatchMatMul_scratch_buffer, Index: 259, Shape: [ 1  4 64  8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,607 - INFO - Name: , Index: 271, Shape: [ 1  4 64 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,609 - INFO - Name: BatchMatMul_scratch_buffer, Index: 272, Shape: [ 1  4  8 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,610 - INFO - Name: , Index: 284, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,611 - INFO - Name: , Index: 285, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,612 - INFO - Name: , Index: 286, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,615 - INFO - Name: , Index: 288, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,616 - INFO - Name: , Index: 289, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,618 - INFO - Name: , Index: 290, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,620 - INFO - Name: , Index: 304, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,622 - INFO - Name: , Index: 305, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,623 - INFO - Name: , Index: 306, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,624 - INFO - Name: , Index: 308, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,625 - INFO - Name: , Index: 309, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,626 - INFO - Name: , Index: 310, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,627 - INFO - Name: , Index: 312, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,628 - INFO - Name: , Index: 313, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,629 - INFO - Name: , Index: 314, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,630 - INFO - Name: , Index: 316, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,631 - INFO - Name: , Index: 317, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,632 - INFO - Name: , Index: 318, Shape: [64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,633 - INFO - Name: , Index: 320, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,634 - INFO - Name: , Index: 321, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:45,635 - INFO - Name: , Index: 322, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,637 - INFO - Name: Conv_hwcn_weights, Index: 330, Shape: [24 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:45,638 - INFO - \n",
      "Operations:\n",
      "2025-04-30 16:50:45,640 - INFO - Type: EXPAND_DIMS, Inputs: [ 0 51], Outputs: [52]\n",
      "2025-04-30 16:50:45,641 - INFO - Type: CONV_2D, Inputs: [52 14  1], Outputs: [53]\n",
      "2025-04-30 16:50:45,642 - INFO - Type: RESHAPE, Inputs: [53 41], Outputs: [54]\n",
      "2025-04-30 16:50:45,645 - INFO - Type: MEAN, Inputs: [54 44], Outputs: [55]\n",
      "2025-04-30 16:50:45,646 - INFO - Type: NEG, Inputs: [55], Outputs: [56]\n",
      "2025-04-30 16:50:45,647 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [54 55], Outputs: [57]\n",
      "2025-04-30 16:50:45,649 - INFO - Type: MEAN, Inputs: [57 44], Outputs: [58]\n",
      "2025-04-30 16:50:45,650 - INFO - Type: ADD, Inputs: [58 45], Outputs: [59]\n",
      "2025-04-30 16:50:45,651 - INFO - Type: RSQRT, Inputs: [59], Outputs: [60]\n",
      "2025-04-30 16:50:45,651 - INFO - Type: MUL, Inputs: [60 25], Outputs: [61]\n",
      "2025-04-30 16:50:45,653 - INFO - Type: MUL, Inputs: [56 61], Outputs: [62]\n",
      "2025-04-30 16:50:45,655 - INFO - Type: ADD, Inputs: [62 24], Outputs: [63]\n",
      "2025-04-30 16:50:45,657 - INFO - Type: MUL, Inputs: [54 61], Outputs: [64]\n",
      "2025-04-30 16:50:45,659 - INFO - Type: ADD, Inputs: [64 63], Outputs: [65]\n",
      "2025-04-30 16:50:45,659 - INFO - Type: FULLY_CONNECTED, Inputs: [65 13 -1], Outputs: [66]\n",
      "2025-04-30 16:50:45,660 - INFO - Type: RESHAPE, Inputs: [66 39], Outputs: [67]\n",
      "2025-04-30 16:50:45,661 - INFO - Type: ADD, Inputs: [67 38], Outputs: [68]\n",
      "2025-04-30 16:50:45,662 - INFO - Type: FULLY_CONNECTED, Inputs: [65 12 -1], Outputs: [69]\n",
      "2025-04-30 16:50:45,663 - INFO - Type: RESHAPE, Inputs: [69 39], Outputs: [70]\n",
      "2025-04-30 16:50:45,664 - INFO - Type: ADD, Inputs: [70 37], Outputs: [71]\n",
      "2025-04-30 16:50:45,664 - INFO - Type: MUL, Inputs: [71 42], Outputs: [72]\n",
      "2025-04-30 16:50:45,665 - INFO - Type: TRANSPOSE, Inputs: [68 36], Outputs: [73]\n",
      "2025-04-30 16:50:45,666 - INFO - Type: TRANSPOSE, Inputs: [72 35], Outputs: [74]\n",
      "2025-04-30 16:50:45,667 - INFO - Type: BATCH_MATMUL, Inputs: [73 74], Outputs: [75]\n",
      "2025-04-30 16:50:45,667 - INFO - Type: TRANSPOSE, Inputs: [75 34], Outputs: [76]\n",
      "2025-04-30 16:50:45,668 - INFO - Type: SOFTMAX, Inputs: [76], Outputs: [77]\n",
      "2025-04-30 16:50:45,669 - INFO - Type: FULLY_CONNECTED, Inputs: [65 11 -1], Outputs: [78]\n",
      "2025-04-30 16:50:45,671 - INFO - Type: RESHAPE, Inputs: [78 39], Outputs: [79]\n",
      "2025-04-30 16:50:45,672 - INFO - Type: ADD, Inputs: [79 33], Outputs: [80]\n",
      "2025-04-30 16:50:45,673 - INFO - Type: TRANSPOSE, Inputs: [80 36], Outputs: [81]\n",
      "2025-04-30 16:50:45,674 - INFO - Type: BATCH_MATMUL, Inputs: [77 81], Outputs: [82]\n",
      "2025-04-30 16:50:45,675 - INFO - Type: TRANSPOSE, Inputs: [82 36], Outputs: [83]\n",
      "2025-04-30 16:50:45,676 - INFO - Type: RESHAPE, Inputs: [83 41], Outputs: [84]\n",
      "2025-04-30 16:50:45,676 - INFO - Type: FULLY_CONNECTED, Inputs: [84 10 40], Outputs: [85]\n",
      "2025-04-30 16:50:45,677 - INFO - Type: ADD, Inputs: [65 85], Outputs: [86]\n",
      "2025-04-30 16:50:45,679 - INFO - Type: MEAN, Inputs: [86 44], Outputs: [87]\n",
      "2025-04-30 16:50:45,680 - INFO - Type: NEG, Inputs: [87], Outputs: [88]\n",
      "2025-04-30 16:50:45,682 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [86 87], Outputs: [89]\n",
      "2025-04-30 16:50:45,684 - INFO - Type: MEAN, Inputs: [89 44], Outputs: [90]\n",
      "2025-04-30 16:50:45,686 - INFO - Type: ADD, Inputs: [90 45], Outputs: [91]\n",
      "2025-04-30 16:50:45,687 - INFO - Type: RSQRT, Inputs: [91], Outputs: [92]\n",
      "2025-04-30 16:50:45,689 - INFO - Type: MUL, Inputs: [92 23], Outputs: [93]\n",
      "2025-04-30 16:50:45,690 - INFO - Type: MUL, Inputs: [88 93], Outputs: [94]\n",
      "2025-04-30 16:50:45,692 - INFO - Type: ADD, Inputs: [94 22], Outputs: [95]\n",
      "2025-04-30 16:50:45,694 - INFO - Type: MUL, Inputs: [86 93], Outputs: [96]\n",
      "2025-04-30 16:50:45,700 - INFO - Type: ADD, Inputs: [96 95], Outputs: [97]\n",
      "2025-04-30 16:50:45,702 - INFO - Type: FULLY_CONNECTED, Inputs: [97  9 49], Outputs: [98]\n",
      "2025-04-30 16:50:45,704 - INFO - Type: FULLY_CONNECTED, Inputs: [98  8 48], Outputs: [99]\n",
      "2025-04-30 16:50:45,705 - INFO - Type: ADD, Inputs: [97 99], Outputs: [100]\n",
      "2025-04-30 16:50:45,707 - INFO - Type: MEAN, Inputs: [100  44], Outputs: [101]\n",
      "2025-04-30 16:50:45,708 - INFO - Type: NEG, Inputs: [101], Outputs: [102]\n",
      "2025-04-30 16:50:45,710 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [100 101], Outputs: [103]\n",
      "2025-04-30 16:50:45,711 - INFO - Type: MEAN, Inputs: [103  44], Outputs: [104]\n",
      "2025-04-30 16:50:45,712 - INFO - Type: ADD, Inputs: [104  45], Outputs: [105]\n",
      "2025-04-30 16:50:45,714 - INFO - Type: RSQRT, Inputs: [105], Outputs: [106]\n",
      "2025-04-30 16:50:45,715 - INFO - Type: MUL, Inputs: [106  21], Outputs: [107]\n",
      "2025-04-30 16:50:45,716 - INFO - Type: MUL, Inputs: [102 107], Outputs: [108]\n",
      "2025-04-30 16:50:45,722 - INFO - Type: ADD, Inputs: [108  20], Outputs: [109]\n",
      "2025-04-30 16:50:45,723 - INFO - Type: MUL, Inputs: [100 107], Outputs: [110]\n",
      "2025-04-30 16:50:45,724 - INFO - Type: ADD, Inputs: [110 109], Outputs: [111]\n",
      "2025-04-30 16:50:45,725 - INFO - Type: FULLY_CONNECTED, Inputs: [111   7  -1], Outputs: [112]\n",
      "2025-04-30 16:50:45,727 - INFO - Type: RESHAPE, Inputs: [112  39], Outputs: [113]\n",
      "2025-04-30 16:50:45,727 - INFO - Type: ADD, Inputs: [113  31], Outputs: [114]\n",
      "2025-04-30 16:50:45,729 - INFO - Type: FULLY_CONNECTED, Inputs: [111   6  -1], Outputs: [115]\n",
      "2025-04-30 16:50:45,730 - INFO - Type: RESHAPE, Inputs: [115  39], Outputs: [116]\n",
      "2025-04-30 16:50:45,731 - INFO - Type: ADD, Inputs: [116  30], Outputs: [117]\n",
      "2025-04-30 16:50:45,731 - INFO - Type: MUL, Inputs: [117  42], Outputs: [118]\n",
      "2025-04-30 16:50:45,732 - INFO - Type: TRANSPOSE, Inputs: [114  36], Outputs: [119]\n",
      "2025-04-30 16:50:45,733 - INFO - Type: TRANSPOSE, Inputs: [118  35], Outputs: [120]\n",
      "2025-04-30 16:50:45,733 - INFO - Type: BATCH_MATMUL, Inputs: [119 120], Outputs: [121]\n",
      "2025-04-30 16:50:45,734 - INFO - Type: TRANSPOSE, Inputs: [121  34], Outputs: [122]\n",
      "2025-04-30 16:50:45,735 - INFO - Type: SOFTMAX, Inputs: [122], Outputs: [123]\n",
      "2025-04-30 16:50:45,736 - INFO - Type: FULLY_CONNECTED, Inputs: [111   5  -1], Outputs: [124]\n",
      "2025-04-30 16:50:45,736 - INFO - Type: RESHAPE, Inputs: [124  39], Outputs: [125]\n",
      "2025-04-30 16:50:45,737 - INFO - Type: ADD, Inputs: [125  29], Outputs: [126]\n",
      "2025-04-30 16:50:45,738 - INFO - Type: TRANSPOSE, Inputs: [126  36], Outputs: [127]\n",
      "2025-04-30 16:50:45,739 - INFO - Type: BATCH_MATMUL, Inputs: [123 127], Outputs: [128]\n",
      "2025-04-30 16:50:45,739 - INFO - Type: TRANSPOSE, Inputs: [128  36], Outputs: [129]\n",
      "2025-04-30 16:50:45,740 - INFO - Type: RESHAPE, Inputs: [129  41], Outputs: [130]\n",
      "2025-04-30 16:50:45,744 - INFO - Type: FULLY_CONNECTED, Inputs: [130   4  32], Outputs: [131]\n",
      "2025-04-30 16:50:45,747 - INFO - Type: ADD, Inputs: [111 131], Outputs: [132]\n",
      "2025-04-30 16:50:45,748 - INFO - Type: MEAN, Inputs: [132  44], Outputs: [133]\n",
      "2025-04-30 16:50:45,749 - INFO - Type: NEG, Inputs: [133], Outputs: [134]\n",
      "2025-04-30 16:50:45,750 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [132 133], Outputs: [135]\n",
      "2025-04-30 16:50:45,752 - INFO - Type: MEAN, Inputs: [135  44], Outputs: [136]\n",
      "2025-04-30 16:50:45,753 - INFO - Type: ADD, Inputs: [136  45], Outputs: [137]\n",
      "2025-04-30 16:50:45,754 - INFO - Type: RSQRT, Inputs: [137], Outputs: [138]\n",
      "2025-04-30 16:50:45,755 - INFO - Type: MUL, Inputs: [138  19], Outputs: [139]\n",
      "2025-04-30 16:50:45,756 - INFO - Type: MUL, Inputs: [134 139], Outputs: [140]\n",
      "2025-04-30 16:50:45,757 - INFO - Type: ADD, Inputs: [140  18], Outputs: [141]\n",
      "2025-04-30 16:50:45,759 - INFO - Type: MUL, Inputs: [132 139], Outputs: [142]\n",
      "2025-04-30 16:50:45,760 - INFO - Type: ADD, Inputs: [142 141], Outputs: [143]\n",
      "2025-04-30 16:50:45,761 - INFO - Type: FULLY_CONNECTED, Inputs: [143   3  47], Outputs: [144]\n",
      "2025-04-30 16:50:45,763 - INFO - Type: FULLY_CONNECTED, Inputs: [144   2  46], Outputs: [145]\n",
      "2025-04-30 16:50:45,764 - INFO - Type: ADD, Inputs: [143 145], Outputs: [146]\n",
      "2025-04-30 16:50:45,765 - INFO - Type: MEAN, Inputs: [146  44], Outputs: [147]\n",
      "2025-04-30 16:50:45,766 - INFO - Type: NEG, Inputs: [147], Outputs: [148]\n",
      "2025-04-30 16:50:45,767 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [146 147], Outputs: [149]\n",
      "2025-04-30 16:50:45,768 - INFO - Type: MEAN, Inputs: [149  44], Outputs: [150]\n",
      "2025-04-30 16:50:45,768 - INFO - Type: ADD, Inputs: [150  45], Outputs: [151]\n",
      "2025-04-30 16:50:45,769 - INFO - Type: RSQRT, Inputs: [151], Outputs: [152]\n",
      "2025-04-30 16:50:45,770 - INFO - Type: MUL, Inputs: [152  17], Outputs: [153]\n",
      "2025-04-30 16:50:45,771 - INFO - Type: MUL, Inputs: [148 153], Outputs: [154]\n",
      "2025-04-30 16:50:45,773 - INFO - Type: ADD, Inputs: [154  16], Outputs: [155]\n",
      "2025-04-30 16:50:45,775 - INFO - Type: MUL, Inputs: [146 153], Outputs: [156]\n",
      "2025-04-30 16:50:45,775 - INFO - Type: ADD, Inputs: [156 155], Outputs: [157]\n",
      "2025-04-30 16:50:45,776 - INFO - Type: MEAN, Inputs: [157  44], Outputs: [158]\n",
      "2025-04-30 16:50:45,778 - INFO - Type: NEG, Inputs: [158], Outputs: [159]\n",
      "2025-04-30 16:50:45,780 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [157 158], Outputs: [160]\n",
      "2025-04-30 16:50:45,781 - INFO - Type: MEAN, Inputs: [160  44], Outputs: [161]\n",
      "2025-04-30 16:50:45,782 - INFO - Type: ADD, Inputs: [161  45], Outputs: [162]\n",
      "2025-04-30 16:50:45,783 - INFO - Type: RSQRT, Inputs: [162], Outputs: [163]\n",
      "2025-04-30 16:50:45,784 - INFO - Type: MUL, Inputs: [163  27], Outputs: [164]\n",
      "2025-04-30 16:50:45,785 - INFO - Type: MUL, Inputs: [159 164], Outputs: [165]\n",
      "2025-04-30 16:50:45,785 - INFO - Type: ADD, Inputs: [165  26], Outputs: [166]\n",
      "2025-04-30 16:50:45,786 - INFO - Type: MUL, Inputs: [157 164], Outputs: [167]\n",
      "2025-04-30 16:50:45,787 - INFO - Type: ADD, Inputs: [167 166], Outputs: [168]\n",
      "2025-04-30 16:50:45,788 - INFO - Type: MEAN, Inputs: [168  43], Outputs: [169]\n",
      "2025-04-30 16:50:45,789 - INFO - Type: FULLY_CONNECTED, Inputs: [169  15  28], Outputs: [170]\n",
      "2025-04-30 16:50:45,790 - INFO - Type: RESHAPE, Inputs: [170  50], Outputs: [171]\n",
      "2025-04-30 16:50:45,790 - INFO - Type: DELEGATE, Inputs: [ 1 14 41 52], Outputs: [54]\n",
      "2025-04-30 16:50:45,792 - INFO - Type: DELEGATE, Inputs: [54 55], Outputs: [56 57]\n",
      "2025-04-30 16:50:45,793 - INFO - Type: DELEGATE, Inputs: [45 58], Outputs: [59]\n",
      "2025-04-30 16:50:45,794 - INFO - Type: DELEGATE, Inputs: [11 12 13 24 25 33 35 36 37 38 39 42 54 56 60], Outputs: [65 73 74 81]\n",
      "2025-04-30 16:50:45,795 - INFO - Type: DELEGATE, Inputs: [34 75], Outputs: [77]\n",
      "2025-04-30 16:50:45,796 - INFO - Type: DELEGATE, Inputs: [10 36 40 41 65 82], Outputs: [86]\n",
      "2025-04-30 16:50:45,797 - INFO - Type: DELEGATE, Inputs: [86 87], Outputs: [88 89]\n",
      "2025-04-30 16:50:45,798 - INFO - Type: DELEGATE, Inputs: [45 90], Outputs: [91]\n",
      "2025-04-30 16:50:45,799 - INFO - Type: DELEGATE, Inputs: [ 8  9 22 23 48 49 86 88 92], Outputs: [100]\n",
      "2025-04-30 16:50:45,799 - INFO - Type: DELEGATE, Inputs: [100 101], Outputs: [102 103]\n",
      "2025-04-30 16:50:45,801 - INFO - Type: DELEGATE, Inputs: [ 45 104], Outputs: [105]\n",
      "2025-04-30 16:50:45,802 - INFO - Type: DELEGATE, Inputs: [  5   6   7  20  21  29  30  31  35  36  39  42 100 102 106], Outputs: [111 119 120 127]\n",
      "2025-04-30 16:50:45,803 - INFO - Type: DELEGATE, Inputs: [ 34 121], Outputs: [123]\n",
      "2025-04-30 16:50:45,804 - INFO - Type: DELEGATE, Inputs: [  4  32  36  41 111 128], Outputs: [132]\n",
      "2025-04-30 16:50:45,805 - INFO - Type: DELEGATE, Inputs: [132 133], Outputs: [134 135]\n",
      "2025-04-30 16:50:45,806 - INFO - Type: DELEGATE, Inputs: [ 45 136], Outputs: [137]\n",
      "2025-04-30 16:50:45,807 - INFO - Type: DELEGATE, Inputs: [  2   3  18  19  46  47 132 134 138], Outputs: [146]\n",
      "2025-04-30 16:50:45,808 - INFO - Type: DELEGATE, Inputs: [146 147], Outputs: [148 149]\n",
      "2025-04-30 16:50:45,809 - INFO - Type: DELEGATE, Inputs: [ 45 150], Outputs: [151]\n",
      "2025-04-30 16:50:45,810 - INFO - Type: DELEGATE, Inputs: [ 16  17 146 148 152], Outputs: [157]\n",
      "2025-04-30 16:50:45,816 - INFO - Type: DELEGATE, Inputs: [157 158], Outputs: [159 160]\n",
      "2025-04-30 16:50:45,818 - INFO - Type: DELEGATE, Inputs: [ 45 161], Outputs: [162]\n",
      "2025-04-30 16:50:45,819 - INFO - Type: DELEGATE, Inputs: [ 26  27 157 159 163], Outputs: [168]\n",
      "2025-04-30 16:50:45,820 - INFO - Type: DELEGATE, Inputs: [ 15  28  50 169], Outputs: [171]\n",
      "2025-04-30 16:50:45,820 - INFO - \n",
      "Model Metadata:\n",
      "2025-04-30 16:50:45,847 - WARNING - tflite_support module not found. Metadata extraction skipped.\n",
      "2025-04-30 16:50:45,847 - INFO - \n",
      "Signatures:\n",
      "2025-04-30 16:50:45,848 - INFO - No signatures found in the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def print_tflite_info(tflite_model_path):\n",
    "    \"\"\"\n",
    "    Print all essential information about a TensorFlow Lite (.tflite) model for future use in Java/Android Studio.\n",
    "    \n",
    "    Args:\n",
    "        tflite_model_path (str): Path to the .tflite model file.\n",
    "    \"\"\"\n",
    "    # Load TFLite model\n",
    "    try:\n",
    "        interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "        interpreter.allocate_tensors()\n",
    "        logger.info(\"TFLite model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load TFLite model from {tflite_model_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Model file size\n",
    "    try:\n",
    "        model_size = os.path.getsize(tflite_model_path) / (1024 * 1024)  # Convert to MB\n",
    "        logger.info(f\"Model File Size: {model_size:.2f} MB\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to compute model size: {e}\")\n",
    "\n",
    "    # Input tensors\n",
    "    logger.info(\"\\nInput Tensors:\")\n",
    "    input_details = interpreter.get_input_details()\n",
    "    for tensor in input_details:\n",
    "        quant = tensor['quantization']\n",
    "        quant_info = f\"Quantization: scale={quant[0]}, zero_point={quant[1]}\" if quant != (0.0, 0) else \"No quantization\"\n",
    "        logger.info(f\"Name: {tensor['name']}, Index: {tensor['index']}, Shape: {tensor['shape']}, Dtype: {tensor['dtype']}, {quant_info}\")\n",
    "\n",
    "    # Output tensors\n",
    "    logger.info(\"\\nOutput Tensors:\")\n",
    "    output_details = interpreter.get_output_details()\n",
    "    for tensor in output_details:\n",
    "        quant = tensor['quantization']\n",
    "        quant_info = f\"Quantization: scale={quant[0]}, zero_point={quant[1]}\" if quant != (0.0, 0) else \"No quantization\"\n",
    "        logger.info(f\"Name: {tensor['name']}, Index: {tensor['index']}, Shape: {tensor['shape']}, Dtype: {tensor['dtype']}, {quant_info}\")\n",
    "\n",
    "    # All tensors\n",
    "    logger.info(\"\\nAll Tensors:\")\n",
    "    all_tensors = interpreter.get_tensor_details()\n",
    "    for tensor in all_tensors:\n",
    "        quant = tensor['quantization']\n",
    "        quant_info = f\"Quantization: scale={quant[0]}, zero_point={quant[1]}\" if quant != (0.0, 0) else \"No quantization\"\n",
    "        logger.info(f\"Name: {tensor['name']}, Index: {tensor['index']}, Shape: {tensor['shape']}, Dtype: {tensor['dtype']}, {quant_info}\")\n",
    "\n",
    "    # Operations\n",
    "    logger.info(\"\\nOperations:\")\n",
    "    try:\n",
    "        ops_details = interpreter._get_ops_details()\n",
    "        for op in ops_details:\n",
    "            logger.info(f\"Type: {op['op_name']}, Inputs: {op['inputs']}, Outputs: {op['outputs']}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to retrieve operations: {e}\")\n",
    "\n",
    "    # Metadata\n",
    "    logger.info(\"\\nModel Metadata:\")\n",
    "    try:\n",
    "        from tflite_support import metadata as _metadata\n",
    "        displayer = _metadata.MetadataDisplayer.with_model_file(tflite_model_path)\n",
    "        metadata_json = displayer.get_metadata_json()\n",
    "        if metadata_json:\n",
    "            logger.info(f\"Metadata: {metadata_json}\")\n",
    "        else:\n",
    "            logger.info(\"No metadata found in the model.\")\n",
    "    except ImportError:\n",
    "        logger.warning(\"tflite_support module not found. Metadata extraction skipped.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to extract metadata: {e}\")\n",
    "\n",
    "    # Signatures\n",
    "    logger.info(\"\\nSignatures:\")\n",
    "    signatures = interpreter.get_signature_list()\n",
    "    if signatures:\n",
    "        for sig_name, sig_details in signatures.items():\n",
    "            logger.info(f\"Signature Name: {sig_name}, Details: {sig_details}\")\n",
    "    else:\n",
    "        logger.info(\"No signatures found in the model.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    tflite_model_path = \"student_model_31.tflite\"  # Replace with your .tflite file path\n",
    "    print_tflite_info(tflite_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c1a4295-75ff-40db-9ff5-18a87f9b9602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 16:50:58,591 - INFO - TFLite model loaded successfully.\n",
      "2025-04-30 16:50:58,596 - INFO - Model File Size: 0.10 MB\n",
      "2025-04-30 16:50:58,597 - INFO - \n",
      "Input Tensors:\n",
      "2025-04-30 16:50:58,598 - INFO - Name: serving_default_args_0:0, Index: 0, Shape: [  1   3 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,600 - INFO - \n",
      "Output Tensors:\n",
      "2025-04-30 16:50:58,601 - INFO - Name: StatefulPartitionedCall:0, Index: 197, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,602 - INFO - \n",
      "All Tensors:\n",
      "2025-04-30 16:50:58,607 - INFO - Name: serving_default_args_0:0, Index: 0, Shape: [  1   3 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,609 - INFO - Name: arith.constant, Index: 1, Shape: [ 1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,610 - INFO - Name: arith.constant1, Index: 2, Shape: [1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,611 - INFO - Name: arith.constant2, Index: 3, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,612 - INFO - Name: arith.constant3, Index: 4, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,615 - INFO - Name: arith.constant4, Index: 5, Shape: [32 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,617 - INFO - Name: arith.constant5, Index: 6, Shape: [64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,618 - INFO - Name: arith.constant6, Index: 7, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,619 - INFO - Name: arith.constant7, Index: 8, Shape: [96 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,621 - INFO - Name: arith.constant8, Index: 9, Shape: [32 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,622 - INFO - Name: arith.constant9, Index: 10, Shape: [64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,623 - INFO - Name: arith.constant10, Index: 11, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,624 - INFO - Name: arith.constant11, Index: 12, Shape: [96 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,625 - INFO - Name: arith.constant12, Index: 13, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,626 - INFO - Name: arith.constant13, Index: 14, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,627 - INFO - Name: arith.constant14, Index: 15, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,628 - INFO - Name: arith.constant15, Index: 16, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,629 - INFO - Name: arith.constant16, Index: 17, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,631 - INFO - Name: arith.constant17, Index: 18, Shape: [32  8  1  3], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,632 - INFO - Name: arith.constant18, Index: 19, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,634 - INFO - Name: arith.constant19, Index: 20, Shape: [ 1 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,634 - INFO - Name: arith.constant20, Index: 21, Shape: [ 1 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,635 - INFO - Name: arith.constant21, Index: 22, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,637 - INFO - Name: arith.constant22, Index: 23, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,637 - INFO - Name: arith.constant23, Index: 24, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,638 - INFO - Name: arith.constant24, Index: 25, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,639 - INFO - Name: arith.constant25, Index: 26, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,639 - INFO - Name: arith.constant26, Index: 27, Shape: [4 2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,640 - INFO - Name: arith.constant27, Index: 28, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,641 - INFO - Name: arith.constant28, Index: 29, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,642 - INFO - Name: arith.constant29, Index: 30, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,643 - INFO - Name: arith.constant30, Index: 31, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,644 - INFO - Name: arith.constant31, Index: 32, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,645 - INFO - Name: arith.constant32, Index: 33, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,645 - INFO - Name: arith.constant33, Index: 34, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,647 - INFO - Name: arith.constant34, Index: 35, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,648 - INFO - Name: arith.constant35, Index: 36, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,649 - INFO - Name: arith.constant36, Index: 37, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,650 - INFO - Name: arith.constant37, Index: 38, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,653 - INFO - Name: arith.constant38, Index: 39, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,653 - INFO - Name: arith.constant39, Index: 40, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,654 - INFO - Name: arith.constant40, Index: 41, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,656 - INFO - Name: arith.constant41, Index: 42, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,656 - INFO - Name: arith.constant42, Index: 43, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,657 - INFO - Name: arith.constant43, Index: 44, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,658 - INFO - Name: arith.constant44, Index: 45, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,659 - INFO - Name: arith.constant45, Index: 46, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,660 - INFO - Name: XlaCallModule/ReadVariableOp_14;StatefulPartitionedCall, Index: 47, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,661 - INFO - Name: XlaCallModule/ReadVariableOp_15;StatefulPartitionedCall, Index: 48, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,662 - INFO - Name: XlaCallModule/ReadVariableOp_18;StatefulPartitionedCall, Index: 49, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,664 - INFO - Name: XlaCallModule/ReadVariableOp_19;StatefulPartitionedCall, Index: 50, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,664 - INFO - Name: XlaCallModule/ReadVariableOp_24;StatefulPartitionedCall, Index: 51, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,665 - INFO - Name: XlaCallModule/ReadVariableOp_25;StatefulPartitionedCall, Index: 52, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,666 - INFO - Name: XlaCallModule/ReadVariableOp_4;StatefulPartitionedCall, Index: 53, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,667 - INFO - Name: XlaCallModule/ReadVariableOp_5;StatefulPartitionedCall, Index: 54, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,668 - INFO - Name: XlaCallModule/ReadVariableOp_8;StatefulPartitionedCall, Index: 55, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,669 - INFO - Name: XlaCallModule/ReadVariableOp_9;StatefulPartitionedCall, Index: 56, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,670 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;, Index: 57, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,672 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;1, Index: 58, Shape: [  1   3 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,674 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;2, Index: 59, Shape: [  1 128   1   3], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,676 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;3, Index: 60, Shape: [  1 134   1   3], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,678 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;4, Index: 61, Shape: [  1 127   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,683 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;5, Index: 62, Shape: [  1  32 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,685 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;6, Index: 63, Shape: [  1  32 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,687 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;7, Index: 64, Shape: [  1  32 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,689 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;, Index: 65, Shape: [  1  32 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,691 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;1, Index: 66, Shape: [  1  32 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,692 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;2, Index: 67, Shape: [  1  32 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,694 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;3, Index: 68, Shape: [  1  32 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,695 - INFO - Name: __main__.TransModel;, Index: 69, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,697 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;, Index: 70, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,699 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;1, Index: 71, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,707 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;2, Index: 72, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,709 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;3, Index: 73, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,710 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;4, Index: 74, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,712 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;5, Index: 75, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,714 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;6, Index: 76, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,716 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;7, Index: 77, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,719 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;8, Index: 78, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,723 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;9, Index: 79, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,725 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;10, Index: 80, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,729 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;11, Index: 81, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,732 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;12, Index: 82, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,738 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;13, Index: 83, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,740 - INFO - Name: __main__.TransModel;;__main__.TransModel/torch.nn.modules.linear.Linear_qkv;, Index: 84, Shape: [  1 127  96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,744 - INFO - Name: __main__.TransModel;;__main__.TransModel/torch.nn.modules.linear.Linear_qkv;1, Index: 85, Shape: [  1 127   3   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,746 - INFO - Name: __main__.TransModel;1, Index: 86, Shape: [  3   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,749 - INFO - Name: __main__.TransModel;2, Index: 87, Shape: [  1   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,751 - INFO - Name: __main__.TransModel;3, Index: 88, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,753 - INFO - Name: __main__.TransModel;4, Index: 89, Shape: [  1   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,755 - INFO - Name: __main__.TransModel;5, Index: 90, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,756 - INFO - Name: __main__.TransModel;6, Index: 91, Shape: [  1   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,757 - INFO - Name: __main__.TransModel;7, Index: 92, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,758 - INFO - Name: __main__.TransModel;8, Index: 93, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,760 - INFO - Name: __main__.TransModel;9, Index: 94, Shape: [  1   4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,762 - INFO - Name: __main__.TransModel;10, Index: 95, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,763 - INFO - Name: __main__.TransModel;11, Index: 96, Shape: [  4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,765 - INFO - Name: __main__.TransModel;12, Index: 97, Shape: [  4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,766 - INFO - Name: __main__.TransModel;13, Index: 98, Shape: [  1   4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,768 - INFO - Name: __main__.TransModel;14, Index: 99, Shape: [  1   4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,770 - INFO - Name: __main__.TransModel;15, Index: 100, Shape: [  4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,771 - INFO - Name: __main__.TransModel;16, Index: 101, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,773 - INFO - Name: __main__.TransModel;17, Index: 102, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,774 - INFO - Name: __main__.TransModel;18, Index: 103, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,775 - INFO - Name: __main__.TransModel;19, Index: 104, Shape: [  1 127   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,777 - INFO - Name: __main__.TransModel/torch.nn.modules.linear.Linear_proj;, Index: 105, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,777 - INFO - Name: __main__.TransModel/torch.nn.modules.linear.Linear_proj;1, Index: 106, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,779 - INFO - Name: __main__.TransModel;20, Index: 107, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,781 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;14, Index: 108, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,782 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;15, Index: 109, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,783 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;16, Index: 110, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,784 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;17, Index: 111, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,785 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;18, Index: 112, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,786 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;19, Index: 113, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,787 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;20, Index: 114, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,788 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;21, Index: 115, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,789 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;22, Index: 116, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,789 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;23, Index: 117, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,790 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;24, Index: 118, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,791 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;25, Index: 119, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,792 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;26, Index: 120, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,796 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;27, Index: 121, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,797 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_0;, Index: 122, Shape: [127  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,798 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.activation.ReLU_1;;__main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_0;, Index: 123, Shape: [127  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,799 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_2;, Index: 124, Shape: [127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,800 - INFO - Name: __main__.TransModel;;__main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_2;, Index: 125, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,801 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;28, Index: 126, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,802 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;29, Index: 127, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,803 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;30, Index: 128, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,804 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;31, Index: 129, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,805 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;32, Index: 130, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,806 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;33, Index: 131, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,807 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;34, Index: 132, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,808 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;35, Index: 133, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,810 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;36, Index: 134, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,811 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;37, Index: 135, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,813 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;38, Index: 136, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,814 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;39, Index: 137, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,817 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;40, Index: 138, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,819 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;41, Index: 139, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,828 - INFO - Name: __main__.TransModel;;__main__.TransModel/torch.nn.modules.linear.Linear_qkv;2, Index: 140, Shape: [  1 127  96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,831 - INFO - Name: __main__.TransModel;;__main__.TransModel/torch.nn.modules.linear.Linear_qkv;3, Index: 141, Shape: [  1 127   3   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,834 - INFO - Name: __main__.TransModel;21, Index: 142, Shape: [  3   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,836 - INFO - Name: __main__.TransModel;22, Index: 143, Shape: [  1   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,838 - INFO - Name: __main__.TransModel;23, Index: 144, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,839 - INFO - Name: __main__.TransModel;24, Index: 145, Shape: [  1   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,842 - INFO - Name: __main__.TransModel;25, Index: 146, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,843 - INFO - Name: __main__.TransModel;26, Index: 147, Shape: [  1   1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,845 - INFO - Name: __main__.TransModel;27, Index: 148, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,846 - INFO - Name: __main__.TransModel;28, Index: 149, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,848 - INFO - Name: __main__.TransModel;29, Index: 150, Shape: [  1   4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,850 - INFO - Name: __main__.TransModel;30, Index: 151, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,852 - INFO - Name: __main__.TransModel;31, Index: 152, Shape: [  4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,854 - INFO - Name: __main__.TransModel;32, Index: 153, Shape: [  4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,855 - INFO - Name: __main__.TransModel;33, Index: 154, Shape: [  1   4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,858 - INFO - Name: __main__.TransModel;34, Index: 155, Shape: [  1   4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,861 - INFO - Name: __main__.TransModel;35, Index: 156, Shape: [  4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,864 - INFO - Name: __main__.TransModel;36, Index: 157, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,867 - INFO - Name: __main__.TransModel;37, Index: 158, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,868 - INFO - Name: __main__.TransModel;38, Index: 159, Shape: [  1   4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,871 - INFO - Name: __main__.TransModel;39, Index: 160, Shape: [  1 127   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,874 - INFO - Name: __main__.TransModel/torch.nn.modules.linear.Linear_proj;2, Index: 161, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,879 - INFO - Name: __main__.TransModel/torch.nn.modules.linear.Linear_proj;3, Index: 162, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,881 - INFO - Name: __main__.TransModel;40, Index: 163, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,883 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;42, Index: 164, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,885 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;43, Index: 165, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,887 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;44, Index: 166, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,889 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;45, Index: 167, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,891 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;46, Index: 168, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,892 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;47, Index: 169, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,894 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;48, Index: 170, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,897 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;49, Index: 171, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,899 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;50, Index: 172, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,900 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;51, Index: 173, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,901 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;52, Index: 174, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,903 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;53, Index: 175, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,905 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;54, Index: 176, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,906 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_ln;55, Index: 177, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,907 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_0;1, Index: 178, Shape: [127  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,908 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.activation.ReLU_1;;__main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_0;1, Index: 179, Shape: [127  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,909 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_2;1, Index: 180, Shape: [127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,910 - INFO - Name: __main__.TransModel;;__main__.TransModel/torch.nn.modules.container.Sequential_ff/torch.nn.modules.linear.Linear_2;1, Index: 181, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,911 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;, Index: 182, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,912 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;1, Index: 183, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,914 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;2, Index: 184, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,915 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;3, Index: 185, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,917 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;4, Index: 186, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,918 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;5, Index: 187, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,918 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;6, Index: 188, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,919 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;7, Index: 189, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,921 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;8, Index: 190, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,922 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;9, Index: 191, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,923 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;10, Index: 192, Shape: [  1 127   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,924 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;11, Index: 193, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,925 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;12, Index: 194, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,927 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;13, Index: 195, Shape: [  1 127  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,928 - INFO - Name: __main__.TransModel;41, Index: 196, Shape: [ 1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,928 - INFO - Name: StatefulPartitionedCall:0, Index: 197, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,929 - INFO - Name: , Index: 198, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,930 - INFO - Name: , Index: 199, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,931 - INFO - Name: , Index: 200, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,933 - INFO - Name: , Index: 202, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,934 - INFO - Name: , Index: 203, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,936 - INFO - Name: , Index: 204, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,938 - INFO - Name: , Index: 212, Shape: [  4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,939 - INFO - Name: BatchMatMul_scratch_buffer, Index: 213, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,941 - INFO - Name: , Index: 219, Shape: [  4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,942 - INFO - Name: BatchMatMul_scratch_buffer, Index: 220, Shape: [  4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,943 - INFO - Name: , Index: 232, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,944 - INFO - Name: , Index: 233, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,945 - INFO - Name: , Index: 234, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,946 - INFO - Name: , Index: 236, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,947 - INFO - Name: , Index: 237, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,948 - INFO - Name: , Index: 238, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,950 - INFO - Name: , Index: 252, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,950 - INFO - Name: , Index: 253, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,951 - INFO - Name: , Index: 254, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,952 - INFO - Name: , Index: 256, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,955 - INFO - Name: , Index: 257, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,956 - INFO - Name: , Index: 258, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,957 - INFO - Name: , Index: 266, Shape: [  4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,959 - INFO - Name: BatchMatMul_scratch_buffer, Index: 267, Shape: [  4 127   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,959 - INFO - Name: , Index: 273, Shape: [  4 127 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,960 - INFO - Name: BatchMatMul_scratch_buffer, Index: 274, Shape: [  4   8 127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,961 - INFO - Name: , Index: 286, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,962 - INFO - Name: , Index: 287, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,963 - INFO - Name: , Index: 288, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,964 - INFO - Name: , Index: 290, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,965 - INFO - Name: , Index: 291, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,966 - INFO - Name: , Index: 292, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,968 - INFO - Name: , Index: 306, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,969 - INFO - Name: , Index: 307, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,972 - INFO - Name: , Index: 308, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,973 - INFO - Name: , Index: 310, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,977 - INFO - Name: , Index: 311, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,978 - INFO - Name: , Index: 312, Shape: [127], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,979 - INFO - Name: , Index: 314, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,980 - INFO - Name: , Index: 315, Shape: [1], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:58,981 - INFO - Name: , Index: 316, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,982 - INFO - Name: Conv_hwcn_weights, Index: 324, Shape: [24 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:58,983 - INFO - \n",
      "Operations:\n",
      "2025-04-30 16:50:58,984 - INFO - Type: RESHAPE, Inputs: [ 0 57], Outputs: [58]\n",
      "2025-04-30 16:50:58,986 - INFO - Type: TRANSPOSE, Inputs: [58 39], Outputs: [59]\n",
      "2025-04-30 16:50:58,987 - INFO - Type: PAD, Inputs: [59 27], Outputs: [60]\n",
      "2025-04-30 16:50:58,996 - INFO - Type: CONV_2D, Inputs: [60 18 42], Outputs: [61]\n",
      "2025-04-30 16:50:58,997 - INFO - Type: TRANSPOSE, Inputs: [61 38], Outputs: [62]\n",
      "2025-04-30 16:50:59,002 - INFO - Type: RESHAPE, Inputs: [62 17], Outputs: [63]\n",
      "2025-04-30 16:50:59,002 - INFO - Type: ADD, Inputs: [63 26], Outputs: [64]\n",
      "2025-04-30 16:50:59,003 - INFO - Type: SUB, Inputs: [64 24], Outputs: [65]\n",
      "2025-04-30 16:50:59,004 - INFO - Type: MUL, Inputs: [65 25], Outputs: [66]\n",
      "2025-04-30 16:50:59,005 - INFO - Type: MUL, Inputs: [66 23], Outputs: [67]\n",
      "2025-04-30 16:50:59,006 - INFO - Type: ADD, Inputs: [67 22], Outputs: [68]\n",
      "2025-04-30 16:50:59,007 - INFO - Type: TRANSPOSE, Inputs: [68 37], Outputs: [69]\n",
      "2025-04-30 16:50:59,008 - INFO - Type: MEAN, Inputs: [69 44], Outputs: [70]\n",
      "2025-04-30 16:50:59,010 - INFO - Type: RESHAPE, Inputs: [70 41], Outputs: [71]\n",
      "2025-04-30 16:50:59,011 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [69 71], Outputs: [72]\n",
      "2025-04-30 16:50:59,013 - INFO - Type: MEAN, Inputs: [72 44], Outputs: [73]\n",
      "2025-04-30 16:50:59,014 - INFO - Type: ADD, Inputs: [73 45], Outputs: [74]\n",
      "2025-04-30 16:50:59,014 - INFO - Type: RSQRT, Inputs: [74], Outputs: [75]\n",
      "2025-04-30 16:50:59,016 - INFO - Type: MUL, Inputs: [75 70], Outputs: [76]\n",
      "2025-04-30 16:50:59,018 - INFO - Type: SUB, Inputs: [43 76], Outputs: [77]\n",
      "2025-04-30 16:50:59,019 - INFO - Type: RESHAPE, Inputs: [75 41], Outputs: [78]\n",
      "2025-04-30 16:50:59,020 - INFO - Type: MUL, Inputs: [69 78], Outputs: [79]\n",
      "2025-04-30 16:50:59,023 - INFO - Type: RESHAPE, Inputs: [77 41], Outputs: [80]\n",
      "2025-04-30 16:50:59,025 - INFO - Type: ADD, Inputs: [79 80], Outputs: [81]\n",
      "2025-04-30 16:50:59,026 - INFO - Type: MUL, Inputs: [81 53], Outputs: [82]\n",
      "2025-04-30 16:50:59,027 - INFO - Type: ADD, Inputs: [82 54], Outputs: [83]\n",
      "2025-04-30 16:50:59,028 - INFO - Type: FULLY_CONNECTED, Inputs: [83 12 -1], Outputs: [84]\n",
      "2025-04-30 16:50:59,034 - INFO - Type: RESHAPE, Inputs: [84 19], Outputs: [85]\n",
      "2025-04-30 16:50:59,040 - INFO - Type: TRANSPOSE, Inputs: [85 36], Outputs: [86]\n",
      "2025-04-30 16:50:59,042 - INFO - Type: SLICE, Inputs: [86 16 15], Outputs: [87]\n",
      "2025-04-30 16:50:59,043 - INFO - Type: RESHAPE, Inputs: [87 35], Outputs: [88]\n",
      "2025-04-30 16:50:59,044 - INFO - Type: SLICE, Inputs: [86 14 15], Outputs: [89]\n",
      "2025-04-30 16:50:59,045 - INFO - Type: RESHAPE, Inputs: [89 35], Outputs: [90]\n",
      "2025-04-30 16:50:59,047 - INFO - Type: SLICE, Inputs: [86 13 15], Outputs: [91]\n",
      "2025-04-30 16:50:59,048 - INFO - Type: MUL, Inputs: [88 46], Outputs: [92]\n",
      "2025-04-30 16:50:59,048 - INFO - Type: MUL, Inputs: [90 46], Outputs: [93]\n",
      "2025-04-30 16:50:59,049 - INFO - Type: TRANSPOSE, Inputs: [93 34], Outputs: [94]\n",
      "2025-04-30 16:50:59,050 - INFO - Type: RESHAPE, Inputs: [92 33], Outputs: [95]\n",
      "2025-04-30 16:50:59,052 - INFO - Type: RESHAPE, Inputs: [94 32], Outputs: [96]\n",
      "2025-04-30 16:50:59,053 - INFO - Type: BATCH_MATMUL, Inputs: [95 96], Outputs: [97]\n",
      "2025-04-30 16:50:59,054 - INFO - Type: RESHAPE, Inputs: [97 31], Outputs: [98]\n",
      "2025-04-30 16:50:59,055 - INFO - Type: SOFTMAX, Inputs: [98], Outputs: [99]\n",
      "2025-04-30 16:50:59,059 - INFO - Type: RESHAPE, Inputs: [99 30], Outputs: [100]\n",
      "2025-04-30 16:50:59,060 - INFO - Type: RESHAPE, Inputs: [91 33], Outputs: [101]\n",
      "2025-04-30 16:50:59,061 - INFO - Type: BATCH_MATMUL, Inputs: [100 101], Outputs: [102]\n",
      "2025-04-30 16:50:59,062 - INFO - Type: RESHAPE, Inputs: [102  35], Outputs: [103]\n",
      "2025-04-30 16:50:59,063 - INFO - Type: TRANSPOSE, Inputs: [103  29], Outputs: [104]\n",
      "2025-04-30 16:50:59,064 - INFO - Type: RESHAPE, Inputs: [104  28], Outputs: [105]\n",
      "2025-04-30 16:50:59,066 - INFO - Type: FULLY_CONNECTED, Inputs: [105  11  -1], Outputs: [106]\n",
      "2025-04-30 16:50:59,069 - INFO - Type: ADD, Inputs: [ 69 106], Outputs: [107]\n",
      "2025-04-30 16:50:59,070 - INFO - Type: MEAN, Inputs: [107  44], Outputs: [108]\n",
      "2025-04-30 16:50:59,071 - INFO - Type: RESHAPE, Inputs: [108  41], Outputs: [109]\n",
      "2025-04-30 16:50:59,072 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [107 109], Outputs: [110]\n",
      "2025-04-30 16:50:59,074 - INFO - Type: MEAN, Inputs: [110  44], Outputs: [111]\n",
      "2025-04-30 16:50:59,076 - INFO - Type: ADD, Inputs: [111  45], Outputs: [112]\n",
      "2025-04-30 16:50:59,078 - INFO - Type: RSQRT, Inputs: [112], Outputs: [113]\n",
      "2025-04-30 16:50:59,079 - INFO - Type: MUL, Inputs: [113 108], Outputs: [114]\n",
      "2025-04-30 16:50:59,080 - INFO - Type: SUB, Inputs: [ 43 114], Outputs: [115]\n",
      "2025-04-30 16:50:59,082 - INFO - Type: RESHAPE, Inputs: [113  41], Outputs: [116]\n",
      "2025-04-30 16:50:59,084 - INFO - Type: MUL, Inputs: [107 116], Outputs: [117]\n",
      "2025-04-30 16:50:59,086 - INFO - Type: RESHAPE, Inputs: [115  41], Outputs: [118]\n",
      "2025-04-30 16:50:59,089 - INFO - Type: ADD, Inputs: [117 118], Outputs: [119]\n",
      "2025-04-30 16:50:59,090 - INFO - Type: MUL, Inputs: [119  55], Outputs: [120]\n",
      "2025-04-30 16:50:59,092 - INFO - Type: ADD, Inputs: [120  56], Outputs: [121]\n",
      "2025-04-30 16:50:59,094 - INFO - Type: FULLY_CONNECTED, Inputs: [121  10  -1], Outputs: [122]\n",
      "2025-04-30 16:50:59,095 - INFO - Type: ADD, Inputs: [122  21], Outputs: [123]\n",
      "2025-04-30 16:50:59,096 - INFO - Type: FULLY_CONNECTED, Inputs: [123   9   4], Outputs: [124]\n",
      "2025-04-30 16:50:59,097 - INFO - Type: ADD, Inputs: [107 124], Outputs: [125]\n",
      "2025-04-30 16:50:59,098 - INFO - Type: MEAN, Inputs: [125  44], Outputs: [126]\n",
      "2025-04-30 16:50:59,101 - INFO - Type: RESHAPE, Inputs: [126  41], Outputs: [127]\n",
      "2025-04-30 16:50:59,103 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [125 127], Outputs: [128]\n",
      "2025-04-30 16:50:59,105 - INFO - Type: MEAN, Inputs: [128  44], Outputs: [129]\n",
      "2025-04-30 16:50:59,107 - INFO - Type: ADD, Inputs: [129  45], Outputs: [130]\n",
      "2025-04-30 16:50:59,108 - INFO - Type: RSQRT, Inputs: [130], Outputs: [131]\n",
      "2025-04-30 16:50:59,110 - INFO - Type: MUL, Inputs: [131 126], Outputs: [132]\n",
      "2025-04-30 16:50:59,111 - INFO - Type: SUB, Inputs: [ 43 132], Outputs: [133]\n",
      "2025-04-30 16:50:59,113 - INFO - Type: RESHAPE, Inputs: [131  41], Outputs: [134]\n",
      "2025-04-30 16:50:59,114 - INFO - Type: MUL, Inputs: [125 134], Outputs: [135]\n",
      "2025-04-30 16:50:59,116 - INFO - Type: RESHAPE, Inputs: [133  41], Outputs: [136]\n",
      "2025-04-30 16:50:59,118 - INFO - Type: ADD, Inputs: [135 136], Outputs: [137]\n",
      "2025-04-30 16:50:59,119 - INFO - Type: MUL, Inputs: [137  47], Outputs: [138]\n",
      "2025-04-30 16:50:59,120 - INFO - Type: ADD, Inputs: [138  48], Outputs: [139]\n",
      "2025-04-30 16:50:59,123 - INFO - Type: FULLY_CONNECTED, Inputs: [139   8  -1], Outputs: [140]\n",
      "2025-04-30 16:50:59,125 - INFO - Type: RESHAPE, Inputs: [140  19], Outputs: [141]\n",
      "2025-04-30 16:50:59,126 - INFO - Type: TRANSPOSE, Inputs: [141  36], Outputs: [142]\n",
      "2025-04-30 16:50:59,126 - INFO - Type: SLICE, Inputs: [142  16  15], Outputs: [143]\n",
      "2025-04-30 16:50:59,127 - INFO - Type: RESHAPE, Inputs: [143  35], Outputs: [144]\n",
      "2025-04-30 16:50:59,129 - INFO - Type: SLICE, Inputs: [142  14  15], Outputs: [145]\n",
      "2025-04-30 16:50:59,130 - INFO - Type: RESHAPE, Inputs: [145  35], Outputs: [146]\n",
      "2025-04-30 16:50:59,131 - INFO - Type: SLICE, Inputs: [142  13  15], Outputs: [147]\n",
      "2025-04-30 16:50:59,131 - INFO - Type: MUL, Inputs: [144  46], Outputs: [148]\n",
      "2025-04-30 16:50:59,132 - INFO - Type: MUL, Inputs: [146  46], Outputs: [149]\n",
      "2025-04-30 16:50:59,134 - INFO - Type: TRANSPOSE, Inputs: [149  34], Outputs: [150]\n",
      "2025-04-30 16:50:59,137 - INFO - Type: RESHAPE, Inputs: [148  33], Outputs: [151]\n",
      "2025-04-30 16:50:59,139 - INFO - Type: RESHAPE, Inputs: [150  32], Outputs: [152]\n",
      "2025-04-30 16:50:59,140 - INFO - Type: BATCH_MATMUL, Inputs: [151 152], Outputs: [153]\n",
      "2025-04-30 16:50:59,141 - INFO - Type: RESHAPE, Inputs: [153  31], Outputs: [154]\n",
      "2025-04-30 16:50:59,142 - INFO - Type: SOFTMAX, Inputs: [154], Outputs: [155]\n",
      "2025-04-30 16:50:59,143 - INFO - Type: RESHAPE, Inputs: [155  30], Outputs: [156]\n",
      "2025-04-30 16:50:59,144 - INFO - Type: RESHAPE, Inputs: [147  33], Outputs: [157]\n",
      "2025-04-30 16:50:59,145 - INFO - Type: BATCH_MATMUL, Inputs: [156 157], Outputs: [158]\n",
      "2025-04-30 16:50:59,146 - INFO - Type: RESHAPE, Inputs: [158  35], Outputs: [159]\n",
      "2025-04-30 16:50:59,147 - INFO - Type: TRANSPOSE, Inputs: [159  29], Outputs: [160]\n",
      "2025-04-30 16:50:59,147 - INFO - Type: RESHAPE, Inputs: [160  28], Outputs: [161]\n",
      "2025-04-30 16:50:59,149 - INFO - Type: FULLY_CONNECTED, Inputs: [161   7  -1], Outputs: [162]\n",
      "2025-04-30 16:50:59,150 - INFO - Type: ADD, Inputs: [125 162], Outputs: [163]\n",
      "2025-04-30 16:50:59,151 - INFO - Type: MEAN, Inputs: [163  44], Outputs: [164]\n",
      "2025-04-30 16:50:59,152 - INFO - Type: RESHAPE, Inputs: [164  41], Outputs: [165]\n",
      "2025-04-30 16:50:59,153 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [163 165], Outputs: [166]\n",
      "2025-04-30 16:50:59,153 - INFO - Type: MEAN, Inputs: [166  44], Outputs: [167]\n",
      "2025-04-30 16:50:59,154 - INFO - Type: ADD, Inputs: [167  45], Outputs: [168]\n",
      "2025-04-30 16:50:59,154 - INFO - Type: RSQRT, Inputs: [168], Outputs: [169]\n",
      "2025-04-30 16:50:59,155 - INFO - Type: MUL, Inputs: [169 164], Outputs: [170]\n",
      "2025-04-30 16:50:59,156 - INFO - Type: SUB, Inputs: [ 43 170], Outputs: [171]\n",
      "2025-04-30 16:50:59,157 - INFO - Type: RESHAPE, Inputs: [169  41], Outputs: [172]\n",
      "2025-04-30 16:50:59,157 - INFO - Type: MUL, Inputs: [163 172], Outputs: [173]\n",
      "2025-04-30 16:50:59,159 - INFO - Type: RESHAPE, Inputs: [171  41], Outputs: [174]\n",
      "2025-04-30 16:50:59,159 - INFO - Type: ADD, Inputs: [173 174], Outputs: [175]\n",
      "2025-04-30 16:50:59,161 - INFO - Type: MUL, Inputs: [175  49], Outputs: [176]\n",
      "2025-04-30 16:50:59,162 - INFO - Type: ADD, Inputs: [176  50], Outputs: [177]\n",
      "2025-04-30 16:50:59,163 - INFO - Type: FULLY_CONNECTED, Inputs: [177   6  -1], Outputs: [178]\n",
      "2025-04-30 16:50:59,164 - INFO - Type: ADD, Inputs: [178  20], Outputs: [179]\n",
      "2025-04-30 16:50:59,165 - INFO - Type: FULLY_CONNECTED, Inputs: [179   5   3], Outputs: [180]\n",
      "2025-04-30 16:50:59,168 - INFO - Type: ADD, Inputs: [163 180], Outputs: [181]\n",
      "2025-04-30 16:50:59,169 - INFO - Type: MEAN, Inputs: [181  44], Outputs: [182]\n",
      "2025-04-30 16:50:59,169 - INFO - Type: RESHAPE, Inputs: [182  41], Outputs: [183]\n",
      "2025-04-30 16:50:59,170 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [181 183], Outputs: [184]\n",
      "2025-04-30 16:50:59,171 - INFO - Type: MEAN, Inputs: [184  44], Outputs: [185]\n",
      "2025-04-30 16:50:59,172 - INFO - Type: ADD, Inputs: [185  45], Outputs: [186]\n",
      "2025-04-30 16:50:59,173 - INFO - Type: RSQRT, Inputs: [186], Outputs: [187]\n",
      "2025-04-30 16:50:59,174 - INFO - Type: MUL, Inputs: [187 182], Outputs: [188]\n",
      "2025-04-30 16:50:59,175 - INFO - Type: SUB, Inputs: [ 43 188], Outputs: [189]\n",
      "2025-04-30 16:50:59,175 - INFO - Type: RESHAPE, Inputs: [187  41], Outputs: [190]\n",
      "2025-04-30 16:50:59,176 - INFO - Type: MUL, Inputs: [181 190], Outputs: [191]\n",
      "2025-04-30 16:50:59,177 - INFO - Type: RESHAPE, Inputs: [189  41], Outputs: [192]\n",
      "2025-04-30 16:50:59,178 - INFO - Type: ADD, Inputs: [191 192], Outputs: [193]\n",
      "2025-04-30 16:50:59,178 - INFO - Type: MUL, Inputs: [193  51], Outputs: [194]\n",
      "2025-04-30 16:50:59,179 - INFO - Type: ADD, Inputs: [194  52], Outputs: [195]\n",
      "2025-04-30 16:50:59,180 - INFO - Type: SUM, Inputs: [195  40], Outputs: [196]\n",
      "2025-04-30 16:50:59,181 - INFO - Type: FULLY_CONNECTED, Inputs: [196   1   2], Outputs: [197]\n",
      "2025-04-30 16:50:59,182 - INFO - Type: DELEGATE, Inputs: [ 0 17 18 22 23 24 25 26 27 37 38 39 42 57], Outputs: [69]\n",
      "2025-04-30 16:50:59,183 - INFO - Type: DELEGATE, Inputs: [41 69 70], Outputs: [72]\n",
      "2025-04-30 16:50:59,185 - INFO - Type: DELEGATE, Inputs: [45 73], Outputs: [74]\n",
      "2025-04-30 16:50:59,185 - INFO - Type: DELEGATE, Inputs: [12 13 14 15 16 19 32 33 34 35 36 41 43 46 53 54 69 70 75], Outputs: [ 95  96 101]\n",
      "2025-04-30 16:50:59,187 - INFO - Type: DELEGATE, Inputs: [30 31 97], Outputs: [100]\n",
      "2025-04-30 16:50:59,188 - INFO - Type: DELEGATE, Inputs: [ 11  28  29  35  69 102], Outputs: [107]\n",
      "2025-04-30 16:50:59,188 - INFO - Type: DELEGATE, Inputs: [ 41 107 108], Outputs: [110]\n",
      "2025-04-30 16:50:59,189 - INFO - Type: DELEGATE, Inputs: [ 45 111], Outputs: [112]\n",
      "2025-04-30 16:50:59,190 - INFO - Type: DELEGATE, Inputs: [  4   9  10  21  41  43  55  56 107 108 113], Outputs: [125]\n",
      "2025-04-30 16:50:59,191 - INFO - Type: DELEGATE, Inputs: [ 41 125 126], Outputs: [128]\n",
      "2025-04-30 16:50:59,192 - INFO - Type: DELEGATE, Inputs: [ 45 129], Outputs: [130]\n",
      "2025-04-30 16:50:59,193 - INFO - Type: DELEGATE, Inputs: [  8  13  14  15  16  19  32  33  34  35  36  41  43  46  47  48 125 126\n",
      " 131], Outputs: [151 152 157]\n",
      "2025-04-30 16:50:59,194 - INFO - Type: DELEGATE, Inputs: [ 30  31 153], Outputs: [156]\n",
      "2025-04-30 16:50:59,196 - INFO - Type: DELEGATE, Inputs: [  7  28  29  35 125 158], Outputs: [163]\n",
      "2025-04-30 16:50:59,197 - INFO - Type: DELEGATE, Inputs: [ 41 163 164], Outputs: [166]\n",
      "2025-04-30 16:50:59,198 - INFO - Type: DELEGATE, Inputs: [ 45 167], Outputs: [168]\n",
      "2025-04-30 16:50:59,199 - INFO - Type: DELEGATE, Inputs: [  3   5   6  20  41  43  49  50 163 164 169], Outputs: [181]\n",
      "2025-04-30 16:50:59,201 - INFO - Type: DELEGATE, Inputs: [ 41 181 182], Outputs: [184]\n",
      "2025-04-30 16:50:59,202 - INFO - Type: DELEGATE, Inputs: [ 45 185], Outputs: [186]\n",
      "2025-04-30 16:50:59,203 - INFO - Type: DELEGATE, Inputs: [ 41  43  51  52 181 182 187], Outputs: [195]\n",
      "2025-04-30 16:50:59,204 - INFO - Type: DELEGATE, Inputs: [  1   2 196], Outputs: [197]\n",
      "2025-04-30 16:50:59,204 - INFO - \n",
      "Model Metadata:\n",
      "2025-04-30 16:50:59,223 - WARNING - tflite_support module not found. Metadata extraction skipped.\n",
      "2025-04-30 16:50:59,224 - INFO - \n",
      "Signatures:\n",
      "2025-04-30 16:50:59,225 - INFO - Signature Name: serving_default, Details: {'inputs': ['args_0'], 'outputs': ['output_0']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    tflite_model_path = \"time_series_transformer.tflite\"  # Replace with your .tflite file path\n",
    "    print_tflite_info(tflite_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0404d2a-93c8-4c6d-8ac2-8b4272a0ca93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 16:50:49,865 - INFO - TFLite model loaded successfully.\n",
      "2025-04-30 16:50:49,868 - INFO - Model File Size: 0.14 MB\n",
      "2025-04-30 16:50:49,870 - INFO - \n",
      "Input Tensors:\n",
      "2025-04-30 16:50:49,873 - INFO - Name: serving_default_args_0:0, Index: 0, Shape: [  1 128   4], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,874 - INFO - \n",
      "Output Tensors:\n",
      "2025-04-30 16:50:49,876 - INFO - Name: StatefulPartitionedCall:0, Index: 272, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,878 - INFO - \n",
      "All Tensors:\n",
      "2025-04-30 16:50:49,881 - INFO - Name: serving_default_args_0:0, Index: 0, Shape: [  1 128   4], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,882 - INFO - Name: arith.constant, Index: 1, Shape: [1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,883 - INFO - Name: arith.constant1, Index: 2, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,884 - INFO - Name: arith.constant2, Index: 3, Shape: [96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,886 - INFO - Name: arith.constant3, Index: 4, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,887 - INFO - Name: arith.constant4, Index: 5, Shape: [96 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,888 - INFO - Name: arith.constant5, Index: 6, Shape: [96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,890 - INFO - Name: arith.constant6, Index: 7, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,891 - INFO - Name: arith.constant7, Index: 8, Shape: [96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,892 - INFO - Name: arith.constant8, Index: 9, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,893 - INFO - Name: arith.constant9, Index: 10, Shape: [96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,894 - INFO - Name: arith.constant10, Index: 11, Shape: [ 1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,895 - INFO - Name: arith.constant11, Index: 12, Shape: [32 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,896 - INFO - Name: arith.constant12, Index: 13, Shape: [64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,897 - INFO - Name: arith.constant13, Index: 14, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,898 - INFO - Name: arith.constant14, Index: 15, Shape: [96 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,899 - INFO - Name: arith.constant15, Index: 16, Shape: [32 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,900 - INFO - Name: arith.constant16, Index: 17, Shape: [64 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,902 - INFO - Name: arith.constant17, Index: 18, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,904 - INFO - Name: arith.constant18, Index: 19, Shape: [96 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,906 - INFO - Name: arith.constant19, Index: 20, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,908 - INFO - Name: arith.constant20, Index: 21, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,910 - INFO - Name: arith.constant21, Index: 22, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,914 - INFO - Name: arith.constant22, Index: 23, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,916 - INFO - Name: arith.constant23, Index: 24, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,919 - INFO - Name: arith.constant24, Index: 25, Shape: [32  8  1  4], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,920 - INFO - Name: arith.constant25, Index: 26, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,921 - INFO - Name: arith.constant26, Index: 27, Shape: [ 1 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,922 - INFO - Name: arith.constant27, Index: 28, Shape: [ 1 64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,926 - INFO - Name: arith.constant28, Index: 29, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,929 - INFO - Name: arith.constant29, Index: 30, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,930 - INFO - Name: arith.constant30, Index: 31, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,931 - INFO - Name: arith.constant31, Index: 32, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,933 - INFO - Name: arith.constant32, Index: 33, Shape: [ 1 32  1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,939 - INFO - Name: arith.constant33, Index: 34, Shape: [4 2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,940 - INFO - Name: arith.constant34, Index: 35, Shape: [3 2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,942 - INFO - Name: arith.constant35, Index: 36, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,944 - INFO - Name: arith.constant36, Index: 37, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,946 - INFO - Name: arith.constant37, Index: 38, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,947 - INFO - Name: arith.constant38, Index: 39, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,950 - INFO - Name: arith.constant39, Index: 40, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,951 - INFO - Name: arith.constant40, Index: 41, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,953 - INFO - Name: arith.constant41, Index: 42, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,954 - INFO - Name: arith.constant42, Index: 43, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,956 - INFO - Name: arith.constant43, Index: 44, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,957 - INFO - Name: arith.constant44, Index: 45, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,958 - INFO - Name: arith.constant45, Index: 46, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,959 - INFO - Name: arith.constant46, Index: 47, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,960 - INFO - Name: arith.constant47, Index: 48, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,961 - INFO - Name: arith.constant48, Index: 49, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,962 - INFO - Name: arith.constant49, Index: 50, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,963 - INFO - Name: arith.constant50, Index: 51, Shape: [5], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,964 - INFO - Name: arith.constant51, Index: 52, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,966 - INFO - Name: arith.constant52, Index: 53, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,967 - INFO - Name: arith.constant53, Index: 54, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,969 - INFO - Name: arith.constant54, Index: 55, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,971 - INFO - Name: arith.constant55, Index: 56, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,972 - INFO - Name: arith.constant56, Index: 57, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,973 - INFO - Name: arith.constant57, Index: 58, Shape: [4], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,975 - INFO - Name: arith.constant58, Index: 59, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:49,977 - INFO - Name: arith.constant59, Index: 60, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,978 - INFO - Name: arith.constant60, Index: 61, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,980 - INFO - Name: arith.constant61, Index: 62, Shape: [], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,981 - INFO - Name: XlaCallModule/ReadVariableOp_12;StatefulPartitionedCall, Index: 63, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,983 - INFO - Name: XlaCallModule/ReadVariableOp_13;StatefulPartitionedCall, Index: 64, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,984 - INFO - Name: XlaCallModule/ReadVariableOp_24;StatefulPartitionedCall, Index: 65, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,986 - INFO - Name: XlaCallModule/ReadVariableOp_25;StatefulPartitionedCall, Index: 66, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,987 - INFO - Name: XlaCallModule/ReadVariableOp_26;StatefulPartitionedCall, Index: 67, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,989 - INFO - Name: XlaCallModule/ReadVariableOp_27;StatefulPartitionedCall, Index: 68, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,990 - INFO - Name: XlaCallModule/ReadVariableOp_28;StatefulPartitionedCall, Index: 69, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,992 - INFO - Name: XlaCallModule/ReadVariableOp_29;StatefulPartitionedCall, Index: 70, Shape: [32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,993 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;, Index: 71, Shape: [  1 129   4], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,995 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;1, Index: 72, Shape: [  1   4 129], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,996 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;2, Index: 73, Shape: [  1   4 129   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,998 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;3, Index: 74, Shape: [  1 129   1   4], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:49,999 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;4, Index: 75, Shape: [  1 135   1   4], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,001 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;5, Index: 76, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,003 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;6, Index: 77, Shape: [  1  32 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,004 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;7, Index: 78, Shape: [  1  32 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,005 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.conv.Conv1d_0;8, Index: 79, Shape: [  1  32 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,006 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;, Index: 80, Shape: [  1  32 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,007 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;1, Index: 81, Shape: [  1  32 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,008 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;2, Index: 82, Shape: [  1  32 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,010 - INFO - Name: __main__.TransModel/torch.nn.modules.container.Sequential_input_proj/torch.nn.modules.batchnorm.BatchNorm1d_1;3, Index: 83, Shape: [  1  32 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,011 - INFO - Name: __main__.TransModel;, Index: 84, Shape: [128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,012 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;, Index: 85, Shape: [128   1  96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,013 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;1, Index: 86, Shape: [  1 128   1   3  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,015 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;2, Index: 87, Shape: [  3 128   1   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,015 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;3, Index: 88, Shape: [  3 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,016 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;4, Index: 89, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,017 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;5, Index: 90, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,019 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;6, Index: 91, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,020 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;7, Index: 92, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,023 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;8, Index: 93, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,025 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;9, Index: 94, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,025 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;, Index: 95, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,027 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;1, Index: 96, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,029 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;10, Index: 97, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,030 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;11, Index: 98, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,032 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;12, Index: 99, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,033 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;13, Index: 100, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,035 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;14, Index: 101, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,036 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;15, Index: 102, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,037 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;16, Index: 103, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,039 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;17, Index: 104, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,040 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;18, Index: 105, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,041 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;, Index: 106, Shape: [128  96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,042 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;, Index: 107, Shape: [  1 128   1   3  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,043 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;1, Index: 108, Shape: [  3 128   1   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,045 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;2, Index: 109, Shape: [  3 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,046 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;3, Index: 110, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,047 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;4, Index: 111, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,049 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;5, Index: 112, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,050 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;6, Index: 113, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,051 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;7, Index: 114, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,052 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;, Index: 115, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,053 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;1, Index: 116, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,055 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;, Index: 117, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,056 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;2, Index: 118, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,057 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;3, Index: 119, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,059 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;1, Index: 120, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,061 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;2, Index: 121, Shape: [  1   4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,063 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;8, Index: 122, Shape: [  1   4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,064 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;9, Index: 123, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,066 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;10, Index: 124, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,067 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;11, Index: 125, Shape: [  1   4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,068 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;12, Index: 126, Shape: [  1   4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,070 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;13, Index: 127, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,071 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;14, Index: 128, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,073 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;15, Index: 129, Shape: [  1   4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,075 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;16, Index: 130, Shape: [128   1   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,076 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;17, Index: 131, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,078 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;, Index: 132, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,079 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;, Index: 133, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,081 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;18, Index: 134, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,082 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;19, Index: 135, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,084 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;20, Index: 136, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,085 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;21, Index: 137, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,086 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;22, Index: 138, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,087 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;23, Index: 139, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,088 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;24, Index: 140, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,090 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;25, Index: 141, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,091 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;26, Index: 142, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,093 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;27, Index: 143, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,095 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;28, Index: 144, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,096 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;29, Index: 145, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,099 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;30, Index: 146, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,100 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;XlaCallModule/ReadVariableOp_12;StatefulPartitionedCall, Index: 147, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,101 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;XlaCallModule/ReadVariableOp_12;StatefulPartitionedCall;XlaCallModule/ReadVariableOp_13, Index: 148, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,102 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;XlaCallModule/ReadVariableOp_12;StatefulPartitionedCall;XlaCallModule/ReadVariableOp_131, Index: 149, Shape: [128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,103 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;31, Index: 150, Shape: [128  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,104 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;3, Index: 151, Shape: [128  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,105 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;32, Index: 152, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,106 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;33, Index: 153, Shape: [128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,107 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;34, Index: 154, Shape: [128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,108 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;35, Index: 155, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,109 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;36, Index: 156, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,110 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;37, Index: 157, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,111 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;38, Index: 158, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,112 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;39, Index: 159, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,114 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;40, Index: 160, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,115 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;41, Index: 161, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,116 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;42, Index: 162, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,117 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;43, Index: 163, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,124 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;44, Index: 164, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,126 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;45, Index: 165, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,127 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;46, Index: 166, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,128 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;47, Index: 167, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,130 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_0;;XlaCallModule/ReadVariableOp_14;StatefulPartitionedCall;XlaCallModule/ReadVariableOp_15;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;, Index: 168, Shape: [  1 128  96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,131 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;19, Index: 169, Shape: [  1 128   1   3  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,132 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;20, Index: 170, Shape: [  3 128   1   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,133 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;21, Index: 171, Shape: [  3 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,133 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;22, Index: 172, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,134 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;23, Index: 173, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,136 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;24, Index: 174, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,137 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;25, Index: 175, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,138 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;26, Index: 176, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,139 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;27, Index: 177, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,140 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;2, Index: 178, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,142 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;3, Index: 179, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,144 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;28, Index: 180, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,146 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;29, Index: 181, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,147 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;30, Index: 182, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,148 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;31, Index: 183, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,149 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;32, Index: 184, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,150 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;33, Index: 185, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,151 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;34, Index: 186, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,153 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;35, Index: 187, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,154 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;36, Index: 188, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,156 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;, Index: 189, Shape: [128  96], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,157 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;, Index: 190, Shape: [  1 128   1   3  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,163 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;1, Index: 191, Shape: [  3 128   1   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,165 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;2, Index: 192, Shape: [  3 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,166 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;3, Index: 193, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,167 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;4, Index: 194, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,168 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;5, Index: 195, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,169 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;6, Index: 196, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,171 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;7, Index: 197, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,171 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;, Index: 198, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,172 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;1, Index: 199, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,174 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;, Index: 200, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,176 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;2, Index: 201, Shape: [  1 128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,177 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;3, Index: 202, Shape: [128   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,179 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;1, Index: 203, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,180 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;2, Index: 204, Shape: [  1   4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,181 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;8, Index: 205, Shape: [  1   4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,183 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;9, Index: 206, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,184 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;10, Index: 207, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,185 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;11, Index: 208, Shape: [  1   4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,187 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;12, Index: 209, Shape: [  1   4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,188 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;13, Index: 210, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,190 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;14, Index: 211, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,192 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;15, Index: 212, Shape: [  1   4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,193 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;16, Index: 213, Shape: [128   1   4   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,194 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;17, Index: 214, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,195 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;, Index: 215, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,195 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.activation.MultiheadAttention_self_attn;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;, Index: 216, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,196 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;18, Index: 217, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,197 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;19, Index: 218, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,198 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;20, Index: 219, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,198 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;21, Index: 220, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,200 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;22, Index: 221, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,201 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;23, Index: 222, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,202 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;24, Index: 223, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,203 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;25, Index: 224, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,204 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;26, Index: 225, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,205 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;27, Index: 226, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,206 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;28, Index: 227, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,207 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;29, Index: 228, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,208 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;30, Index: 229, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,210 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;XlaCallModule/ReadVariableOp_24;StatefulPartitionedCall, Index: 230, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,211 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;XlaCallModule/ReadVariableOp_24;StatefulPartitionedCall;XlaCallModule/ReadVariableOp_25, Index: 231, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,212 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;XlaCallModule/ReadVariableOp_24;StatefulPartitionedCall;XlaCallModule/ReadVariableOp_251, Index: 232, Shape: [128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,212 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;31, Index: 233, Shape: [128  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,213 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;__main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;3, Index: 234, Shape: [128  64], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,214 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;32, Index: 235, Shape: [128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,215 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;33, Index: 236, Shape: [128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,216 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;34, Index: 237, Shape: [128   1  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,217 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;35, Index: 238, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,218 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;36, Index: 239, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,219 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;37, Index: 240, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,220 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;38, Index: 241, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,221 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;39, Index: 242, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,223 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;40, Index: 243, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,224 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;41, Index: 244, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,225 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;42, Index: 245, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,226 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;43, Index: 246, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,227 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;44, Index: 247, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,228 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;45, Index: 248, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,229 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;46, Index: 249, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,230 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;47, Index: 250, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,231 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;XlaCallModule/ReadVariableOp_26;StatefulPartitionedCall, Index: 251, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,232 - INFO - Name: __main__.TransModel/__main__.TransformerEncoderWAttention_encoder/torch.nn.modules.transformer.TransformerEncoderLayer_1;;XlaCallModule/ReadVariableOp_26;StatefulPartitionedCall;XlaCallModule/ReadVariableOp_27, Index: 252, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,232 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;, Index: 253, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,233 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;1, Index: 254, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,235 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;2, Index: 255, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,237 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;3, Index: 256, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,237 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;4, Index: 257, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,238 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;5, Index: 258, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,239 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;6, Index: 259, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,240 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;7, Index: 260, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,241 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;8, Index: 261, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,242 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;9, Index: 262, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,243 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;10, Index: 263, Shape: [  1 128   1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,244 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;11, Index: 264, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,245 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;12, Index: 265, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,246 - INFO - Name: __main__.TransModel/torch.nn.modules.normalization.LayerNorm_temporal_norm;13, Index: 266, Shape: [  1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,247 - INFO - Name: __main__.TransModel;1, Index: 267, Shape: [  1  32 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,248 - INFO - Name: __main__.TransModel;2, Index: 268, Shape: [  1  32   1 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,249 - INFO - Name: __main__.TransModel;3, Index: 269, Shape: [  1   1 128  32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,250 - INFO - Name: __main__.TransModel;4, Index: 270, Shape: [ 1  1  1 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,251 - INFO - Name: __main__.TransModel/torch.nn.modules.linear.Linear_output;;__main__.TransModel;, Index: 271, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,254 - INFO - Name: StatefulPartitionedCall:0, Index: 272, Shape: [1 1], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,255 - INFO - Name: , Index: 279, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,255 - INFO - Name: BatchMatMul_scratch_buffer, Index: 280, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,256 - INFO - Name: , Index: 286, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,258 - INFO - Name: BatchMatMul_scratch_buffer, Index: 287, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,259 - INFO - Name: , Index: 311, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,260 - INFO - Name: BatchMatMul_scratch_buffer, Index: 312, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,261 - INFO - Name: , Index: 318, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,262 - INFO - Name: BatchMatMul_scratch_buffer, Index: 319, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,263 - INFO - Name: , Index: 331, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,264 - INFO - Name: , Index: 332, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,265 - INFO - Name: , Index: 333, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,265 - INFO - Name: , Index: 335, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,266 - INFO - Name: , Index: 336, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,267 - INFO - Name: , Index: 337, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,268 - INFO - Name: , Index: 351, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,269 - INFO - Name: , Index: 352, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,269 - INFO - Name: , Index: 353, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,270 - INFO - Name: , Index: 355, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,271 - INFO - Name: , Index: 356, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,272 - INFO - Name: , Index: 357, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,274 - INFO - Name: , Index: 365, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,275 - INFO - Name: BatchMatMul_scratch_buffer, Index: 366, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,276 - INFO - Name: , Index: 372, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,277 - INFO - Name: BatchMatMul_scratch_buffer, Index: 373, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,278 - INFO - Name: , Index: 397, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,279 - INFO - Name: BatchMatMul_scratch_buffer, Index: 398, Shape: [  4 128   8], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,280 - INFO - Name: , Index: 404, Shape: [  4 128 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,281 - INFO - Name: BatchMatMul_scratch_buffer, Index: 405, Shape: [  4   8 128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,282 - INFO - Name: , Index: 417, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,283 - INFO - Name: , Index: 418, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,284 - INFO - Name: , Index: 419, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,285 - INFO - Name: , Index: 421, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,286 - INFO - Name: , Index: 422, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,286 - INFO - Name: , Index: 423, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,287 - INFO - Name: , Index: 437, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,288 - INFO - Name: , Index: 438, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,289 - INFO - Name: , Index: 439, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,290 - INFO - Name: , Index: 441, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,292 - INFO - Name: , Index: 442, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,292 - INFO - Name: , Index: 443, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,293 - INFO - Name: , Index: 445, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,293 - INFO - Name: , Index: 446, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,295 - INFO - Name: , Index: 447, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,296 - INFO - Name: , Index: 449, Shape: [3], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,297 - INFO - Name: , Index: 450, Shape: [2], Dtype: <class 'numpy.int32'>, No quantization\n",
      "2025-04-30 16:50:50,297 - INFO - Name: , Index: 451, Shape: [128], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,298 - INFO - Name: Conv_hwcn_weights, Index: 459, Shape: [32 32], Dtype: <class 'numpy.float32'>, No quantization\n",
      "2025-04-30 16:50:50,299 - INFO - \n",
      "Operations:\n",
      "2025-04-30 16:50:50,300 - INFO - Type: PAD, Inputs: [ 0 35], Outputs: [71]\n",
      "2025-04-30 16:50:50,301 - INFO - Type: TRANSPOSE, Inputs: [71 53], Outputs: [72]\n",
      "2025-04-30 16:50:50,302 - INFO - Type: RESHAPE, Inputs: [72 26], Outputs: [73]\n",
      "2025-04-30 16:50:50,303 - INFO - Type: TRANSPOSE, Inputs: [73 58], Outputs: [74]\n",
      "2025-04-30 16:50:50,304 - INFO - Type: PAD, Inputs: [74 34], Outputs: [75]\n",
      "2025-04-30 16:50:50,305 - INFO - Type: CONV_2D, Inputs: [75 25 55], Outputs: [76]\n",
      "2025-04-30 16:50:50,306 - INFO - Type: TRANSPOSE, Inputs: [76 57], Outputs: [77]\n",
      "2025-04-30 16:50:50,307 - INFO - Type: RESHAPE, Inputs: [77 24], Outputs: [78]\n",
      "2025-04-30 16:50:50,314 - INFO - Type: ADD, Inputs: [78 33], Outputs: [79]\n",
      "2025-04-30 16:50:50,314 - INFO - Type: SUB, Inputs: [79 31], Outputs: [80]\n",
      "2025-04-30 16:50:50,315 - INFO - Type: MUL, Inputs: [80 32], Outputs: [81]\n",
      "2025-04-30 16:50:50,316 - INFO - Type: MUL, Inputs: [81 30], Outputs: [82]\n",
      "2025-04-30 16:50:50,317 - INFO - Type: ADD, Inputs: [82 29], Outputs: [83]\n",
      "2025-04-30 16:50:50,318 - INFO - Type: TRANSPOSE, Inputs: [83 52], Outputs: [84]\n",
      "2025-04-30 16:50:50,319 - INFO - Type: FULLY_CONNECTED, Inputs: [84 19 10], Outputs: [85]\n",
      "2025-04-30 16:50:50,319 - INFO - Type: RESHAPE, Inputs: [85 51], Outputs: [86]\n",
      "2025-04-30 16:50:50,320 - INFO - Type: TRANSPOSE, Inputs: [86 50], Outputs: [87]\n",
      "2025-04-30 16:50:50,320 - INFO - Type: RESHAPE, Inputs: [87 49], Outputs: [88]\n",
      "2025-04-30 16:50:50,321 - INFO - Type: SLICE, Inputs: [88 23 22], Outputs: [89]\n",
      "2025-04-30 16:50:50,322 - INFO - Type: SLICE, Inputs: [88 21 22], Outputs: [90]\n",
      "2025-04-30 16:50:50,323 - INFO - Type: SLICE, Inputs: [88 20 22], Outputs: [91]\n",
      "2025-04-30 16:50:50,324 - INFO - Type: RESHAPE, Inputs: [90 48], Outputs: [92]\n",
      "2025-04-30 16:50:50,325 - INFO - Type: RESHAPE, Inputs: [91 48], Outputs: [93]\n",
      "2025-04-30 16:50:50,326 - INFO - Type: TRANSPOSE, Inputs: [93 47], Outputs: [94]\n",
      "2025-04-30 16:50:50,327 - INFO - Type: MUL, Inputs: [89 62], Outputs: [95]\n",
      "2025-04-30 16:50:50,327 - INFO - Type: RESHAPE, Inputs: [95 48], Outputs: [96]\n",
      "2025-04-30 16:50:50,328 - INFO - Type: TRANSPOSE, Inputs: [96 47], Outputs: [97]\n",
      "2025-04-30 16:50:50,329 - INFO - Type: TRANSPOSE, Inputs: [92 46], Outputs: [98]\n",
      "2025-04-30 16:50:50,330 - INFO - Type: BATCH_MATMUL, Inputs: [97 98], Outputs: [99]\n",
      "2025-04-30 16:50:50,331 - INFO - Type: SOFTMAX, Inputs: [99], Outputs: [100]\n",
      "2025-04-30 16:50:50,332 - INFO - Type: BATCH_MATMUL, Inputs: [100  94], Outputs: [101]\n",
      "2025-04-30 16:50:50,333 - INFO - Type: TRANSPOSE, Inputs: [101  47], Outputs: [102]\n",
      "2025-04-30 16:50:50,334 - INFO - Type: RESHAPE, Inputs: [102  45], Outputs: [103]\n",
      "2025-04-30 16:50:50,334 - INFO - Type: FULLY_CONNECTED, Inputs: [103  18  -1], Outputs: [104]\n",
      "2025-04-30 16:50:50,335 - INFO - Type: FULLY_CONNECTED, Inputs: [103  18   9], Outputs: [105]\n",
      "2025-04-30 16:50:50,336 - INFO - Type: FULLY_CONNECTED, Inputs: [104  19   8], Outputs: [106]\n",
      "2025-04-30 16:50:50,337 - INFO - Type: RESHAPE, Inputs: [106  51], Outputs: [107]\n",
      "2025-04-30 16:50:50,338 - INFO - Type: TRANSPOSE, Inputs: [107  50], Outputs: [108]\n",
      "2025-04-30 16:50:50,339 - INFO - Type: RESHAPE, Inputs: [108  49], Outputs: [109]\n",
      "2025-04-30 16:50:50,340 - INFO - Type: SLICE, Inputs: [109  23  22], Outputs: [110]\n",
      "2025-04-30 16:50:50,341 - INFO - Type: SLICE, Inputs: [109  21  22], Outputs: [111]\n",
      "2025-04-30 16:50:50,342 - INFO - Type: SLICE, Inputs: [109  20  22], Outputs: [112]\n",
      "2025-04-30 16:50:50,343 - INFO - Type: RESHAPE, Inputs: [112  48], Outputs: [113]\n",
      "2025-04-30 16:50:50,344 - INFO - Type: TRANSPOSE, Inputs: [113  47], Outputs: [114]\n",
      "2025-04-30 16:50:50,345 - INFO - Type: MUL, Inputs: [110  61], Outputs: [115]\n",
      "2025-04-30 16:50:50,346 - INFO - Type: RESHAPE, Inputs: [115  48], Outputs: [116]\n",
      "2025-04-30 16:50:50,347 - INFO - Type: TRANSPOSE, Inputs: [116  47], Outputs: [117]\n",
      "2025-04-30 16:50:50,347 - INFO - Type: MUL, Inputs: [111  61], Outputs: [118]\n",
      "2025-04-30 16:50:50,348 - INFO - Type: RESHAPE, Inputs: [118  48], Outputs: [119]\n",
      "2025-04-30 16:50:50,349 - INFO - Type: TRANSPOSE, Inputs: [119  47], Outputs: [120]\n",
      "2025-04-30 16:50:50,354 - INFO - Type: RESHAPE, Inputs: [120  43], Outputs: [121]\n",
      "2025-04-30 16:50:50,359 - INFO - Type: TRANSPOSE, Inputs: [121  42], Outputs: [122]\n",
      "2025-04-30 16:50:50,360 - INFO - Type: RESHAPE, Inputs: [122  41], Outputs: [123]\n",
      "2025-04-30 16:50:50,361 - INFO - Type: BATCH_MATMUL, Inputs: [117 123], Outputs: [124]\n",
      "2025-04-30 16:50:50,362 - INFO - Type: RESHAPE, Inputs: [124  40], Outputs: [125]\n",
      "2025-04-30 16:50:50,363 - INFO - Type: SOFTMAX, Inputs: [125], Outputs: [126]\n",
      "2025-04-30 16:50:50,365 - INFO - Type: RESHAPE, Inputs: [126  39], Outputs: [127]\n",
      "2025-04-30 16:50:50,366 - INFO - Type: BATCH_MATMUL, Inputs: [127 114], Outputs: [128]\n",
      "2025-04-30 16:50:50,367 - INFO - Type: RESHAPE, Inputs: [128  43], Outputs: [129]\n",
      "2025-04-30 16:50:50,368 - INFO - Type: TRANSPOSE, Inputs: [129  38], Outputs: [130]\n",
      "2025-04-30 16:50:50,375 - INFO - Type: RESHAPE, Inputs: [130  45], Outputs: [131]\n",
      "2025-04-30 16:50:50,376 - INFO - Type: FULLY_CONNECTED, Inputs: [131  18   9], Outputs: [132]\n",
      "2025-04-30 16:50:50,377 - INFO - Type: ADD, Inputs: [105 132], Outputs: [133]\n",
      "2025-04-30 16:50:50,378 - INFO - Type: RESHAPE, Inputs: [133  37], Outputs: [134]\n",
      "2025-04-30 16:50:50,379 - INFO - Type: MEAN, Inputs: [134  59], Outputs: [135]\n",
      "2025-04-30 16:50:50,381 - INFO - Type: RESHAPE, Inputs: [135  54], Outputs: [136]\n",
      "2025-04-30 16:50:50,382 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [134 136], Outputs: [137]\n",
      "2025-04-30 16:50:50,383 - INFO - Type: MEAN, Inputs: [137  59], Outputs: [138]\n",
      "2025-04-30 16:50:50,383 - INFO - Type: ADD, Inputs: [138  60], Outputs: [139]\n",
      "2025-04-30 16:50:50,384 - INFO - Type: RSQRT, Inputs: [139], Outputs: [140]\n",
      "2025-04-30 16:50:50,391 - INFO - Type: MUL, Inputs: [140 135], Outputs: [141]\n",
      "2025-04-30 16:50:50,393 - INFO - Type: SUB, Inputs: [ 56 141], Outputs: [142]\n",
      "2025-04-30 16:50:50,394 - INFO - Type: RESHAPE, Inputs: [140  54], Outputs: [143]\n",
      "2025-04-30 16:50:50,395 - INFO - Type: MUL, Inputs: [134 143], Outputs: [144]\n",
      "2025-04-30 16:50:50,396 - INFO - Type: RESHAPE, Inputs: [142  54], Outputs: [145]\n",
      "2025-04-30 16:50:50,396 - INFO - Type: ADD, Inputs: [144 145], Outputs: [146]\n",
      "2025-04-30 16:50:50,397 - INFO - Type: MUL, Inputs: [146  63], Outputs: [147]\n",
      "2025-04-30 16:50:50,398 - INFO - Type: ADD, Inputs: [147  64], Outputs: [148]\n",
      "2025-04-30 16:50:50,399 - INFO - Type: RESHAPE, Inputs: [148  44], Outputs: [149]\n",
      "2025-04-30 16:50:50,400 - INFO - Type: FULLY_CONNECTED, Inputs: [148  17  -1], Outputs: [150]\n",
      "2025-04-30 16:50:50,401 - INFO - Type: ADD, Inputs: [150  28], Outputs: [151]\n",
      "2025-04-30 16:50:50,402 - INFO - Type: FULLY_CONNECTED, Inputs: [151  16   7], Outputs: [152]\n",
      "2025-04-30 16:50:50,403 - INFO - Type: RESHAPE, Inputs: [152  44], Outputs: [153]\n",
      "2025-04-30 16:50:50,403 - INFO - Type: ADD, Inputs: [149 153], Outputs: [154]\n",
      "2025-04-30 16:50:50,404 - INFO - Type: RESHAPE, Inputs: [154  37], Outputs: [155]\n",
      "2025-04-30 16:50:50,405 - INFO - Type: MEAN, Inputs: [155  59], Outputs: [156]\n",
      "2025-04-30 16:50:50,406 - INFO - Type: RESHAPE, Inputs: [156  54], Outputs: [157]\n",
      "2025-04-30 16:50:50,407 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [155 157], Outputs: [158]\n",
      "2025-04-30 16:50:50,408 - INFO - Type: MEAN, Inputs: [158  59], Outputs: [159]\n",
      "2025-04-30 16:50:50,409 - INFO - Type: ADD, Inputs: [159  60], Outputs: [160]\n",
      "2025-04-30 16:50:50,410 - INFO - Type: RSQRT, Inputs: [160], Outputs: [161]\n",
      "2025-04-30 16:50:50,410 - INFO - Type: MUL, Inputs: [161 156], Outputs: [162]\n",
      "2025-04-30 16:50:50,411 - INFO - Type: SUB, Inputs: [ 56 162], Outputs: [163]\n",
      "2025-04-30 16:50:50,412 - INFO - Type: RESHAPE, Inputs: [161  54], Outputs: [164]\n",
      "2025-04-30 16:50:50,413 - INFO - Type: MUL, Inputs: [155 164], Outputs: [165]\n",
      "2025-04-30 16:50:50,414 - INFO - Type: RESHAPE, Inputs: [163  54], Outputs: [166]\n",
      "2025-04-30 16:50:50,415 - INFO - Type: ADD, Inputs: [165 166], Outputs: [167]\n",
      "2025-04-30 16:50:50,416 - INFO - Type: FULLY_CONNECTED, Inputs: [167   5   6], Outputs: [168]\n",
      "2025-04-30 16:50:50,417 - INFO - Type: RESHAPE, Inputs: [168  51], Outputs: [169]\n",
      "2025-04-30 16:50:50,433 - INFO - Type: TRANSPOSE, Inputs: [169  50], Outputs: [170]\n",
      "2025-04-30 16:50:50,434 - INFO - Type: RESHAPE, Inputs: [170  49], Outputs: [171]\n",
      "2025-04-30 16:50:50,436 - INFO - Type: SLICE, Inputs: [171  23  22], Outputs: [172]\n",
      "2025-04-30 16:50:50,437 - INFO - Type: SLICE, Inputs: [171  21  22], Outputs: [173]\n",
      "2025-04-30 16:50:50,439 - INFO - Type: SLICE, Inputs: [171  20  22], Outputs: [174]\n",
      "2025-04-30 16:50:50,440 - INFO - Type: RESHAPE, Inputs: [173  48], Outputs: [175]\n",
      "2025-04-30 16:50:50,445 - INFO - Type: RESHAPE, Inputs: [174  48], Outputs: [176]\n",
      "2025-04-30 16:50:50,448 - INFO - Type: TRANSPOSE, Inputs: [176  47], Outputs: [177]\n",
      "2025-04-30 16:50:50,450 - INFO - Type: MUL, Inputs: [172  62], Outputs: [178]\n",
      "2025-04-30 16:50:50,451 - INFO - Type: RESHAPE, Inputs: [178  48], Outputs: [179]\n",
      "2025-04-30 16:50:50,453 - INFO - Type: TRANSPOSE, Inputs: [179  47], Outputs: [180]\n",
      "2025-04-30 16:50:50,454 - INFO - Type: TRANSPOSE, Inputs: [175  46], Outputs: [181]\n",
      "2025-04-30 16:50:50,455 - INFO - Type: BATCH_MATMUL, Inputs: [180 181], Outputs: [182]\n",
      "2025-04-30 16:50:50,457 - INFO - Type: SOFTMAX, Inputs: [182], Outputs: [183]\n",
      "2025-04-30 16:50:50,458 - INFO - Type: BATCH_MATMUL, Inputs: [183 177], Outputs: [184]\n",
      "2025-04-30 16:50:50,459 - INFO - Type: TRANSPOSE, Inputs: [184  47], Outputs: [185]\n",
      "2025-04-30 16:50:50,460 - INFO - Type: RESHAPE, Inputs: [185  45], Outputs: [186]\n",
      "2025-04-30 16:50:50,461 - INFO - Type: FULLY_CONNECTED, Inputs: [186  14  -1], Outputs: [187]\n",
      "2025-04-30 16:50:50,463 - INFO - Type: FULLY_CONNECTED, Inputs: [186  14   4], Outputs: [188]\n",
      "2025-04-30 16:50:50,464 - INFO - Type: FULLY_CONNECTED, Inputs: [187  15   3], Outputs: [189]\n",
      "2025-04-30 16:50:50,465 - INFO - Type: RESHAPE, Inputs: [189  51], Outputs: [190]\n",
      "2025-04-30 16:50:50,469 - INFO - Type: TRANSPOSE, Inputs: [190  50], Outputs: [191]\n",
      "2025-04-30 16:50:50,470 - INFO - Type: RESHAPE, Inputs: [191  49], Outputs: [192]\n",
      "2025-04-30 16:50:50,472 - INFO - Type: SLICE, Inputs: [192  23  22], Outputs: [193]\n",
      "2025-04-30 16:50:50,473 - INFO - Type: SLICE, Inputs: [192  21  22], Outputs: [194]\n",
      "2025-04-30 16:50:50,474 - INFO - Type: SLICE, Inputs: [192  20  22], Outputs: [195]\n",
      "2025-04-30 16:50:50,476 - INFO - Type: RESHAPE, Inputs: [195  48], Outputs: [196]\n",
      "2025-04-30 16:50:50,477 - INFO - Type: TRANSPOSE, Inputs: [196  47], Outputs: [197]\n",
      "2025-04-30 16:50:50,478 - INFO - Type: MUL, Inputs: [193  61], Outputs: [198]\n",
      "2025-04-30 16:50:50,479 - INFO - Type: RESHAPE, Inputs: [198  48], Outputs: [199]\n",
      "2025-04-30 16:50:50,480 - INFO - Type: TRANSPOSE, Inputs: [199  47], Outputs: [200]\n",
      "2025-04-30 16:50:50,481 - INFO - Type: MUL, Inputs: [194  61], Outputs: [201]\n",
      "2025-04-30 16:50:50,482 - INFO - Type: RESHAPE, Inputs: [201  48], Outputs: [202]\n",
      "2025-04-30 16:50:50,483 - INFO - Type: TRANSPOSE, Inputs: [202  47], Outputs: [203]\n",
      "2025-04-30 16:50:50,484 - INFO - Type: RESHAPE, Inputs: [203  43], Outputs: [204]\n",
      "2025-04-30 16:50:50,485 - INFO - Type: TRANSPOSE, Inputs: [204  42], Outputs: [205]\n",
      "2025-04-30 16:50:50,486 - INFO - Type: RESHAPE, Inputs: [205  41], Outputs: [206]\n",
      "2025-04-30 16:50:50,487 - INFO - Type: BATCH_MATMUL, Inputs: [200 206], Outputs: [207]\n",
      "2025-04-30 16:50:50,487 - INFO - Type: RESHAPE, Inputs: [207  40], Outputs: [208]\n",
      "2025-04-30 16:50:50,488 - INFO - Type: SOFTMAX, Inputs: [208], Outputs: [209]\n",
      "2025-04-30 16:50:50,489 - INFO - Type: RESHAPE, Inputs: [209  39], Outputs: [210]\n",
      "2025-04-30 16:50:50,489 - INFO - Type: BATCH_MATMUL, Inputs: [210 197], Outputs: [211]\n",
      "2025-04-30 16:50:50,490 - INFO - Type: RESHAPE, Inputs: [211  43], Outputs: [212]\n",
      "2025-04-30 16:50:50,491 - INFO - Type: TRANSPOSE, Inputs: [212  38], Outputs: [213]\n",
      "2025-04-30 16:50:50,491 - INFO - Type: RESHAPE, Inputs: [213  45], Outputs: [214]\n",
      "2025-04-30 16:50:50,492 - INFO - Type: FULLY_CONNECTED, Inputs: [214  14   4], Outputs: [215]\n",
      "2025-04-30 16:50:50,494 - INFO - Type: ADD, Inputs: [188 215], Outputs: [216]\n",
      "2025-04-30 16:50:50,496 - INFO - Type: RESHAPE, Inputs: [216  37], Outputs: [217]\n",
      "2025-04-30 16:50:50,496 - INFO - Type: MEAN, Inputs: [217  59], Outputs: [218]\n",
      "2025-04-30 16:50:50,498 - INFO - Type: RESHAPE, Inputs: [218  54], Outputs: [219]\n",
      "2025-04-30 16:50:50,499 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [217 219], Outputs: [220]\n",
      "2025-04-30 16:50:50,499 - INFO - Type: MEAN, Inputs: [220  59], Outputs: [221]\n",
      "2025-04-30 16:50:50,500 - INFO - Type: ADD, Inputs: [221  60], Outputs: [222]\n",
      "2025-04-30 16:50:50,502 - INFO - Type: RSQRT, Inputs: [222], Outputs: [223]\n",
      "2025-04-30 16:50:50,503 - INFO - Type: MUL, Inputs: [223 218], Outputs: [224]\n",
      "2025-04-30 16:50:50,503 - INFO - Type: SUB, Inputs: [ 56 224], Outputs: [225]\n",
      "2025-04-30 16:50:50,504 - INFO - Type: RESHAPE, Inputs: [223  54], Outputs: [226]\n",
      "2025-04-30 16:50:50,505 - INFO - Type: MUL, Inputs: [217 226], Outputs: [227]\n",
      "2025-04-30 16:50:50,506 - INFO - Type: RESHAPE, Inputs: [225  54], Outputs: [228]\n",
      "2025-04-30 16:50:50,507 - INFO - Type: ADD, Inputs: [227 228], Outputs: [229]\n",
      "2025-04-30 16:50:50,509 - INFO - Type: MUL, Inputs: [229  65], Outputs: [230]\n",
      "2025-04-30 16:50:50,510 - INFO - Type: ADD, Inputs: [230  66], Outputs: [231]\n",
      "2025-04-30 16:50:50,511 - INFO - Type: RESHAPE, Inputs: [231  44], Outputs: [232]\n",
      "2025-04-30 16:50:50,512 - INFO - Type: FULLY_CONNECTED, Inputs: [231  13  -1], Outputs: [233]\n",
      "2025-04-30 16:50:50,513 - INFO - Type: ADD, Inputs: [233  27], Outputs: [234]\n",
      "2025-04-30 16:50:50,514 - INFO - Type: FULLY_CONNECTED, Inputs: [234  12   2], Outputs: [235]\n",
      "2025-04-30 16:50:50,515 - INFO - Type: RESHAPE, Inputs: [235  44], Outputs: [236]\n",
      "2025-04-30 16:50:50,515 - INFO - Type: ADD, Inputs: [232 236], Outputs: [237]\n",
      "2025-04-30 16:50:50,516 - INFO - Type: RESHAPE, Inputs: [237  37], Outputs: [238]\n",
      "2025-04-30 16:50:50,518 - INFO - Type: MEAN, Inputs: [238  59], Outputs: [239]\n",
      "2025-04-30 16:50:50,519 - INFO - Type: RESHAPE, Inputs: [239  54], Outputs: [240]\n",
      "2025-04-30 16:50:50,520 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [238 240], Outputs: [241]\n",
      "2025-04-30 16:50:50,520 - INFO - Type: MEAN, Inputs: [241  59], Outputs: [242]\n",
      "2025-04-30 16:50:50,521 - INFO - Type: ADD, Inputs: [242  60], Outputs: [243]\n",
      "2025-04-30 16:50:50,521 - INFO - Type: RSQRT, Inputs: [243], Outputs: [244]\n",
      "2025-04-30 16:50:50,522 - INFO - Type: MUL, Inputs: [244 239], Outputs: [245]\n",
      "2025-04-30 16:50:50,522 - INFO - Type: SUB, Inputs: [ 56 245], Outputs: [246]\n",
      "2025-04-30 16:50:50,523 - INFO - Type: RESHAPE, Inputs: [244  54], Outputs: [247]\n",
      "2025-04-30 16:50:50,524 - INFO - Type: MUL, Inputs: [238 247], Outputs: [248]\n",
      "2025-04-30 16:50:50,525 - INFO - Type: RESHAPE, Inputs: [246  54], Outputs: [249]\n",
      "2025-04-30 16:50:50,527 - INFO - Type: ADD, Inputs: [248 249], Outputs: [250]\n",
      "2025-04-30 16:50:50,528 - INFO - Type: MUL, Inputs: [250  67], Outputs: [251]\n",
      "2025-04-30 16:50:50,528 - INFO - Type: ADD, Inputs: [251  68], Outputs: [252]\n",
      "2025-04-30 16:50:50,529 - INFO - Type: MEAN, Inputs: [252  59], Outputs: [253]\n",
      "2025-04-30 16:50:50,530 - INFO - Type: RESHAPE, Inputs: [253  54], Outputs: [254]\n",
      "2025-04-30 16:50:50,531 - INFO - Type: SQUARED_DIFFERENCE, Inputs: [252 254], Outputs: [255]\n",
      "2025-04-30 16:50:50,531 - INFO - Type: MEAN, Inputs: [255  59], Outputs: [256]\n",
      "2025-04-30 16:50:50,532 - INFO - Type: ADD, Inputs: [256  60], Outputs: [257]\n",
      "2025-04-30 16:50:50,533 - INFO - Type: RSQRT, Inputs: [257], Outputs: [258]\n",
      "2025-04-30 16:50:50,534 - INFO - Type: MUL, Inputs: [258 253], Outputs: [259]\n",
      "2025-04-30 16:50:50,535 - INFO - Type: SUB, Inputs: [ 56 259], Outputs: [260]\n",
      "2025-04-30 16:50:50,536 - INFO - Type: RESHAPE, Inputs: [258  54], Outputs: [261]\n",
      "2025-04-30 16:50:50,536 - INFO - Type: MUL, Inputs: [252 261], Outputs: [262]\n",
      "2025-04-30 16:50:50,538 - INFO - Type: RESHAPE, Inputs: [260  54], Outputs: [263]\n",
      "2025-04-30 16:50:50,539 - INFO - Type: ADD, Inputs: [262 263], Outputs: [264]\n",
      "2025-04-30 16:50:50,540 - INFO - Type: MUL, Inputs: [264  69], Outputs: [265]\n",
      "2025-04-30 16:50:50,541 - INFO - Type: ADD, Inputs: [265  70], Outputs: [266]\n",
      "2025-04-30 16:50:50,542 - INFO - Type: TRANSPOSE, Inputs: [266  53], Outputs: [267]\n",
      "2025-04-30 16:50:50,543 - INFO - Type: RESHAPE, Inputs: [267  36], Outputs: [268]\n",
      "2025-04-30 16:50:50,543 - INFO - Type: TRANSPOSE, Inputs: [268  58], Outputs: [269]\n",
      "2025-04-30 16:50:50,544 - INFO - Type: AVERAGE_POOL_2D, Inputs: [269], Outputs: [270]\n",
      "2025-04-30 16:50:50,551 - INFO - Type: FULLY_CONNECTED, Inputs: [270  11   1], Outputs: [271]\n",
      "2025-04-30 16:50:50,552 - INFO - Type: LOGISTIC, Inputs: [271], Outputs: [272]\n",
      "2025-04-30 16:50:50,553 - INFO - Type: DELEGATE, Inputs: [ 0 10 19 20 21 22 23 24 25 26 29 30 31 32 33 34 35 46 47 48 49 50 51 52\n",
      " 53 55 57 58 62], Outputs: [94 97 98]\n",
      "2025-04-30 16:50:50,554 - INFO - Type: DELEGATE, Inputs: [99], Outputs: [100]\n",
      "2025-04-30 16:50:50,555 - INFO - Type: DELEGATE, Inputs: [  8   9  18  19  20  21  22  23  41  42  43  45  47  48  49  50  51  61\n",
      " 101], Outputs: [105 114 117 123]\n",
      "2025-04-30 16:50:50,556 - INFO - Type: DELEGATE, Inputs: [ 39  40 124], Outputs: [127]\n",
      "2025-04-30 16:50:50,556 - INFO - Type: DELEGATE, Inputs: [  9  18  37  38  43  45 105 128], Outputs: [134]\n",
      "2025-04-30 16:50:50,557 - INFO - Type: DELEGATE, Inputs: [ 54 134 135], Outputs: [137]\n",
      "2025-04-30 16:50:50,558 - INFO - Type: DELEGATE, Inputs: [ 60 138], Outputs: [139]\n",
      "2025-04-30 16:50:50,560 - INFO - Type: DELEGATE, Inputs: [  7  16  17  28  37  44  54  56  63  64 134 135 140], Outputs: [155]\n",
      "2025-04-30 16:50:50,562 - INFO - Type: DELEGATE, Inputs: [ 54 155 156], Outputs: [158]\n",
      "2025-04-30 16:50:50,563 - INFO - Type: DELEGATE, Inputs: [ 60 159], Outputs: [160]\n",
      "2025-04-30 16:50:50,563 - INFO - Type: DELEGATE, Inputs: [  5   6  20  21  22  23  46  47  48  49  50  51  54  56  62 155 156 161], Outputs: [177 180 181]\n",
      "2025-04-30 16:50:50,564 - INFO - Type: DELEGATE, Inputs: [182], Outputs: [183]\n",
      "2025-04-30 16:50:50,565 - INFO - Type: DELEGATE, Inputs: [  3   4  14  15  20  21  22  23  41  42  43  45  47  48  49  50  51  61\n",
      " 184], Outputs: [188 197 200 206]\n",
      "2025-04-30 16:50:50,566 - INFO - Type: DELEGATE, Inputs: [ 39  40 207], Outputs: [210]\n",
      "2025-04-30 16:50:50,566 - INFO - Type: DELEGATE, Inputs: [  4  14  37  38  43  45 188 211], Outputs: [217]\n",
      "2025-04-30 16:50:50,567 - INFO - Type: DELEGATE, Inputs: [ 54 217 218], Outputs: [220]\n",
      "2025-04-30 16:50:50,568 - INFO - Type: DELEGATE, Inputs: [ 60 221], Outputs: [222]\n",
      "2025-04-30 16:50:50,569 - INFO - Type: DELEGATE, Inputs: [  2  12  13  27  37  44  54  56  65  66 217 218 223], Outputs: [238]\n",
      "2025-04-30 16:50:50,570 - INFO - Type: DELEGATE, Inputs: [ 54 238 239], Outputs: [241]\n",
      "2025-04-30 16:50:50,572 - INFO - Type: DELEGATE, Inputs: [ 60 242], Outputs: [243]\n",
      "2025-04-30 16:50:50,573 - INFO - Type: DELEGATE, Inputs: [ 54  56  67  68 238 239 244], Outputs: [252]\n",
      "2025-04-30 16:50:50,574 - INFO - Type: DELEGATE, Inputs: [ 54 252 253], Outputs: [255]\n",
      "2025-04-30 16:50:50,575 - INFO - Type: DELEGATE, Inputs: [ 60 256], Outputs: [257]\n",
      "2025-04-30 16:50:50,576 - INFO - Type: DELEGATE, Inputs: [  1  11  36  53  54  56  58  69  70 252 253 258], Outputs: [272]\n",
      "2025-04-30 16:50:50,577 - INFO - \n",
      "Model Metadata:\n",
      "2025-04-30 16:50:50,597 - WARNING - tflite_support module not found. Metadata extraction skipped.\n",
      "2025-04-30 16:50:50,597 - INFO - \n",
      "Signatures:\n",
      "2025-04-30 16:50:50,598 - INFO - Signature Name: serving_default, Details: {'inputs': ['args_0'], 'outputs': ['output_0']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    print_tflite_info(\"watchTousifKd.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2c23eea-7c88-4032-b7ee-ea45a9fd24c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 16:59:00,451 - INFO - Loading Keras model from: student_model_31.keras\n",
      "2025-04-30 16:59:01,013 - INFO - Keras model loaded from .keras file.\n",
      "2025-04-30 16:59:01,055 - INFO - Keras model built successfully with dummy input.\n",
      "2025-04-30 16:59:01,055 - INFO - \n",
      "=== Keras Model Details ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f6990774ae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 16:59:01,481 - WARNING - 5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f6990774ae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2025-04-30 16:59:01,503 - INFO - Keras Input Shape (inferred): [None, 64, 3]\n",
      "2025-04-30 16:59:01,504 - INFO - Keras Output Shape (inferred): [1, 1]\n",
      "2025-04-30 16:59:01,505 - INFO - Using existing TFLite model at student_model_31.tflite.\n",
      "2025-04-30 16:59:01,506 - INFO - Loading TFLite model from student_model_31.tflite\n",
      "2025-04-30 16:59:01,508 - INFO - TFLite model loaded successfully.\n",
      "2025-04-30 16:59:01,509 - INFO - \n",
      "=== TFLite Model Details ===\n",
      "2025-04-30 16:59:01,510 - INFO - TFLite Input Shape: [ 1 64  3]\n",
      "2025-04-30 16:59:01,512 - INFO - TFLite Output Shape: [1 1]\n",
      "2025-04-30 16:59:01,513 - INFO - TFLite Input Data Type: <class 'numpy.float32'>\n",
      "2025-04-30 16:59:01,515 - ERROR - Failed to extract TFLite op info: 'Interpreter' object has no attribute '_model_path'\n",
      "2025-04-30 16:59:01,516 - INFO - \n",
      "=== Layer/Operator Comparison ===\n",
      "2025-04-30 16:59:01,516 - INFO - Keras model has 13 main layers\n",
      "2025-04-30 16:59:01,517 - INFO - TFLite model has 0 tensors/operators\n",
      "2025-04-30 16:59:01,518 - INFO - \n",
      "Keras Layers:\n",
      "2025-04-30 16:59:01,518 - INFO -   1. conv_projection (Conv2D) - Params: 800\n",
      "2025-04-30 16:59:01,519 - INFO -   2. layer_norm (LayerNormalization) - Params: 64\n",
      "2025-04-30 16:59:01,519 - INFO -   3. mha_0 (MultiHeadAttention) - Params: 4224\n",
      "2025-04-30 16:59:01,521 - INFO -   4. mha_1 (MultiHeadAttention) - Params: 4224\n",
      "2025-04-30 16:59:01,522 - INFO -   5. ffn_0 (Sequential) - Params: 4192\n",
      "2025-04-30 16:59:01,523 - INFO -      Input shape: (1, 64, 32)\n",
      "2025-04-30 16:59:01,525 - INFO -      Output shape: (1, 64, 32)\n",
      "2025-04-30 16:59:01,525 - INFO -        1. ffn_dense1_0 (Dense) - Params: 2112\n",
      "2025-04-30 16:59:01,526 - INFO -        2. dropout_48 (Dropout) - Params: 0\n",
      "2025-04-30 16:59:01,526 - INFO -        3. ffn_dense2_0 (Dense) - Params: 2080\n",
      "2025-04-30 16:59:01,527 - INFO -        4. dropout_49 (Dropout) - Params: 0\n",
      "2025-04-30 16:59:01,528 - INFO -   6. ffn_1 (Sequential) - Params: 4192\n",
      "2025-04-30 16:59:01,528 - INFO -      Input shape: (1, 64, 32)\n",
      "2025-04-30 16:59:01,529 - INFO -      Output shape: (1, 64, 32)\n",
      "2025-04-30 16:59:01,530 - INFO -        1. ffn_dense1_1 (Dense) - Params: 2112\n",
      "2025-04-30 16:59:01,530 - INFO -        2. dropout_50 (Dropout) - Params: 0\n",
      "2025-04-30 16:59:01,531 - INFO -        3. ffn_dense2_1 (Dense) - Params: 2080\n",
      "2025-04-30 16:59:01,531 - INFO -        4. dropout_51 (Dropout) - Params: 0\n",
      "2025-04-30 16:59:01,532 - INFO -   7. ln0_0 (LayerNormalization) - Params: 64\n",
      "2025-04-30 16:59:01,532 - INFO -   8. ln0_1 (LayerNormalization) - Params: 64\n",
      "2025-04-30 16:59:01,534 - INFO -   9. ln1_0 (LayerNormalization) - Params: 64\n",
      "2025-04-30 16:59:01,535 - INFO -   10. ln1_1 (LayerNormalization) - Params: 64\n",
      "2025-04-30 16:59:01,536 - INFO -   11. final_norm (LayerNormalization) - Params: 64\n",
      "2025-04-30 16:59:01,537 - INFO -   12. global_pool (GlobalAveragePooling1D) - Params: 0\n",
      "2025-04-30 16:59:01,537 - INFO -   13. output_dense (Dense) - Params: 33\n",
      "2025-04-30 16:59:01,538 - INFO - \n",
      "TFLite Tensors/Operators:\n",
      "2025-04-30 16:59:01,539 - INFO - \n",
      "=== Shape Comparison ===\n",
      "2025-04-30 16:59:01,539 - INFO - ✓ Input shapes match (ignoring batch dimension).\n",
      "2025-04-30 16:59:01,540 - INFO - ✓ Output shapes match.\n",
      "2025-04-30 16:59:01,541 - INFO - Generated random input for inference comparison.\n",
      "2025-04-30 16:59:01,545 - INFO - \n",
      "=== Inference Comparison ===\n",
      "2025-04-30 16:59:01,546 - INFO - Running Keras model inference...\n",
      "2025-04-30 16:59:01,622 - INFO - Running TFLite model inference...\n",
      "2025-04-30 16:59:01,624 - INFO - Comparing outputs...\n",
      "2025-04-30 16:59:01,626 - INFO - Mean Squared Error between outputs: 0.0000000000\n",
      "2025-04-30 16:59:01,627 - INFO - ✓ Outputs are approximately equal (MSE < 1e-5).\n",
      "2025-04-30 16:59:01,628 - INFO - \n",
      "Sample output values:\n",
      "2025-04-30 16:59:01,628 - INFO -   Value 1: Keras=0.936020, TFLite=0.936020, Diff=0.000000\n",
      "2025-04-30 16:59:01,629 - INFO - \n",
      "=== Model Size Comparison ===\n",
      "2025-04-30 16:59:01,630 - INFO - Keras model size (.keras): 0.15 MB\n",
      "2025-04-30 16:59:01,631 - INFO - Weights size (.weights.h5): 0.15 MB\n",
      "2025-04-30 16:59:01,633 - INFO - TFLite model size: 0.09 MB\n",
      "2025-04-30 16:59:01,634 - INFO - Size reduction: 39.49%\n",
      "2025-04-30 16:59:01,635 - INFO - \n",
      "=== Compatibility Check ===\n",
      "2025-04-30 16:59:01,635 - INFO - ✓ Keras model can be loaded and executed\n",
      "2025-04-30 16:59:01,636 - INFO - ✓ TFLite model can be loaded and executed\n",
      "2025-04-30 16:59:01,637 - INFO - ✓ Inference results match between implementations\n",
      "2025-04-30 16:59:01,638 - INFO - \n",
      "=== Comparison Complete ===\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "import shutil\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define and register the custom TransModel class\n",
    "@register_keras_serializable(package=\"CustomModels\")\n",
    "class TransModel(tf.keras.Model):\n",
    "    def __init__(self, acc_frames=64, num_classes=1, num_heads=4, acc_coords=3, embed_dim=32, num_layers=2, dropout=0.5, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.acc_frames = acc_frames\n",
    "        self.num_classes = num_classes\n",
    "        self.num_heads = num_heads\n",
    "        self.acc_coords = acc_coords\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Define layers\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(filters=embed_dim, kernel_size=(8, 1), padding='same', name=\"conv_projection\")\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"layer_norm\")\n",
    "        self.attention_layers = [\n",
    "            tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout, name=f\"mha_{i}\")\n",
    "            for i in range(num_layers)\n",
    "        ]\n",
    "        self.ffn_layers = [\n",
    "            tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(embed_dim * 2, activation=activation, name=f\"ffn_dense1_{i}\"),\n",
    "                tf.keras.layers.Dropout(dropout),\n",
    "                tf.keras.layers.Dense(embed_dim, name=f\"ffn_dense2_{i}\"),\n",
    "                tf.keras.layers.Dropout(dropout)\n",
    "            ], name=f\"ffn_{i}\")\n",
    "            for i in range(num_layers)\n",
    "        ]\n",
    "        self.layer_norms = [\n",
    "            [tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f\"ln{i}_{j}\") for j in range(2)]\n",
    "            for i in range(num_layers)\n",
    "        ]\n",
    "        self.final_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"final_norm\")\n",
    "        self.global_pool = tf.keras.layers.GlobalAveragePooling1D(name=\"global_pool\")\n",
    "        self.output_dense = tf.keras.layers.Dense(num_classes, name=\"output_dense\")\n",
    "        \n",
    "        # Initialize with a dummy input to ensure the model is built\n",
    "        dummy_input = tf.zeros((1, acc_frames, acc_coords), dtype=tf.float32)\n",
    "        self(dummy_input, training=False)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs.get('accelerometer', inputs) if isinstance(inputs, dict) else inputs\n",
    "        x = tf.expand_dims(x, axis=2)  # Add channel dimension for Conv2D\n",
    "        x = self.conv_layer(x)\n",
    "        x = tf.squeeze(x, axis=2)  # Remove channel dimension\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        # Transformer layers\n",
    "        for i in range(self.num_layers):\n",
    "            attn = self.attention_layers[i](x, x, training=training)\n",
    "            x = self.layer_norms[i][0](x + attn)  # Residual + normalization\n",
    "            ffn = self.ffn_layers[i](x, training=training)\n",
    "            x = self.layer_norms[i][1](x + ffn)  # Residual + normalization\n",
    "            \n",
    "        x = self.final_norm(x)\n",
    "        x = self.global_pool(x)\n",
    "        logits = self.output_dense(x)\n",
    "        return tf.reshape(logits, [-1, self.num_classes])\n",
    "    \n",
    "    # Add get_config method for proper serialization\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"acc_frames\": self.acc_frames,\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"acc_coords\": self.acc_coords,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "            \"activation\": self.activation\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    # Add TFLite export functionality\n",
    "    def export_to_tflite(self, save_path, input_shape=None):\n",
    "        \"\"\"\n",
    "        Export the model to TFLite format\n",
    "        \n",
    "        Args:\n",
    "            save_path (str): Path to save the TFLite model\n",
    "            input_shape (tuple, optional): Input shape for the model. Defaults to (1, acc_frames, acc_coords).\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if export was successful, False otherwise\n",
    "        \"\"\"\n",
    "        if input_shape is None:\n",
    "            input_shape = (1, self.acc_frames, self.acc_coords)\n",
    "            \n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)\n",
    "            save_path = save_path if save_path.endswith('.tflite') else f\"{save_path}.tflite\"\n",
    "            logger.info(f\"Exporting to TFLite: {save_path}, shape={input_shape}\")\n",
    "\n",
    "            # Define a wrapper model to ensure proper input signature\n",
    "            class TFLiteModel(tf.keras.Model):\n",
    "                def __init__(self, parent):\n",
    "                    super().__init__()\n",
    "                    self.parent = parent\n",
    "\n",
    "                @tf.function(input_signature=[tf.TensorSpec(shape=input_shape, dtype=tf.float32, name='accelerometer')])\n",
    "                def call(self, inputs):\n",
    "                    return self.parent({'accelerometer': inputs}, training=False)\n",
    "\n",
    "            tflite_model = TFLiteModel(self)\n",
    "            \n",
    "            # Create a temporary directory for the SavedModel\n",
    "            temp_dir = os.path.join(os.path.dirname(save_path) or '.', \"temp_savedmodel\")\n",
    "            if os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "            # Save the model with signatures\n",
    "            tf.saved_model.save(\n",
    "                tflite_model, \n",
    "                temp_dir, \n",
    "                signatures={'serving_default': tflite_model.call}\n",
    "            )\n",
    "            \n",
    "            # Convert to TFLite\n",
    "            converter = tf.lite.TFLiteConverter.from_saved_model(temp_dir)\n",
    "            converter.target_spec.supported_ops = [\n",
    "                tf.lite.OpsSet.TFLITE_BUILTINS, \n",
    "                tf.lite.OpsSet.SELECT_TF_OPS\n",
    "            ]\n",
    "            converter.inference_input_type = tf.float32\n",
    "            converter.inference_output_type = tf.float32\n",
    "            tflite_content = converter.convert()\n",
    "\n",
    "            # Save TFLite model\n",
    "            with open(save_path, 'wb') as f:\n",
    "                f.write(tflite_content)\n",
    "                \n",
    "            # Clean up temporary directory\n",
    "            shutil.rmtree(temp_dir)\n",
    "            logger.info(f\"TFLite model successfully saved: {save_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"TFLite export failed: {e}\\n{traceback.format_exc()}\")\n",
    "            if 'temp_dir' in locals() and os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "            return False\n",
    "\n",
    "\n",
    "def get_keras_layer_info(model):\n",
    "    \"\"\"Extract layer information from a Keras model\"\"\"\n",
    "    try:\n",
    "        layers_info = []\n",
    "        for layer in model.layers:\n",
    "            layer_info = {\n",
    "                'name': layer.name,\n",
    "                'type': layer.__class__.__name__,\n",
    "                'trainable': layer.trainable,\n",
    "                'params': layer.count_params()\n",
    "            }\n",
    "            \n",
    "            # Try to extract shape information if available\n",
    "            try:\n",
    "                if hasattr(layer, 'output_shape'):\n",
    "                    layer_info['output_shape'] = str(layer.output_shape)\n",
    "                if hasattr(layer, 'input_shape'):\n",
    "                    layer_info['input_shape'] = str(layer.input_shape)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            # If it's a Sequential model, get info about its layers\n",
    "            if isinstance(layer, tf.keras.Sequential):\n",
    "                sublayers = []\n",
    "                for sublayer in layer.layers:\n",
    "                    sublayer_info = {\n",
    "                        'name': sublayer.name,\n",
    "                        'type': sublayer.__class__.__name__,\n",
    "                        'trainable': sublayer.trainable,\n",
    "                        'params': sublayer.count_params()\n",
    "                    }\n",
    "                    sublayers.append(sublayer_info)\n",
    "                layer_info['sublayers'] = sublayers\n",
    "                \n",
    "            layers_info.append(layer_info)\n",
    "        return layers_info\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to extract Keras layer info: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_tflite_op_info(interpreter):\n",
    "    \"\"\"Extract operation information from a TFLite interpreter\"\"\"\n",
    "    try:\n",
    "        ops_info = []\n",
    "        \n",
    "        # Get information about ops from the interpreter\n",
    "        with open(interpreter._model_path, 'rb') as f:\n",
    "            model_data = f.read()\n",
    "        \n",
    "        # Get input and output details\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        \n",
    "        # Get operator codes and subgraphs from the model\n",
    "        try:\n",
    "            # Get basic tensor details\n",
    "            tensor_details = interpreter._get_tensor_details()\n",
    "            for i, tensor in enumerate(tensor_details):\n",
    "                is_input = any(tensor['index'] == det['index'] for det in input_details)\n",
    "                is_output = any(tensor['index'] == det['index'] for det in output_details)\n",
    "                \n",
    "                op_info = {\n",
    "                    'tensor_index': tensor['index'],\n",
    "                    'name': tensor['name'],\n",
    "                    'shape': str(tensor['shape']),\n",
    "                    'dtype': str(tensor['dtype']),\n",
    "                    'is_input': is_input,\n",
    "                    'is_output': is_output\n",
    "                }\n",
    "                ops_info.append(op_info)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Couldn't extract detailed TFLite tensor info: {e}\")\n",
    "            \n",
    "            # Fallback to basic input/output info\n",
    "            for i, details in enumerate(input_details):\n",
    "                ops_info.append({\n",
    "                    'tensor_index': details['index'],\n",
    "                    'name': details.get('name', f'input_{i}'),\n",
    "                    'shape': str(details['shape']),\n",
    "                    'dtype': str(details['dtype']),\n",
    "                    'is_input': True,\n",
    "                    'is_output': False\n",
    "                })\n",
    "                \n",
    "            for i, details in enumerate(output_details):\n",
    "                ops_info.append({\n",
    "                    'tensor_index': details['index'],\n",
    "                    'name': details.get('name', f'output_{i}'),\n",
    "                    'shape': str(details['shape']),\n",
    "                    'dtype': str(details['dtype']),\n",
    "                    'is_input': False,\n",
    "                    'is_output': True\n",
    "                })\n",
    "                \n",
    "        return ops_info\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to extract TFLite op info: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def compare_keras_tflite(keras_model_path, tflite_model_path, weights_path=None, sample_input=None, model_architecture=None):\n",
    "    \"\"\"\n",
    "    Compare a Keras TransModel with its TFLite version for robustness and compatibility.\n",
    "    \n",
    "    Args:\n",
    "        keras_model_path (str): Path to the .keras model file.\n",
    "        tflite_model_path (str): Path to the .tflite model file (or where it will be saved if converted).\n",
    "        weights_path (str, optional): Path to the .weights.h5 file if .keras is unavailable.\n",
    "        sample_input (np.ndarray, optional): Sample input for inference comparison.\n",
    "        model_architecture (callable, optional): Function to define model architecture if using .weights.h5.\n",
    "    \"\"\"\n",
    "    keras_model = None\n",
    "    \n",
    "    # Load or create Keras model\n",
    "    try:\n",
    "        if os.path.exists(keras_model_path):\n",
    "            logger.info(f\"Loading Keras model from: {keras_model_path}\")\n",
    "            keras_model = tf.keras.models.load_model(\n",
    "                keras_model_path, \n",
    "                custom_objects={'TransModel': TransModel}\n",
    "            )\n",
    "            logger.info(\"Keras model loaded from .keras file.\")\n",
    "        elif weights_path and model_architecture and os.path.exists(weights_path):\n",
    "            logger.info(f\"Creating model and loading weights from: {weights_path}\")\n",
    "            keras_model = model_architecture()\n",
    "            keras_model.load_weights(weights_path)\n",
    "            logger.info(\"Keras model loaded from .weights.h5 with provided architecture.\")\n",
    "        else:\n",
    "            logger.info(\"Creating new model instance\")\n",
    "            keras_model = model_architecture() if model_architecture else TransModel()\n",
    "            logger.info(\"New TransModel instance created.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load/create Keras model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Ensure model is built\n",
    "    try:\n",
    "        dummy_input = np.zeros((1, 64, 3), dtype=np.float32)\n",
    "        _ = keras_model(dummy_input)\n",
    "        logger.info(\"Keras model built successfully with dummy input.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to build model: {e}\")\n",
    "    \n",
    "    # Log Keras model details\n",
    "    logger.info(\"\\n=== Keras Model Details ===\")\n",
    "    \n",
    "    # Get shapes by inference instead of direct attribute access\n",
    "    try:\n",
    "        dummy_input = np.zeros((1, 64, 3), dtype=np.float32)\n",
    "        test_output = keras_model.predict(dummy_input, verbose=0)\n",
    "        keras_input_shape = [None, 64, 3]  # Input shape is known from our dummy input pattern\n",
    "        keras_output_shape = list(test_output.shape)\n",
    "        logger.info(f\"Keras Input Shape (inferred): {keras_input_shape}\")\n",
    "        logger.info(f\"Keras Output Shape (inferred): {keras_output_shape}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to infer shapes: {e}\")\n",
    "    \n",
    "    # Extract keras layer information\n",
    "    keras_layers = get_keras_layer_info(keras_model)\n",
    "    \n",
    "    # Convert to TFLite if necessary\n",
    "    if not os.path.exists(tflite_model_path):\n",
    "        try:\n",
    "            logger.info(f\"Converting model to TFLite: {tflite_model_path}\")\n",
    "            # Try to use the built-in export method if it's a TransModel instance\n",
    "            if isinstance(keras_model, TransModel):\n",
    "                logger.info(\"Using TransModel's built-in TFLite export method\")\n",
    "                success = keras_model.export_to_tflite(tflite_model_path)\n",
    "                if not success:\n",
    "                    raise ValueError(\"Export failed using TransModel's export_to_tflite method\")\n",
    "            else:\n",
    "                # Fallback to generic conversion\n",
    "                logger.info(\"Using generic TFLite conversion\")\n",
    "                @tf.function(input_signature=[tf.TensorSpec(shape=(None, 64, 3), dtype=tf.float32)])\n",
    "                def model_func(inputs):\n",
    "                    return keras_model(inputs, training=False)\n",
    "                concrete_func = model_func.get_concrete_function()\n",
    "                converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "                tflite_model = converter.convert()\n",
    "                with open(tflite_model_path, 'wb') as f:\n",
    "                    f.write(tflite_model)\n",
    "            logger.info(f\"Converted Keras model to TFLite and saved to {tflite_model_path}.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to convert Keras model to TFLite: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        logger.info(f\"Using existing TFLite model at {tflite_model_path}.\")\n",
    "    \n",
    "    # Load TFLite model\n",
    "    try:\n",
    "        logger.info(f\"Loading TFLite model from {tflite_model_path}\")\n",
    "        interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "        interpreter.allocate_tensors()\n",
    "        logger.info(\"TFLite model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load TFLite model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Get TFLite model details\n",
    "    logger.info(\"\\n=== TFLite Model Details ===\")\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    tflite_input_shape = input_details[0]['shape']\n",
    "    tflite_output_shape = output_details[0]['shape']\n",
    "    logger.info(f\"TFLite Input Shape: {tflite_input_shape}\")\n",
    "    logger.info(f\"TFLite Output Shape: {tflite_output_shape}\")\n",
    "    tflite_input_dtype = input_details[0]['dtype']\n",
    "    logger.info(f\"TFLite Input Data Type: {tflite_input_dtype}\")\n",
    "    \n",
    "    # Extract TFLite operation information\n",
    "    tflite_ops = get_tflite_op_info(interpreter)\n",
    "    \n",
    "    # Compare and display layer information\n",
    "    logger.info(\"\\n=== Layer/Operator Comparison ===\")\n",
    "    logger.info(f\"Keras model has {len(keras_layers)} main layers\")\n",
    "    logger.info(f\"TFLite model has {len(tflite_ops)} tensors/operators\")\n",
    "    \n",
    "    # Display Keras layers\n",
    "    logger.info(\"\\nKeras Layers:\")\n",
    "    for i, layer in enumerate(keras_layers):\n",
    "        logger.info(f\"  {i+1}. {layer['name']} ({layer['type']}) - Params: {layer['params']}\")\n",
    "        if 'input_shape' in layer:\n",
    "            logger.info(f\"     Input shape: {layer['input_shape']}\")\n",
    "        if 'output_shape' in layer:\n",
    "            logger.info(f\"     Output shape: {layer['output_shape']}\")\n",
    "        if 'sublayers' in layer:\n",
    "            for j, sublayer in enumerate(layer['sublayers']):\n",
    "                logger.info(f\"       {j+1}. {sublayer['name']} ({sublayer['type']}) - Params: {sublayer['params']}\")\n",
    "    \n",
    "    # Display TFLite operators\n",
    "    logger.info(\"\\nTFLite Tensors/Operators:\")\n",
    "    for i, op in enumerate(tflite_ops):\n",
    "        role = \"INPUT\" if op['is_input'] else \"OUTPUT\" if op['is_output'] else \"INTERMEDIATE\"\n",
    "        logger.info(f\"  {i+1}. {op['name']} ({role}) - Shape: {op['shape']}, Type: {op['dtype']}\")\n",
    "    \n",
    "    # Compare shapes\n",
    "    logger.info(\"\\n=== Shape Comparison ===\")\n",
    "    try:\n",
    "        if 'keras_input_shape' in locals() and 'tflite_input_shape' in locals():\n",
    "            # Compare all except batch dimension\n",
    "            if keras_input_shape[1:] == list(tflite_input_shape)[1:]:\n",
    "                logger.info(\"✓ Input shapes match (ignoring batch dimension).\")\n",
    "            else:\n",
    "                logger.warning(f\"✗ Input shapes differ: Keras {keras_input_shape} vs TFLite {tflite_input_shape}\")\n",
    "        else:\n",
    "            logger.info(f\"⚠ Full shape comparison unavailable - displaying separately:\")\n",
    "            logger.info(f\"  Keras input (inferred): {locals().get('keras_input_shape', 'Unknown')}\")\n",
    "            logger.info(f\"  TFLite input: {locals().get('tflite_input_shape', 'Unknown')}\")\n",
    "        \n",
    "        if 'keras_output_shape' in locals() and 'tflite_output_shape' in locals():\n",
    "            if keras_output_shape == list(tflite_output_shape):\n",
    "                logger.info(\"✓ Output shapes match.\")\n",
    "            else:\n",
    "                logger.warning(f\"✗ Output shapes differ: Keras {keras_output_shape} vs TFLite {tflite_output_shape}\")\n",
    "        else:\n",
    "            logger.info(f\"⚠ Output shape comparison unavailable - displaying separately:\")\n",
    "            logger.info(f\"  Keras output (inferred): {locals().get('keras_output_shape', 'Unknown')}\")\n",
    "            logger.info(f\"  TFLite output: {locals().get('tflite_output_shape', 'Unknown')}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during shape comparison: {e}\")\n",
    "    \n",
    "    # Generate sample input if not provided\n",
    "    if sample_input is None:\n",
    "        sample_input = np.random.randn(1, 64, 3).astype(np.float32)\n",
    "        logger.info(\"Generated random input for inference comparison.\")\n",
    "    \n",
    "    # Perform inference and compare outputs\n",
    "    logger.info(\"\\n=== Inference Comparison ===\")\n",
    "    try:\n",
    "        logger.info(\"Running Keras model inference...\")\n",
    "        keras_output = keras_model.predict(sample_input, verbose=0)\n",
    "        \n",
    "        logger.info(\"Running TFLite model inference...\")\n",
    "        interpreter.set_tensor(input_details[0]['index'], sample_input)\n",
    "        interpreter.invoke()\n",
    "        tflite_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        logger.info(\"Comparing outputs...\")\n",
    "        mse = mean_squared_error(keras_output.flatten(), tflite_output.flatten())\n",
    "        logger.info(f\"Mean Squared Error between outputs: {mse:.10f}\")\n",
    "        \n",
    "        if mse < 1e-5:\n",
    "            logger.info(\"✓ Outputs are approximately equal (MSE < 1e-5).\")\n",
    "        else:\n",
    "            logger.warning(f\"✗ Outputs differ significantly (MSE = {mse:.10f}).\")\n",
    "            \n",
    "        # Display sample values from both outputs\n",
    "        logger.info(\"\\nSample output values:\")\n",
    "        keras_flat = keras_output.flatten()\n",
    "        tflite_flat = tflite_output.flatten()\n",
    "        num_samples = min(5, len(keras_flat))\n",
    "        for i in range(num_samples):\n",
    "            logger.info(f\"  Value {i+1}: Keras={keras_flat[i]:.6f}, TFLite={tflite_flat[i]:.6f}, Diff={abs(keras_flat[i]-tflite_flat[i]):.6f}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to compare outputs: {e}\")\n",
    "    \n",
    "    # Compare model sizes\n",
    "    logger.info(\"\\n=== Model Size Comparison ===\")\n",
    "    try:\n",
    "        keras_size = os.path.getsize(keras_model_path) / (1024 * 1024) if os.path.exists(keras_model_path) else 0\n",
    "        weights_size = os.path.getsize(weights_path) / (1024 * 1024) if weights_path and os.path.exists(weights_path) else 0\n",
    "        tflite_size = os.path.getsize(tflite_model_path) / (1024 * 1024)\n",
    "        \n",
    "        if keras_size:\n",
    "            logger.info(f\"Keras model size (.keras): {keras_size:.2f} MB\")\n",
    "        if weights_size:\n",
    "            logger.info(f\"Weights size (.weights.h5): {weights_size:.2f} MB\")\n",
    "        logger.info(f\"TFLite model size: {tflite_size:.2f} MB\")\n",
    "        \n",
    "        if keras_size and tflite_size:\n",
    "            reduction = (1 - tflite_size/keras_size) * 100\n",
    "            logger.info(f\"Size reduction: {reduction:.2f}%\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to compute model sizes: {e}\")\n",
    "    \n",
    "    logger.info(\"\\n=== Compatibility Check ===\")\n",
    "    logger.info(\"✓ Keras model can be loaded and executed\")\n",
    "    logger.info(\"✓ TFLite model can be loaded and executed\")\n",
    "    logger.info(f\"✓ Inference results {'match' if mse < 1e-5 else 'differ'} between implementations\")\n",
    "    \n",
    "    logger.info(\"\\n=== Comparison Complete ===\")\n",
    "    return keras_model, interpreter\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    keras_model_path = \"student_model_31.keras\"\n",
    "    tflite_model_path = \"student_model_31.tflite\"\n",
    "    weights_path = \"student_model_31.weights.h5\"\n",
    "    \n",
    "    # Define a function to create a new instance of TransModel\n",
    "    def create_trans_model():\n",
    "        return TransModel()\n",
    "    \n",
    "    # Run comparison\n",
    "    compare_keras_tflite(\n",
    "        keras_model_path, \n",
    "        tflite_model_path, \n",
    "        weights_path=weights_path, \n",
    "        model_architecture=create_trans_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819874e2-c57f-4f17-be24-9a00ec6d0545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 17:09:56,633 - INFO - Loading Keras model from: student_model_31.keras\n",
      "2025-04-30 17:09:57,236 - INFO - Keras model loaded from .keras file.\n",
      "2025-04-30 17:09:57,312 - INFO - Keras model built successfully with dummy input.\n",
      "2025-04-30 17:09:57,313 - INFO - \n",
      "=== Keras Model Details ===\n",
      "2025-04-30 17:09:57,691 - INFO - Keras Input Shape (inferred): [None, 64, 3]\n",
      "2025-04-30 17:09:57,691 - INFO - Keras Output Shape (inferred): [1, 1]\n",
      "2025-04-30 17:09:57,693 - INFO - Using existing TFLite model at student_model_31.tflite.\n",
      "2025-04-30 17:09:57,694 - INFO - Loading TFLite model from student_model_31.tflite\n",
      "2025-04-30 17:09:57,696 - INFO - TFLite model loaded successfully.\n",
      "2025-04-30 17:09:57,697 - INFO - \n",
      "=== TFLite Model Details ===\n",
      "2025-04-30 17:09:57,698 - INFO - TFLite Input Shape: [1, 64, 3]\n",
      "2025-04-30 17:09:57,699 - INFO - TFLite Output Shape: [1, 1]\n",
      "2025-04-30 17:09:57,699 - INFO - TFLite Input Data Type: <class 'numpy.float32'>\n",
      "2025-04-30 17:09:57,708 - INFO - \n",
      "=== Layer/Operator Comparison ===\n",
      "2025-04-30 17:09:57,709 - INFO - Keras model has 13 main layers\n",
      "2025-04-30 17:09:57,710 - INFO - TFLite model has 220 tensors\n",
      "2025-04-30 17:09:57,711 - INFO - \n",
      "Keras Layers:\n",
      "2025-04-30 17:09:57,711 - INFO -   1. conv_projection (Conv2D) - Params: 800\n",
      "2025-04-30 17:09:57,712 - INFO -   2. layer_norm (LayerNormalization) - Params: 64\n",
      "2025-04-30 17:09:57,712 - INFO -   3. mha_0 (MultiHeadAttention) - Params: 4224\n",
      "2025-04-30 17:09:57,713 - INFO -   4. mha_1 (MultiHeadAttention) - Params: 4224\n",
      "2025-04-30 17:09:57,714 - INFO -   5. ffn_0 (Sequential) - Params: 4192\n",
      "2025-04-30 17:09:57,715 - INFO -      Input shape: (1, 64, 32)\n",
      "2025-04-30 17:09:57,715 - INFO -      Output shape: (1, 64, 32)\n",
      "2025-04-30 17:09:57,716 - INFO -        1. ffn_dense1_0 (Dense) - Params: 2112\n",
      "2025-04-30 17:09:57,716 - INFO -        2. dropout_60 (Dropout) - Params: 0\n",
      "2025-04-30 17:09:57,717 - INFO -        3. ffn_dense2_0 (Dense) - Params: 2080\n",
      "2025-04-30 17:09:57,717 - INFO -        4. dropout_61 (Dropout) - Params: 0\n",
      "2025-04-30 17:09:57,718 - INFO -   6. ffn_1 (Sequential) - Params: 4192\n",
      "2025-04-30 17:09:57,719 - INFO -      Input shape: (1, 64, 32)\n",
      "2025-04-30 17:09:57,720 - INFO -      Output shape: (1, 64, 32)\n",
      "2025-04-30 17:09:57,721 - INFO -        1. ffn_dense1_1 (Dense) - Params: 2112\n",
      "2025-04-30 17:09:57,721 - INFO -        2. dropout_62 (Dropout) - Params: 0\n",
      "2025-04-30 17:09:57,722 - INFO -        3. ffn_dense2_1 (Dense) - Params: 2080\n",
      "2025-04-30 17:09:57,722 - INFO -        4. dropout_63 (Dropout) - Params: 0\n",
      "2025-04-30 17:09:57,723 - INFO -   7. ln0_0 (LayerNormalization) - Params: 64\n",
      "2025-04-30 17:09:57,723 - INFO -   8. ln0_1 (LayerNormalization) - Params: 64\n",
      "2025-04-30 17:09:57,724 - INFO -   9. ln1_0 (LayerNormalization) - Params: 64\n",
      "2025-04-30 17:09:57,725 - INFO -   10. ln1_1 (LayerNormalization) - Params: 64\n",
      "2025-04-30 17:09:57,725 - INFO -   11. final_norm (LayerNormalization) - Params: 64\n",
      "2025-04-30 17:09:57,726 - INFO -   12. global_pool (GlobalAveragePooling1D) - Params: 0\n",
      "2025-04-30 17:09:57,726 - INFO -   13. output_dense (Dense) - Params: 33\n",
      "2025-04-30 17:09:57,727 - INFO - \n",
      "TFLite Tensors:\n",
      "2025-04-30 17:09:57,727 - INFO - \n",
      "  Input Tensors:\n",
      "2025-04-30 17:09:57,728 - INFO -     1. inputs - Shape: [ 1 64  3], Type: <class 'numpy.float32'>\n",
      "2025-04-30 17:09:57,729 - INFO - \n",
      "  Output Tensors:\n",
      "2025-04-30 17:09:57,729 - INFO -     1. Identity - Shape: [1 1], Type: <class 'numpy.float32'>\n",
      "2025-04-30 17:09:57,730 - INFO - \n",
      "  Intermediate Tensors (operators):\n",
      "2025-04-30 17:09:57,731 - INFO - \n",
      "    arith.constant:\n",
      "2025-04-30 17:09:57,731 - INFO -       1. arith.constant - Shape: [32]\n",
      "2025-04-30 17:09:57,732 - INFO - \n",
      "    arith.constant1:\n",
      "2025-04-30 17:09:57,732 - INFO -       1. arith.constant1 - Shape: [32 64]\n",
      "2025-04-30 17:09:57,733 - INFO - \n",
      "    arith.constant2:\n",
      "2025-04-30 17:09:57,733 - INFO -       1. arith.constant2 - Shape: [64 32]\n",
      "2025-04-30 17:09:57,734 - INFO - \n",
      "    arith.constant3:\n",
      "2025-04-30 17:09:57,734 - INFO -       1. arith.constant3 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,735 - INFO - \n",
      "    arith.constant4:\n",
      "2025-04-30 17:09:57,736 - INFO -       1. arith.constant4 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,737 - INFO - \n",
      "    arith.constant5:\n",
      "2025-04-30 17:09:57,738 - INFO -       1. arith.constant5 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,739 - INFO - \n",
      "    arith.constant6:\n",
      "2025-04-30 17:09:57,739 - INFO -       1. arith.constant6 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,740 - INFO - \n",
      "    arith.constant7:\n",
      "2025-04-30 17:09:57,743 - INFO -       1. arith.constant7 - Shape: [32 64]\n",
      "2025-04-30 17:09:57,744 - INFO - \n",
      "    arith.constant8:\n",
      "2025-04-30 17:09:57,744 - INFO -       1. arith.constant8 - Shape: [64 32]\n",
      "2025-04-30 17:09:57,745 - INFO - \n",
      "    arith.constant9:\n",
      "2025-04-30 17:09:57,745 - INFO -       1. arith.constant9 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,746 - INFO - \n",
      "    arith.constant10:\n",
      "2025-04-30 17:09:57,747 - INFO -       1. arith.constant10 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,747 - INFO - \n",
      "    arith.constant11:\n",
      "2025-04-30 17:09:57,748 - INFO -       1. arith.constant11 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,749 - INFO - \n",
      "    arith.constant12:\n",
      "2025-04-30 17:09:57,750 - INFO -       1. arith.constant12 - Shape: [32 32]\n",
      "2025-04-30 17:09:57,750 - INFO - \n",
      "    arith.constant13:\n",
      "2025-04-30 17:09:57,751 - INFO -       1. arith.constant13 - Shape: [32  8  1  3]\n",
      "2025-04-30 17:09:57,752 - INFO - \n",
      "    arith.constant14:\n",
      "2025-04-30 17:09:57,753 - INFO -       1. arith.constant14 - Shape: [ 1 32]\n",
      "2025-04-30 17:09:57,753 - INFO - \n",
      "    arith.constant15:\n",
      "2025-04-30 17:09:57,754 - INFO -       1. arith.constant15 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,755 - INFO - \n",
      "    arith.constant16:\n",
      "2025-04-30 17:09:57,755 - INFO -       1. arith.constant16 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,756 - INFO - \n",
      "    arith.constant17:\n",
      "2025-04-30 17:09:57,757 - INFO -       1. arith.constant17 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,758 - INFO - \n",
      "    arith.constant18:\n",
      "2025-04-30 17:09:57,759 - INFO -       1. arith.constant18 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,759 - INFO - \n",
      "    arith.constant19:\n",
      "2025-04-30 17:09:57,760 - INFO -       1. arith.constant19 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,760 - INFO - \n",
      "    arith.constant20:\n",
      "2025-04-30 17:09:57,761 - INFO -       1. arith.constant20 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,761 - INFO - \n",
      "    arith.constant21:\n",
      "2025-04-30 17:09:57,761 - INFO -       1. arith.constant21 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,762 - INFO - \n",
      "    arith.constant22:\n",
      "2025-04-30 17:09:57,763 - INFO -       1. arith.constant22 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,763 - INFO - \n",
      "    arith.constant23:\n",
      "2025-04-30 17:09:57,764 - INFO -       1. arith.constant23 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,765 - INFO - \n",
      "    arith.constant24:\n",
      "2025-04-30 17:09:57,765 - INFO -       1. arith.constant24 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,766 - INFO - \n",
      "    arith.constant25:\n",
      "2025-04-30 17:09:57,767 - INFO -       1. arith.constant25 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,767 - INFO - \n",
      "    arith.constant26:\n",
      "2025-04-30 17:09:57,768 - INFO -       1. arith.constant26 - Shape: [ 1  1 32]\n",
      "2025-04-30 17:09:57,768 - INFO - \n",
      "    arith.constant27:\n",
      "2025-04-30 17:09:57,768 - INFO -       1. arith.constant27 - Shape: [1]\n",
      "2025-04-30 17:09:57,769 - INFO - \n",
      "    arith.constant28:\n",
      "2025-04-30 17:09:57,770 - INFO -       1. arith.constant28 - Shape: [4 8]\n",
      "2025-04-30 17:09:57,771 - INFO - \n",
      "    arith.constant29:\n",
      "2025-04-30 17:09:57,771 - INFO -       1. arith.constant29 - Shape: [4 8]\n",
      "2025-04-30 17:09:57,772 - INFO - \n",
      "    arith.constant30:\n",
      "2025-04-30 17:09:57,772 - INFO -       1. arith.constant30 - Shape: [4 8]\n",
      "2025-04-30 17:09:57,773 - INFO - \n",
      "    arith.constant31:\n",
      "2025-04-30 17:09:57,774 - INFO -       1. arith.constant31 - Shape: [32]\n",
      "2025-04-30 17:09:57,774 - INFO - \n",
      "    arith.constant32:\n",
      "2025-04-30 17:09:57,775 - INFO -       1. arith.constant32 - Shape: [4 8]\n",
      "2025-04-30 17:09:57,776 - INFO - \n",
      "    arith.constant33:\n",
      "2025-04-30 17:09:57,776 - INFO -       1. arith.constant33 - Shape: [4]\n",
      "2025-04-30 17:09:57,777 - INFO - \n",
      "    arith.constant34:\n",
      "2025-04-30 17:09:57,778 - INFO -       1. arith.constant34 - Shape: [4]\n",
      "2025-04-30 17:09:57,779 - INFO - \n",
      "    arith.constant35:\n",
      "2025-04-30 17:09:57,779 - INFO -       1. arith.constant35 - Shape: [4]\n",
      "2025-04-30 17:09:57,780 - INFO - \n",
      "    arith.constant36:\n",
      "2025-04-30 17:09:57,780 - INFO -       1. arith.constant36 - Shape: [4 8]\n",
      "2025-04-30 17:09:57,781 - INFO - \n",
      "    arith.constant37:\n",
      "2025-04-30 17:09:57,782 - INFO -       1. arith.constant37 - Shape: [4 8]\n",
      "2025-04-30 17:09:57,782 - INFO - \n",
      "    arith.constant38:\n",
      "2025-04-30 17:09:57,783 - INFO -       1. arith.constant38 - Shape: [4]\n",
      "2025-04-30 17:09:57,784 - INFO - \n",
      "    arith.constant39:\n",
      "2025-04-30 17:09:57,784 - INFO -       1. arith.constant39 - Shape: [32]\n",
      "2025-04-30 17:09:57,785 - INFO - \n",
      "    arith.constant40:\n",
      "2025-04-30 17:09:57,786 - INFO -       1. arith.constant40 - Shape: [3]\n",
      "2025-04-30 17:09:57,787 - INFO - \n",
      "    arith.constant41:\n",
      "2025-04-30 17:09:57,787 - INFO -       1. arith.constant41 - Shape: []\n",
      "2025-04-30 17:09:57,788 - INFO - \n",
      "    arith.constant42:\n",
      "2025-04-30 17:09:57,788 - INFO -       1. arith.constant42 - Shape: []\n",
      "2025-04-30 17:09:57,789 - INFO - \n",
      "    arith.constant43:\n",
      "2025-04-30 17:09:57,789 - INFO -       1. arith.constant43 - Shape: [1]\n",
      "2025-04-30 17:09:57,790 - INFO - \n",
      "    arith.constant44:\n",
      "2025-04-30 17:09:57,791 - INFO -       1. arith.constant44 - Shape: []\n",
      "2025-04-30 17:09:57,792 - INFO - \n",
      "    arith.constant45:\n",
      "2025-04-30 17:09:57,794 - INFO -       1. arith.constant45 - Shape: [32]\n",
      "2025-04-30 17:09:57,795 - INFO - \n",
      "    arith.constant46:\n",
      "2025-04-30 17:09:57,795 - INFO -       1. arith.constant46 - Shape: [64]\n",
      "2025-04-30 17:09:57,796 - INFO - \n",
      "    arith.constant47:\n",
      "2025-04-30 17:09:57,797 - INFO -       1. arith.constant47 - Shape: [32]\n",
      "2025-04-30 17:09:57,798 - INFO - \n",
      "    arith.constant48:\n",
      "2025-04-30 17:09:57,799 - INFO -       1. arith.constant48 - Shape: [64]\n",
      "2025-04-30 17:09:57,802 - INFO - \n",
      "    arith.constant49:\n",
      "2025-04-30 17:09:57,802 - INFO -       1. arith.constant49 - Shape: [2]\n",
      "2025-04-30 17:09:57,803 - INFO - \n",
      "    trans_model_33_1:\n",
      "2025-04-30 17:09:57,803 - INFO -       1. trans_model_33_1/ExpandDims/dim - Shape: []\n",
      "2025-04-30 17:09:57,804 - INFO -       2. trans_model_33_1/ExpandDims - Shape: [ 1 64  1  3]\n",
      "2025-04-30 17:09:57,806 - INFO -       3. trans_model_33_1/conv_projection_1/BiasAdd;trans_model_33_1/conv_projection_1/convolution - Shape: [ 1 64  1 32]\n",
      "2025-04-30 17:09:57,807 - INFO -       4. trans_model_33_1/Squeeze - Shape: [ 1 64 32]\n",
      "2025-04-30 17:09:57,807 - INFO -       5. trans_model_33_1/layer_norm_1/moments/mean - Shape: [ 1 64  1]\n",
      "2025-04-30 17:09:57,808 - INFO -       ... and 115 more\n",
      "2025-04-30 17:09:57,809 - INFO - \n",
      "    :\n",
      "2025-04-30 17:09:57,810 - INFO -       1.  - Shape: [3]\n",
      "2025-04-30 17:09:57,811 - INFO -       2.  - Shape: [1]\n",
      "2025-04-30 17:09:57,812 - INFO -       3.  - Shape: [64]\n",
      "2025-04-30 17:09:57,814 - INFO -       4.  - Shape: [3]\n",
      "2025-04-30 17:09:57,815 - INFO -       5.  - Shape: [1]\n",
      "2025-04-30 17:09:57,817 - INFO -       ... and 38 more\n",
      "2025-04-30 17:09:57,819 - INFO - \n",
      "    BatchMatMul_scratch_buffer:\n",
      "2025-04-30 17:09:57,821 - INFO -       1. BatchMatMul_scratch_buffer - Shape: [ 1  4 64  8]\n",
      "2025-04-30 17:09:57,822 - INFO -       2. BatchMatMul_scratch_buffer - Shape: [ 1  4  8 64]\n",
      "2025-04-30 17:09:57,824 - INFO -       3. BatchMatMul_scratch_buffer - Shape: [ 1  4 64  8]\n",
      "2025-04-30 17:09:57,825 - INFO -       4. BatchMatMul_scratch_buffer - Shape: [ 1  4  8 64]\n",
      "2025-04-30 17:09:57,826 - INFO - \n",
      "    Conv_hwcn_weights:\n",
      "2025-04-30 17:09:57,827 - INFO -       1. Conv_hwcn_weights - Shape: [24 32]\n",
      "2025-04-30 17:09:57,829 - INFO - \n",
      "  TFLite Operation Types:\n",
      "2025-04-30 17:09:57,830 - INFO -     1. ExpandDims\n",
      "2025-04-30 17:09:57,831 - INFO -     2. Squeeze\n",
      "2025-04-30 17:09:57,833 - INFO -     3. add\n",
      "2025-04-30 17:09:57,833 - INFO -     4. add_1\n",
      "2025-04-30 17:09:57,834 - INFO -     5. add_2\n",
      "2025-04-30 17:09:57,835 - INFO -     6. add_3\n",
      "2025-04-30 17:09:57,836 - INFO -     7. conv_projection_1\n",
      "2025-04-30 17:09:57,837 - INFO -     8. ffn_0_1\n",
      "2025-04-30 17:09:57,837 - INFO -     9. ffn_1_1\n",
      "2025-04-30 17:09:57,838 - INFO -     10. final_norm_1\n",
      "2025-04-30 17:09:57,839 - INFO -     11. global_pool_1\n",
      "2025-04-30 17:09:57,840 - INFO -     12. layer_norm_1\n",
      "2025-04-30 17:09:57,840 - INFO -     13. ln0_0_1\n",
      "2025-04-30 17:09:57,841 - INFO -     14. ln0_1_1\n",
      "2025-04-30 17:09:57,841 - INFO -     15. ln1_0_1\n",
      "2025-04-30 17:09:57,842 - INFO -     16. ln1_1_1\n",
      "2025-04-30 17:09:57,843 - INFO -     17. mha_0_1\n",
      "2025-04-30 17:09:57,844 - INFO -     18. mha_1_1\n",
      "2025-04-30 17:09:57,845 - INFO -     19. output_dense_1\n",
      "2025-04-30 17:09:57,845 - INFO - \n",
      "=== Shape Comparison ===\n",
      "2025-04-30 17:09:57,847 - INFO - ✓ Input shapes match (ignoring batch dimension).\n",
      "2025-04-30 17:09:57,848 - INFO - ✓ Output shapes match.\n",
      "2025-04-30 17:09:57,849 - INFO - Generated random input for inference comparison.\n",
      "2025-04-30 17:09:57,850 - INFO - \n",
      "=== Inference Comparison ===\n",
      "2025-04-30 17:09:57,850 - INFO - Running Keras model inference...\n",
      "2025-04-30 17:09:57,944 - INFO - Running TFLite model inference...\n",
      "2025-04-30 17:09:57,945 - INFO - Comparing outputs...\n",
      "2025-04-30 17:09:57,947 - INFO - Mean Squared Error between outputs: 0.0000000000\n",
      "2025-04-30 17:09:57,948 - INFO - ✓ Outputs are approximately equal (MSE < 1e-5).\n",
      "2025-04-30 17:09:57,949 - INFO - \n",
      "Sample output values:\n",
      "2025-04-30 17:09:57,950 - INFO -   Value 1: Keras=-0.304753, TFLite=-0.304753, Diff=0.000000\n",
      "2025-04-30 17:09:57,951 - INFO - \n",
      "=== Model Size Comparison ===\n",
      "2025-04-30 17:09:57,953 - INFO - Keras model size (.keras): 0.15 MB\n",
      "2025-04-30 17:09:57,954 - INFO - Weights size (.weights.h5): 0.15 MB\n",
      "2025-04-30 17:09:57,955 - INFO - TFLite model size: 0.09 MB\n",
      "2025-04-30 17:09:57,955 - INFO - Size reduction: 39.49%\n",
      "2025-04-30 17:09:57,956 - INFO - \n",
      "=== TFLite Model Analysis ===\n",
      "2025-04-30 17:09:57,957 - INFO - Total Keras parameters: 18,049\n",
      "2025-04-30 17:09:57,957 - INFO - Model does not use quantization.\n",
      "2025-04-30 17:09:57,958 - INFO - \n",
      "=== Compatibility Check ===\n",
      "2025-04-30 17:09:57,959 - INFO - ✓ Keras model can be loaded and executed\n",
      "2025-04-30 17:09:57,960 - INFO - ✓ TFLite model can be loaded and executed\n",
      "2025-04-30 17:09:57,960 - INFO - ✓ Inference results match (MSE < 1e-5)\n",
      "2025-04-30 17:09:57,961 - INFO - ✓ Input shapes match\n",
      "2025-04-30 17:09:57,962 - INFO - ✓ Output shapes match\n",
      "2025-04-30 17:09:57,962 - INFO - \n",
      "=== Comparison Complete ===\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "import shutil\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define and register the custom TransModel class\n",
    "@register_keras_serializable(package=\"CustomModels\")\n",
    "class TransModel(tf.keras.Model):\n",
    "    def __init__(self, acc_frames=64, num_classes=1, num_heads=4, acc_coords=3, embed_dim=32, num_layers=2, dropout=0.5, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.acc_frames = acc_frames\n",
    "        self.num_classes = num_classes\n",
    "        self.num_heads = num_heads\n",
    "        self.acc_coords = acc_coords\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Define layers\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(filters=embed_dim, kernel_size=(8, 1), padding='same', name=\"conv_projection\")\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"layer_norm\")\n",
    "        self.attention_layers = [\n",
    "            tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=dropout, name=f\"mha_{i}\")\n",
    "            for i in range(num_layers)\n",
    "        ]\n",
    "        self.ffn_layers = [\n",
    "            tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(embed_dim * 2, activation=activation, name=f\"ffn_dense1_{i}\"),\n",
    "                tf.keras.layers.Dropout(dropout),\n",
    "                tf.keras.layers.Dense(embed_dim, name=f\"ffn_dense2_{i}\"),\n",
    "                tf.keras.layers.Dropout(dropout)\n",
    "            ], name=f\"ffn_{i}\")\n",
    "            for i in range(num_layers)\n",
    "        ]\n",
    "        self.layer_norms = [\n",
    "            [tf.keras.layers.LayerNormalization(epsilon=1e-6, name=f\"ln{i}_{j}\") for j in range(2)]\n",
    "            for i in range(num_layers)\n",
    "        ]\n",
    "        self.final_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"final_norm\")\n",
    "        self.global_pool = tf.keras.layers.GlobalAveragePooling1D(name=\"global_pool\")\n",
    "        self.output_dense = tf.keras.layers.Dense(num_classes, name=\"output_dense\")\n",
    "        \n",
    "        # Initialize with a dummy input to ensure the model is built\n",
    "        dummy_input = tf.zeros((1, acc_frames, acc_coords), dtype=tf.float32)\n",
    "        self(dummy_input, training=False)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs.get('accelerometer', inputs) if isinstance(inputs, dict) else inputs\n",
    "        x = tf.expand_dims(x, axis=2)  # Add channel dimension for Conv2D\n",
    "        x = self.conv_layer(x)\n",
    "        x = tf.squeeze(x, axis=2)  # Remove channel dimension\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        # Transformer layers\n",
    "        for i in range(self.num_layers):\n",
    "            attn = self.attention_layers[i](x, x, training=training)\n",
    "            x = self.layer_norms[i][0](x + attn)  # Residual + normalization\n",
    "            ffn = self.ffn_layers[i](x, training=training)\n",
    "            x = self.layer_norms[i][1](x + ffn)  # Residual + normalization\n",
    "            \n",
    "        x = self.final_norm(x)\n",
    "        x = self.global_pool(x)\n",
    "        logits = self.output_dense(x)\n",
    "        return tf.reshape(logits, [-1, self.num_classes])\n",
    "    \n",
    "    # Add get_config method for proper serialization\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"acc_frames\": self.acc_frames,\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"acc_coords\": self.acc_coords,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "            \"activation\": self.activation\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    # Add TFLite export functionality\n",
    "    def export_to_tflite(self, save_path, input_shape=None):\n",
    "        \"\"\"\n",
    "        Export the model to TFLite format\n",
    "        \n",
    "        Args:\n",
    "            save_path (str): Path to save the TFLite model\n",
    "            input_shape (tuple, optional): Input shape for the model. Defaults to (1, acc_frames, acc_coords).\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if export was successful, False otherwise\n",
    "        \"\"\"\n",
    "        if input_shape is None:\n",
    "            input_shape = (1, self.acc_frames, self.acc_coords)\n",
    "            \n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)\n",
    "            save_path = save_path if save_path.endswith('.tflite') else f\"{save_path}.tflite\"\n",
    "            logger.info(f\"Exporting to TFLite: {save_path}, shape={input_shape}\")\n",
    "\n",
    "            # Define a wrapper model to ensure proper input signature\n",
    "            class TFLiteModel(tf.keras.Model):\n",
    "                def __init__(self, parent):\n",
    "                    super().__init__()\n",
    "                    self.parent = parent\n",
    "\n",
    "                @tf.function(input_signature=[tf.TensorSpec(shape=input_shape, dtype=tf.float32, name='accelerometer')])\n",
    "                def call(self, inputs):\n",
    "                    return self.parent({'accelerometer': inputs}, training=False)\n",
    "\n",
    "            tflite_model = TFLiteModel(self)\n",
    "            \n",
    "            # Create a temporary directory for the SavedModel\n",
    "            temp_dir = os.path.join(os.path.dirname(save_path) or '.', \"temp_savedmodel\")\n",
    "            if os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "            # Save the model with signatures\n",
    "            tf.saved_model.save(\n",
    "                tflite_model, \n",
    "                temp_dir, \n",
    "                signatures={'serving_default': tflite_model.call}\n",
    "            )\n",
    "            \n",
    "            # Convert to TFLite\n",
    "            converter = tf.lite.TFLiteConverter.from_saved_model(temp_dir)\n",
    "            converter.target_spec.supported_ops = [\n",
    "                tf.lite.OpsSet.TFLITE_BUILTINS, \n",
    "                tf.lite.OpsSet.SELECT_TF_OPS\n",
    "            ]\n",
    "            converter.inference_input_type = tf.float32\n",
    "            converter.inference_output_type = tf.float32\n",
    "            tflite_content = converter.convert()\n",
    "\n",
    "            # Save TFLite model\n",
    "            with open(save_path, 'wb') as f:\n",
    "                f.write(tflite_content)\n",
    "                \n",
    "            # Clean up temporary directory\n",
    "            shutil.rmtree(temp_dir)\n",
    "            logger.info(f\"TFLite model successfully saved: {save_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"TFLite export failed: {e}\\n{traceback.format_exc()}\")\n",
    "            if 'temp_dir' in locals() and os.path.exists(temp_dir):\n",
    "                shutil.rmtree(temp_dir)\n",
    "            return False\n",
    "\n",
    "\n",
    "def get_keras_layer_info(model):\n",
    "    \"\"\"Extract layer information from a Keras model\"\"\"\n",
    "    try:\n",
    "        layers_info = []\n",
    "        for layer in model.layers:\n",
    "            layer_info = {\n",
    "                'name': layer.name,\n",
    "                'type': layer.__class__.__name__,\n",
    "                'trainable': layer.trainable,\n",
    "                'params': layer.count_params()\n",
    "            }\n",
    "            \n",
    "            # Try to extract shape information if available\n",
    "            try:\n",
    "                if hasattr(layer, 'output_shape'):\n",
    "                    layer_info['output_shape'] = str(layer.output_shape)\n",
    "                if hasattr(layer, 'input_shape'):\n",
    "                    layer_info['input_shape'] = str(layer.input_shape)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            # If it's a Sequential model, get info about its layers\n",
    "            if isinstance(layer, tf.keras.Sequential):\n",
    "                sublayers = []\n",
    "                for sublayer in layer.layers:\n",
    "                    sublayer_info = {\n",
    "                        'name': sublayer.name,\n",
    "                        'type': sublayer.__class__.__name__,\n",
    "                        'trainable': sublayer.trainable,\n",
    "                        'params': sublayer.count_params()\n",
    "                    }\n",
    "                    sublayers.append(sublayer_info)\n",
    "                layer_info['sublayers'] = sublayers\n",
    "                \n",
    "            layers_info.append(layer_info)\n",
    "        return layers_info\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to extract Keras layer info: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_tflite_tensor_info(interpreter):\n",
    "    \"\"\"Extract tensor information from a TFLite interpreter\"\"\"\n",
    "    try:\n",
    "        # Get tensor details from the interpreter\n",
    "        tensor_details = interpreter.get_tensor_details()\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        \n",
    "        # Organize tensors by their role\n",
    "        tensors_info = []\n",
    "        for tensor in tensor_details:\n",
    "            tensor_idx = tensor['index']\n",
    "            tensor_info = {\n",
    "                'index': tensor_idx,\n",
    "                'name': tensor['name'],\n",
    "                'shape': str(tensor['shape']),\n",
    "                'dtype': str(tensor['dtype']),\n",
    "                'quantization': str(tensor.get('quantization', 'None')),\n",
    "                'is_input': any(detail['index'] == tensor_idx for detail in input_details),\n",
    "                'is_output': any(detail['index'] == tensor_idx for detail in output_details),\n",
    "                'role': 'INTERMEDIATE'\n",
    "            }\n",
    "            \n",
    "            if tensor_info['is_input']:\n",
    "                tensor_info['role'] = 'INPUT'\n",
    "            elif tensor_info['is_output']:\n",
    "                tensor_info['role'] = 'OUTPUT'\n",
    "                \n",
    "            tensors_info.append(tensor_info)\n",
    "            \n",
    "        return tensors_info\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to extract TFLite tensor info: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def compare_keras_tflite(keras_model_path, tflite_model_path, weights_path=None, sample_input=None, model_architecture=None):\n",
    "    \"\"\"\n",
    "    Compare a Keras TransModel with its TFLite version for robustness and compatibility.\n",
    "    \n",
    "    Args:\n",
    "        keras_model_path (str): Path to the .keras model file.\n",
    "        tflite_model_path (str): Path to the .tflite model file (or where it will be saved if converted).\n",
    "        weights_path (str, optional): Path to the .weights.h5 file if .keras is unavailable.\n",
    "        sample_input (np.ndarray, optional): Sample input for inference comparison.\n",
    "        model_architecture (callable, optional): Function to define model architecture if using .weights.h5.\n",
    "    \"\"\"\n",
    "    keras_model = None\n",
    "    \n",
    "    # Load or create Keras model\n",
    "    try:\n",
    "        if os.path.exists(keras_model_path):\n",
    "            logger.info(f\"Loading Keras model from: {keras_model_path}\")\n",
    "            keras_model = tf.keras.models.load_model(\n",
    "                keras_model_path, \n",
    "                custom_objects={'TransModel': TransModel}\n",
    "            )\n",
    "            logger.info(\"Keras model loaded from .keras file.\")\n",
    "        elif weights_path and model_architecture and os.path.exists(weights_path):\n",
    "            logger.info(f\"Creating model and loading weights from: {weights_path}\")\n",
    "            keras_model = model_architecture()\n",
    "            keras_model.load_weights(weights_path)\n",
    "            logger.info(\"Keras model loaded from .weights.h5 with provided architecture.\")\n",
    "        else:\n",
    "            logger.info(\"Creating new model instance\")\n",
    "            keras_model = model_architecture() if model_architecture else TransModel()\n",
    "            logger.info(\"New TransModel instance created.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load/create Keras model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Ensure model is built\n",
    "    try:\n",
    "        dummy_input = np.zeros((1, 64, 3), dtype=np.float32)\n",
    "        _ = keras_model(dummy_input)\n",
    "        logger.info(\"Keras model built successfully with dummy input.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to build model: {e}\")\n",
    "    \n",
    "    # Log Keras model details\n",
    "    logger.info(\"\\n=== Keras Model Details ===\")\n",
    "    \n",
    "    # Variables to store shapes for comparison\n",
    "    keras_input_shape_list = None\n",
    "    keras_output_shape_list = None\n",
    "    tflite_input_shape_list = None\n",
    "    tflite_output_shape_list = None\n",
    "    \n",
    "    # Get shapes by inference instead of direct attribute access\n",
    "    try:\n",
    "        dummy_input = np.zeros((1, 64, 3), dtype=np.float32)\n",
    "        test_output = keras_model.predict(dummy_input, verbose=0)\n",
    "        keras_input_shape_list = [None, 64, 3]  # Input shape is known from our dummy input pattern\n",
    "        keras_output_shape_list = list(test_output.shape)\n",
    "        logger.info(f\"Keras Input Shape (inferred): {keras_input_shape_list}\")\n",
    "        logger.info(f\"Keras Output Shape (inferred): {keras_output_shape_list}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to infer shapes: {e}\")\n",
    "    \n",
    "    # Extract keras layer information\n",
    "    keras_layers = get_keras_layer_info(keras_model)\n",
    "    \n",
    "    # Convert to TFLite if necessary\n",
    "    if not os.path.exists(tflite_model_path):\n",
    "        try:\n",
    "            logger.info(f\"Converting model to TFLite: {tflite_model_path}\")\n",
    "            # Try to use the built-in export method if it's a TransModel instance\n",
    "            if isinstance(keras_model, TransModel):\n",
    "                logger.info(\"Using TransModel's built-in TFLite export method\")\n",
    "                success = keras_model.export_to_tflite(tflite_model_path)\n",
    "                if not success:\n",
    "                    raise ValueError(\"Export failed using TransModel's export_to_tflite method\")\n",
    "            else:\n",
    "                # Fallback to generic conversion\n",
    "                logger.info(\"Using generic TFLite conversion\")\n",
    "                @tf.function(input_signature=[tf.TensorSpec(shape=(None, 64, 3), dtype=tf.float32)])\n",
    "                def model_func(inputs):\n",
    "                    return keras_model(inputs, training=False)\n",
    "                concrete_func = model_func.get_concrete_function()\n",
    "                converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "                tflite_model = converter.convert()\n",
    "                with open(tflite_model_path, 'wb') as f:\n",
    "                    f.write(tflite_model)\n",
    "            logger.info(f\"Converted Keras model to TFLite and saved to {tflite_model_path}.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to convert Keras model to TFLite: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        logger.info(f\"Using existing TFLite model at {tflite_model_path}.\")\n",
    "    \n",
    "    # Load TFLite model\n",
    "    try:\n",
    "        logger.info(f\"Loading TFLite model from {tflite_model_path}\")\n",
    "        interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "        interpreter.allocate_tensors()\n",
    "        logger.info(\"TFLite model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load TFLite model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Get TFLite model details\n",
    "    logger.info(\"\\n=== TFLite Model Details ===\")\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    tflite_input_shape = input_details[0]['shape']\n",
    "    tflite_output_shape = output_details[0]['shape']\n",
    "    tflite_input_shape_list = list(tflite_input_shape)\n",
    "    tflite_output_shape_list = list(tflite_output_shape)\n",
    "    logger.info(f\"TFLite Input Shape: {tflite_input_shape_list}\")\n",
    "    logger.info(f\"TFLite Output Shape: {tflite_output_shape_list}\")\n",
    "    logger.info(f\"TFLite Input Data Type: {input_details[0]['dtype']}\")\n",
    "    \n",
    "    # Extract TFLite tensor information\n",
    "    tflite_tensors = get_tflite_tensor_info(interpreter)\n",
    "    \n",
    "    # Compare and display layer information\n",
    "    logger.info(\"\\n=== Layer/Operator Comparison ===\")\n",
    "    logger.info(f\"Keras model has {len(keras_layers)} main layers\")\n",
    "    logger.info(f\"TFLite model has {len(tflite_tensors)} tensors\")\n",
    "    \n",
    "    # Display Keras layers\n",
    "    logger.info(\"\\nKeras Layers:\")\n",
    "    for i, layer in enumerate(keras_layers):\n",
    "        logger.info(f\"  {i+1}. {layer['name']} ({layer['type']}) - Params: {layer['params']}\")\n",
    "        if 'input_shape' in layer:\n",
    "            logger.info(f\"     Input shape: {layer['input_shape']}\")\n",
    "        if 'output_shape' in layer:\n",
    "            logger.info(f\"     Output shape: {layer['output_shape']}\")\n",
    "        if 'sublayers' in layer:\n",
    "            for j, sublayer in enumerate(layer['sublayers']):\n",
    "                logger.info(f\"       {j+1}. {sublayer['name']} ({sublayer['type']}) - Params: {sublayer['params']}\")\n",
    "    \n",
    "    # Display TFLite tensors\n",
    "    logger.info(\"\\nTFLite Tensors:\")\n",
    "    \n",
    "    # First show inputs and outputs\n",
    "    input_tensors = [t for t in tflite_tensors if t['is_input']]\n",
    "    output_tensors = [t for t in tflite_tensors if t['is_output']]\n",
    "    intermediate_tensors = [t for t in tflite_tensors if not t['is_input'] and not t['is_output']]\n",
    "    \n",
    "    # Show inputs\n",
    "    if input_tensors:\n",
    "        logger.info(\"\\n  Input Tensors:\")\n",
    "        for i, tensor in enumerate(input_tensors):\n",
    "            logger.info(f\"    {i+1}. {tensor['name']} - Shape: {tensor['shape']}, Type: {tensor['dtype']}\")\n",
    "    \n",
    "    # Show outputs\n",
    "    if output_tensors:\n",
    "        logger.info(\"\\n  Output Tensors:\")\n",
    "        for i, tensor in enumerate(output_tensors):\n",
    "            logger.info(f\"    {i+1}. {tensor['name']} - Shape: {tensor['shape']}, Type: {tensor['dtype']}\")\n",
    "    \n",
    "    # Show intermediate tensors (operators)\n",
    "    if intermediate_tensors:\n",
    "        logger.info(\"\\n  Intermediate Tensors (operators):\")\n",
    "        # Group by tensor name to identify patterns\n",
    "        tensor_groups = {}\n",
    "        \n",
    "        for tensor in intermediate_tensors:\n",
    "            name_parts = tensor['name'].split('/')\n",
    "            base_name = name_parts[0] if len(name_parts) > 0 else tensor['name']\n",
    "            \n",
    "            if base_name not in tensor_groups:\n",
    "                tensor_groups[base_name] = []\n",
    "            tensor_groups[base_name].append(tensor)\n",
    "        \n",
    "        # Display tensor groups\n",
    "        for group_name, tensors in tensor_groups.items():\n",
    "            logger.info(f\"\\n    {group_name}:\")\n",
    "            for i, tensor in enumerate(tensors[:5]):  # Show only first 5 tensors per group\n",
    "                logger.info(f\"      {i+1}. {tensor['name']} - Shape: {tensor['shape']}\")\n",
    "            if len(tensors) > 5:\n",
    "                logger.info(f\"      ... and {len(tensors) - 5} more\")\n",
    "    \n",
    "    # Display TFLite operator summary\n",
    "    try:\n",
    "        # Try to get number of operations in the model\n",
    "        op_codes = set()\n",
    "        for i, tensor in enumerate(tflite_tensors):\n",
    "            name_parts = tensor['name'].split('/')\n",
    "            if len(name_parts) > 1:\n",
    "                op_type = name_parts[1].split(':')[0] if ':' in name_parts[1] else name_parts[1]\n",
    "                op_codes.add(op_type)\n",
    "        \n",
    "        if op_codes:\n",
    "            logger.info(\"\\n  TFLite Operation Types:\")\n",
    "            for i, op_type in enumerate(sorted(op_codes)):\n",
    "                logger.info(f\"    {i+1}. {op_type}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not extract TFLite operation types: {e}\")\n",
    "    \n",
    "    # Compare shapes\n",
    "    logger.info(\"\\n=== Shape Comparison ===\")\n",
    "    try:\n",
    "        # Check if we have both input shapes for comparison\n",
    "        if keras_input_shape_list is not None and tflite_input_shape_list is not None:\n",
    "            # Compare all except batch dimension\n",
    "            keras_rest = keras_input_shape_list[1:]\n",
    "            tflite_rest = tflite_input_shape_list[1:]\n",
    "            \n",
    "            shapes_match = True\n",
    "            for i in range(len(keras_rest)):\n",
    "                if i >= len(tflite_rest) or keras_rest[i] != tflite_rest[i]:\n",
    "                    shapes_match = False\n",
    "                    break\n",
    "            \n",
    "            if shapes_match:\n",
    "                logger.info(\"✓ Input shapes match (ignoring batch dimension).\")\n",
    "            else:\n",
    "                logger.warning(f\"✗ Input shapes differ: Keras {keras_input_shape_list} vs TFLite {tflite_input_shape_list}\")\n",
    "        else:\n",
    "            logger.info(f\"⚠ Full shape comparison unavailable - displaying separately:\")\n",
    "            logger.info(f\"  Keras input (inferred): {keras_input_shape_list}\")\n",
    "            logger.info(f\"  TFLite input: {tflite_input_shape_list}\")\n",
    "        \n",
    "        # Check if we have both output shapes for comparison\n",
    "        if keras_output_shape_list is not None and tflite_output_shape_list is not None:\n",
    "            output_shapes_match = True\n",
    "            for i in range(len(keras_output_shape_list)):\n",
    "                if i >= len(tflite_output_shape_list) or keras_output_shape_list[i] != tflite_output_shape_list[i]:\n",
    "                    output_shapes_match = False\n",
    "                    break\n",
    "                    \n",
    "            if output_shapes_match:\n",
    "                logger.info(\"✓ Output shapes match.\")\n",
    "            else:\n",
    "                logger.warning(f\"✗ Output shapes differ: Keras {keras_output_shape_list} vs TFLite {tflite_output_shape_list}\")\n",
    "        else:\n",
    "            logger.info(f\"⚠ Output shape comparison unavailable - displaying separately:\")\n",
    "            logger.info(f\"  Keras output (inferred): {keras_output_shape_list}\")\n",
    "            logger.info(f\"  TFLite output: {tflite_output_shape_list}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during shape comparison: {e}\")\n",
    "    \n",
    "    # Generate sample input if not provided\n",
    "    if sample_input is None:\n",
    "        sample_input = np.random.randn(1, 64, 3).astype(np.float32)\n",
    "        logger.info(\"Generated random input for inference comparison.\")\n",
    "    \n",
    "    # Perform inference and compare outputs\n",
    "    logger.info(\"\\n=== Inference Comparison ===\")\n",
    "    try:\n",
    "        logger.info(\"Running Keras model inference...\")\n",
    "        keras_output = keras_model.predict(sample_input, verbose=0)\n",
    "        \n",
    "        logger.info(\"Running TFLite model inference...\")\n",
    "        interpreter.set_tensor(input_details[0]['index'], sample_input)\n",
    "        interpreter.invoke()\n",
    "        tflite_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        logger.info(\"Comparing outputs...\")\n",
    "        mse = mean_squared_error(keras_output.flatten(), tflite_output.flatten())\n",
    "        logger.info(f\"Mean Squared Error between outputs: {mse:.10f}\")\n",
    "        \n",
    "        # Store MSE for later use\n",
    "        outputs_match = mse < 1e-5\n",
    "        \n",
    "        if outputs_match:\n",
    "            logger.info(\"✓ Outputs are approximately equal (MSE < 1e-5).\")\n",
    "        else:\n",
    "            logger.warning(f\"✗ Outputs differ significantly (MSE = {mse:.10f}).\")\n",
    "            \n",
    "        # Display sample values from both outputs\n",
    "        logger.info(\"\\nSample output values:\")\n",
    "        keras_flat = keras_output.flatten()\n",
    "        tflite_flat = tflite_output.flatten()\n",
    "        num_samples = min(5, len(keras_flat))\n",
    "        for i in range(num_samples):\n",
    "            logger.info(f\"  Value {i+1}: Keras={keras_flat[i]:.6f}, TFLite={tflite_flat[i]:.6f}, Diff={abs(keras_flat[i]-tflite_flat[i]):.6f}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to compare outputs: {e}\")\n",
    "        outputs_match = False\n",
    "    \n",
    "    # Compare model sizes\n",
    "    logger.info(\"\\n=== Model Size Comparison ===\")\n",
    "    try:\n",
    "        keras_size = os.path.getsize(keras_model_path) / (1024 * 1024) if os.path.exists(keras_model_path) else 0\n",
    "        weights_size = os.path.getsize(weights_path) / (1024 * 1024) if weights_path and os.path.exists(weights_path) else 0\n",
    "        tflite_size = os.path.getsize(tflite_model_path) / (1024 * 1024)\n",
    "        \n",
    "        if keras_size:\n",
    "            logger.info(f\"Keras model size (.keras): {keras_size:.2f} MB\")\n",
    "        if weights_size:\n",
    "            logger.info(f\"Weights size (.weights.h5): {weights_size:.2f} MB\")\n",
    "        logger.info(f\"TFLite model size: {tflite_size:.2f} MB\")\n",
    "        \n",
    "        if keras_size and tflite_size:\n",
    "            reduction = (1 - tflite_size/keras_size) * 100\n",
    "            logger.info(f\"Size reduction: {reduction:.2f}%\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to compute model sizes: {e}\")\n",
    "    \n",
    "    # Additional analysis\n",
    "    logger.info(\"\\n=== TFLite Model Analysis ===\")\n",
    "    try:\n",
    "        # Count parameters\n",
    "        keras_params = sum(layer['params'] for layer in keras_layers)\n",
    "        logger.info(f\"Total Keras parameters: {keras_params:,}\")\n",
    "        \n",
    "        # Check for quantization\n",
    "        quantized_tensors = [t for t in tflite_tensors if 'quantization' in t and t['quantization'] != 'None' and 'scale' in str(t['quantization'])]\n",
    "        if quantized_tensors:\n",
    "            logger.info(f\"Model has {len(quantized_tensors)} quantized tensors.\")\n",
    "            quant_types = set(t['dtype'] for t in quantized_tensors)\n",
    "            logger.info(f\"Quantization data types: {', '.join(str(t) for t in quant_types)}\")\n",
    "        else:\n",
    "            logger.info(\"Model does not use quantization.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to perform additional analysis: {e}\")\n",
    "    \n",
    "    # Provide compatibility summary\n",
    "    logger.info(\"\\n=== Compatibility Check ===\")\n",
    "    logger.info(\"✓ Keras model can be loaded and executed\")\n",
    "    logger.info(\"✓ TFLite model can be loaded and executed\")\n",
    "    \n",
    "    # Safe checks for shape comparison results\n",
    "    if 'outputs_match' in locals():\n",
    "        match_text = \"match (MSE < 1e-5)\" if outputs_match else f\"differ (MSE = {mse:.10f})\"\n",
    "        logger.info(f\"✓ Inference results {match_text}\")\n",
    "    \n",
    "    input_shapes_match = False\n",
    "    if keras_input_shape_list is not None and tflite_input_shape_list is not None:\n",
    "        if len(keras_input_shape_list) > 1 and len(tflite_input_shape_list) > 1:\n",
    "            input_shapes_match = keras_input_shape_list[1:] == tflite_input_shape_list[1:]\n",
    "            match_symbol = \"✓\" if input_shapes_match else \"✗\"\n",
    "            match_text = \"match\" if input_shapes_match else \"differ\"\n",
    "            logger.info(f\"{match_symbol} Input shapes {match_text}\")\n",
    "    \n",
    "    output_shapes_match = False\n",
    "    if keras_output_shape_list is not None and tflite_output_shape_list is not None:\n",
    "        output_shapes_match = keras_output_shape_list == tflite_output_shape_list\n",
    "        match_symbol = \"✓\" if output_shapes_match else \"✗\"\n",
    "        match_text = \"match\" if output_shapes_match else \"differ\"\n",
    "        logger.info(f\"{match_symbol} Output shapes {match_text}\")\n",
    "    \n",
    "    logger.info(\"\\n=== Comparison Complete ===\")\n",
    "    return keras_model, interpreter\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    keras_model_path = \"student_model_31.keras\"\n",
    "    tflite_model_path = \"student_model_31.tflite\"\n",
    "    weights_path = \"student_model_31.weights.h5\"\n",
    "    \n",
    "    # Define a function to create a new instance of TransModel\n",
    "    def create_trans_model():\n",
    "        return TransModel()\n",
    "    \n",
    "    # Run comparison\n",
    "    compare_keras_tflite(\n",
    "        keras_model_path, \n",
    "        tflite_model_path, \n",
    "        weights_path=weights_path, \n",
    "        model_architecture=create_trans_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a9363-3363-45cf-a46c-7afd686f4878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489351f-087e-4cb1-a97f-ec7dcd1bf6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_EDGE_TORCH",
   "language": "python",
   "name": "ai_edge_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
