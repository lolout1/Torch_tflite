{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bdf1a51-8727-40fc-8716-77327487783b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping ai-edge-torch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: ai-edge-torch-nightly 0.3.0.dev20250218\n",
      "Uninstalling ai-edge-torch-nightly-0.3.0.dev20250218:\n",
      "  Successfully uninstalled ai-edge-torch-nightly-0.3.0.dev20250218\n",
      "\u001b[33mWARNING: Skipping ai-edge-quantizer as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: ai-edge-quantizer-nightly 0.0.1.dev20250218\n",
      "Uninstalling ai-edge-quantizer-nightly-0.0.1.dev20250218:\n",
      "  Successfully uninstalled ai-edge-quantizer-nightly-0.0.1.dev20250218\n",
      "Collecting ai-edge-torch-nightly\n",
      "  Using cached ai_edge_torch_nightly-0.3.0.dev20250218-py3-none-any.whl (381 kB)\n",
      "Collecting ai-edge-quantizer-nightly\n",
      "  Using cached ai_edge_quantizer_nightly-0.0.1.dev20250218-py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: ai-edge-litert-nightly in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (1.1.2.dev20250217)\n",
      "Requirement already satisfied: torch>=2.4.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (2.5.0)\n",
      "Requirement already satisfied: tf-nightly>=2.19.0.dev20250101 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (2.20.0.dev20250211)\n",
      "Requirement already satisfied: safetensors in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (0.4.5)\n",
      "Requirement already satisfied: scipy in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (1.14.1)\n",
      "Requirement already satisfied: numpy in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (2.1.2)\n",
      "Requirement already satisfied: torch-xla2[odml]>=0.0.1.dev20241201 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (0.0.1.dev202412041639)\n",
      "Requirement already satisfied: tabulate in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (0.9.0)\n",
      "Requirement already satisfied: jax in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-torch-nightly) (0.5.0)\n",
      "Requirement already satisfied: immutabledict in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from ai-edge-quantizer-nightly) (4.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (2.5.0)\n",
      "Requirement already satisfied: tb-nightly~=2.19.0.a in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (2.19.0a20241018)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (18.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (1.67.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.37.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (4.12.2)\n",
      "Requirement already satisfied: keras-nightly>=3.6.0.dev in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.6.0.dev2024101603)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (1.6.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.12.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (1.16.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (2.32.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (5.28.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.2.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.5.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (24.3.25)\n",
      "Requirement already satisfied: packaging in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (24.1)\n",
      "Requirement already satisfied: setuptools in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (59.6.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (9.1.0.70)\n",
      "Requirement already satisfied: filelock in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.16.1)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.1.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (10.3.5.147)\n",
      "Requirement already satisfied: networkx in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.4.1)\n",
      "Requirement already satisfied: fsspec in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.4.0->ai-edge-torch-nightly) (1.3.0)\n",
      "Requirement already satisfied: pytest in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from torch-xla2[odml]>=0.0.1.dev20241201->ai-edge-torch-nightly) (8.3.4)\n",
      "Requirement already satisfied: jaxlib<=0.5.0,>=0.5.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from jax->ai-edge-torch-nightly) (0.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from astunparse>=1.6.0->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.44.0)\n",
      "Requirement already satisfied: optree in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.13.0)\n",
      "Requirement already satisfied: rich in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (13.9.2)\n",
      "Requirement already satisfied: namex in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.0.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (2024.8.30)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tb-nightly~=2.19.0.a->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tb-nightly~=2.19.0.a->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from tb-nightly~=2.19.0.a->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->ai-edge-torch-nightly) (3.0.2)\n",
      "Requirement already satisfied: iniconfig in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from pytest->torch-xla2[odml]>=0.0.1.dev20241201->ai-edge-torch-nightly) (2.0.0)\n",
      "Requirement already satisfied: tomli>=1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from pytest->torch-xla2[odml]>=0.0.1.dev20241201->ai-edge-torch-nightly) (2.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from pytest->torch-xla2[odml]>=0.0.1.dev20241201->ai-edge-torch-nightly) (1.2.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from pytest->torch-xla2[odml]>=0.0.1.dev20241201->ai-edge-torch-nightly) (1.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/abheekp/AI_EDGETORCH_CONVERT/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20250101->ai-edge-torch-nightly) (0.1.2)\n",
      "Installing collected packages: ai-edge-quantizer-nightly, ai-edge-torch-nightly\n",
      "Successfully installed ai-edge-quantizer-nightly-0.0.1.dev20250218 ai-edge-torch-nightly-0.3.0.dev20250218\n"
     ]
    }
   ],
   "source": [
    "# 1) Uninstall any existing AI Edge packages\n",
    "!pip uninstall -y ai-edge-torch ai-edge-torch-nightly ai-edge-quantizer ai-edge-quantizer-nightly\n",
    "\n",
    "# 2) Re-install the newest nightly packages together\n",
    "!pip install --upgrade --pre ai-edge-torch-nightly ai-edge-quantizer-nightly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968266c3-f6ed-4256-9142-ad5acf6bfd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time2vec.lin_weight\n",
      "time2vec.lin_bias\n",
      "time2vec.per_weight\n",
      "time2vec.per_bias\n",
      "input_proj.weight\n",
      "input_proj.bias\n",
      "encoder.layers.0.self_attn.in_proj_weight\n",
      "encoder.layers.0.self_attn.in_proj_bias\n",
      "encoder.layers.0.self_attn.out_proj.weight\n",
      "encoder.layers.0.self_attn.out_proj.bias\n",
      "encoder.layers.0.linear1.weight\n",
      "encoder.layers.0.linear1.bias\n",
      "encoder.layers.0.linear2.weight\n",
      "encoder.layers.0.linear2.bias\n",
      "encoder.layers.0.norm1.weight\n",
      "encoder.layers.0.norm1.bias\n",
      "encoder.layers.0.norm2.weight\n",
      "encoder.layers.0.norm2.bias\n",
      "encoder.layers.1.self_attn.in_proj_weight\n",
      "encoder.layers.1.self_attn.in_proj_bias\n",
      "encoder.layers.1.self_attn.out_proj.weight\n",
      "encoder.layers.1.self_attn.out_proj.bias\n",
      "encoder.layers.1.linear1.weight\n",
      "encoder.layers.1.linear1.bias\n",
      "encoder.layers.1.linear2.weight\n",
      "encoder.layers.1.linear2.bias\n",
      "encoder.layers.1.norm1.weight\n",
      "encoder.layers.1.norm1.bias\n",
      "encoder.layers.1.norm2.weight\n",
      "encoder.layers.1.norm2.bias\n",
      "encoder.layers.2.self_attn.in_proj_weight\n",
      "encoder.layers.2.self_attn.in_proj_bias\n",
      "encoder.layers.2.self_attn.out_proj.weight\n",
      "encoder.layers.2.self_attn.out_proj.bias\n",
      "encoder.layers.2.linear1.weight\n",
      "encoder.layers.2.linear1.bias\n",
      "encoder.layers.2.linear2.weight\n",
      "encoder.layers.2.linear2.bias\n",
      "encoder.layers.2.norm1.weight\n",
      "encoder.layers.2.norm1.bias\n",
      "encoder.layers.2.norm2.weight\n",
      "encoder.layers.2.norm2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "old_sd = torch.load(\"Fold3_NoDistill_best_loss_weights.pth\", map_location=\"cpu\",weights_only=True)\n",
    "for k in old_sd.keys():\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a907c3a-8e13-42fa-9564-4a9df1724286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai_edge_torch version: 0.3.0.dev20250218\n",
      "Help on function signature in module ai_edge_torch._convert.converter:\n",
      "\n",
      "signature(name: 'str', module: 'torch.nn.Module', sample_args=None, sample_kwargs=None, dynamic_shapes: 'Optional[Union[dict[str, Any], Tuple[Any, ...]]]' = None) -> 'Converter'\n",
      "    Initiates a Converter object with the provided signature.\n",
      "    \n",
      "    Args:\n",
      "      name: The name of the signature included in the converted edge model.\n",
      "      module: The torch module to be converted.\n",
      "      sample_args: Tuple of tensors by which the torch module will be traced with\n",
      "        prior to conversion.\n",
      "      sample_kwargs: Dict of str to tensor by which the torch module will be\n",
      "        traced with prior to conversion.\n",
      "      dynamic_shapes: Optional dict or tuple that specify dynamic shape\n",
      "        specifications for each input in original order. See\n",
      "        https://pytorch.org/docs/stable/export.html#expressing-dynamism for more\n",
      "          details.\n",
      "    \n",
      "    Returns:\n",
      "      A Converter object with the provided signature.\n",
      "    \n",
      "    Example:\n",
      "      converter = ai_edge_torch.signature(name, module, args)\n",
      "      edge_model = converter.convert()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ai_edge_torch\n",
    "print(\"ai_edge_torch version:\", ai_edge_torch.__version__)\n",
    "help(ai_edge_torch.signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4786b98c-d4ed-4a12-a9eb-a36a0492c3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95114/1121051200.py:145: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded weights from: Fold3_NoDistill_best_loss_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739878493.214925   95114 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpextvdr50/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpextvdr50/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Exported TFLite model => fall_time2vec_transformer.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1739878494.673421   95114 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1739878494.673463   95114 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-02-18 05:34:54.674993: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpextvdr50\n",
      "2025-02-18 05:34:54.675949: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-02-18 05:34:54.675962: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpextvdr50\n",
      "I0000 00:00:1739878494.683861   95114 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-02-18 05:34:54.685245: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-02-18 05:34:54.751366: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpextvdr50\n",
      "2025-02-18 05:34:54.765003: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 90017 microseconds.\n",
      "2025-02-18 05:34:54.805074: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-18 05:34:55.228232: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:4074] Estimated count of arithmetic ops: 4.417 M  ops, equivalently 2.208 M  MACs\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "##############################\n",
    "# 1) Imports\n",
    "##############################\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# AI Edge Torch (make sure you're using version >= 0.3.x nightly)\n",
    "import ai_edge_torch\n",
    "from ai_edge_torch.generative.quantize import quant_recipes\n",
    "\n",
    "##############################\n",
    "# 2) Time2Vec Definition\n",
    "##############################\n",
    "class Time2Vec(nn.Module):\n",
    "    \"\"\"\n",
    "    This matches the submodule named in your checkpoint:\n",
    "      time2vec.lin_weight\n",
    "      time2vec.lin_bias\n",
    "      time2vec.per_weight\n",
    "      time2vec.per_bias\n",
    "    \"\"\"\n",
    "    def __init__(self, out_channels=8):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lin_weight = nn.Parameter(torch.randn(1))\n",
    "        self.lin_bias   = nn.Parameter(torch.randn(1))\n",
    "        if out_channels > 1:\n",
    "            self.per_weight = nn.Parameter(torch.randn(out_channels - 1))\n",
    "            self.per_bias   = nn.Parameter(torch.randn(out_channels - 1))\n",
    "        else:\n",
    "            self.per_weight = None\n",
    "            self.per_bias   = None\n",
    "\n",
    "    def forward(self, t):\n",
    "        # shape of t: (N, 1), e.g. flatten (B*T, 1)\n",
    "        t_lin = self.lin_weight * t + self.lin_bias\n",
    "        if self.per_weight is not None:\n",
    "            alpha = self.per_weight.unsqueeze(0)  # (1, out_channels-1)\n",
    "            beta  = self.per_bias.unsqueeze(0)    # (1, out_channels-1)\n",
    "            t_per = torch.sin(alpha * t + beta)\n",
    "            return torch.cat([t_lin, t_per], dim=-1)\n",
    "        else:\n",
    "            return t_lin\n",
    "\n",
    "##############################\n",
    "# 3) Main Model Definition\n",
    "##############################\n",
    "class FallTime2VecTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    This matches your original layering structure and parameter naming:\n",
    "      - time2vec.* for Time2Vec\n",
    "      - input_proj (linear)\n",
    "      - encoder.layers.(0..2) => each has\n",
    "          self_attn.in_proj_weight, self_attn.in_proj_bias,\n",
    "          self_attn.out_proj.weight, self_attn.out_proj.bias,\n",
    "          linear1.weight, linear1.bias, linear2.weight, linear2.bias,\n",
    "          norm1.weight, norm1.bias, norm2.weight, norm2.bias\n",
    "      - fc.weight, fc.bias\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 feat_dim=19,        # e.g. 3 accel channels + 16 Time2Vec => 19\n",
    "                 d_model=64,\n",
    "                 nhead=4,\n",
    "                 num_layers=3,\n",
    "                 num_classes=2,\n",
    "                 time2vec_dim=16,\n",
    "                 dropout=0.1,\n",
    "                 dim_feedforward=128):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.time2vec_dim = time2vec_dim\n",
    "\n",
    "        # 1) The same time2vec submodule\n",
    "        self.time2vec = Time2Vec(out_channels=time2vec_dim)\n",
    "\n",
    "        # 2) Project input => d_model\n",
    "        self.input_proj = nn.Linear(feat_dim, d_model)\n",
    "\n",
    "        # 3) A standard PyTorch TransformerEncoder with `num_layers`.\n",
    "        #    Each layer's internal submodules map exactly to the checkpoint keys:\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        # 4) Final classification\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, accel_xyz, accel_mask, accel_time):\n",
    "        \"\"\"\n",
    "        accel_xyz:  (B, T, 3)  => raw accelerometer channels\n",
    "        accel_mask: (B, T) bool => True means 'PAD' => used by Transformer\n",
    "        accel_time: (B, T) => raw time indices\n",
    "        \"\"\"\n",
    "        B, T, _ = accel_xyz.shape\n",
    "\n",
    "        # Flatten time => pass through time2vec => reshape\n",
    "        time_flat = accel_time.reshape(-1, 1)         # (B*T, 1)\n",
    "        t_emb_flat = self.time2vec(time_flat)         # => (B*T, time2vec_dim)\n",
    "        t_emb = t_emb_flat.view(B, T, self.time2vec_dim)\n",
    "\n",
    "        # Concat => shape => (B, T, feat_dim)\n",
    "        x = torch.cat([accel_xyz, t_emb], dim=-1)     # => 3 + time2vec_dim\n",
    "\n",
    "        # Project\n",
    "        x_proj = self.input_proj(x)                   # => (B, T, d_model)\n",
    "\n",
    "        # Pass to Transformer\n",
    "        out_seq = self.encoder(x_proj, src_key_padding_mask=accel_mask)\n",
    "\n",
    "        # Global average pool\n",
    "        feat = out_seq.mean(dim=1)\n",
    "\n",
    "        # Final linear\n",
    "        logits = self.fc(feat)\n",
    "        return logits\n",
    "\n",
    "##############################\n",
    "# 4) Load Weights\n",
    "##############################\n",
    "def load_weights(model, ckpt_path):\n",
    "    \"\"\"\n",
    "    Loads your original .pth. The checkpoint keys, for example, are:\n",
    "\n",
    "      time2vec.lin_weight\n",
    "      time2vec.lin_bias\n",
    "      time2vec.per_weight\n",
    "      ...\n",
    "      encoder.layers.0.self_attn.in_proj_weight\n",
    "      ...\n",
    "      fc.weight\n",
    "      fc.bias\n",
    "\n",
    "    If no prefix, we can load directly:\n",
    "    \"\"\"\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "    # If there's no mismatch (like \"module.\" prefix), just load:\n",
    "    model.load_state_dict(ckpt, strict=True)\n",
    "    print(f\"[INFO] Loaded weights from: {ckpt_path}\")\n",
    "\n",
    "##############################\n",
    "# 5) Convert => TFLite\n",
    "##############################\n",
    "def convert_to_tflite(model,\n",
    "                      tflite_path=\"fall_time2vec_transformer.tflite\",\n",
    "                      quantize=False):\n",
    "    model.eval()\n",
    "\n",
    "    # Example dummy input with (B=1, T=20)\n",
    "    B = 1\n",
    "    T = 20\n",
    "    dummy_xyz  = torch.randn(B, T, 3, dtype=torch.float32)\n",
    "    dummy_mask = torch.zeros(B, T, dtype=torch.bool)   # no pad\n",
    "    dummy_time = torch.arange(T).unsqueeze(0).float()  # shape (1,T)\n",
    "\n",
    "    # AI Edge Torch new signature uses sample_args= for input(s):\n",
    "    converter = ai_edge_torch.signature(\n",
    "        name=\"inference\",\n",
    "        module=model,\n",
    "        sample_args=(dummy_xyz, dummy_mask, dummy_time),\n",
    "    )\n",
    "\n",
    "    quant_config = None\n",
    "    if quantize:\n",
    "        quant_config = quant_recipes.full_int8_weight_only_recipe()\n",
    "\n",
    "    # Convert to TFLite\n",
    "    tflite_model = converter.convert(quant_config=quant_config)\n",
    "    tflite_model.export(tflite_path)\n",
    "    print(f\"[INFO] Exported TFLite model => {tflite_path}\")\n",
    "\n",
    "##############################\n",
    "# 6) Main Orchestrator\n",
    "##############################\n",
    "if __name__ == \"__main__\":\n",
    "    CKPT_PATH = \"Fold3_NoDistill_best_loss_weights.pth\"\n",
    "    OUTPUT_TFLITE_PATH = \"fall_time2vec_transformer.tflite\"\n",
    "\n",
    "    # Build model with same shapes used in your training\n",
    "    model = FallTime2VecTransformer(\n",
    "        feat_dim=19,      # e.g. 3 + 16\n",
    "        d_model=64,\n",
    "        nhead=4,\n",
    "        num_layers=3,     # as your checkpoint uses layers.0, .1, .2\n",
    "        num_classes=2,\n",
    "        time2vec_dim=16,  # must match the time2vec block dimension\n",
    "        dropout=0.1,\n",
    "        dim_feedforward=128\n",
    "    )\n",
    "\n",
    "    # Load your trained checkpoint\n",
    "    load_weights(model, CKPT_PATH)\n",
    "\n",
    "    # Convert to TFLite\n",
    "    convert_to_tflite(\n",
    "        model,\n",
    "        tflite_path=OUTPUT_TFLITE_PATH,\n",
    "        quantize=False   # or True if you want int8 weight-only\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a135c-468c-42be-880c-ae4607a5ef6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Edge Torch)",
   "language": "python",
   "name": "ai_edgetorch_convert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
